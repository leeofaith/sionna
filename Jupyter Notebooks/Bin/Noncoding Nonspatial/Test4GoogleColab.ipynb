{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n",
      "Your runtime has 17.2 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 02:14:36.512932: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 0\n",
      "|                                                                            Data Group 1                                                                           |\n",
      "|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|  EBN0[DB]  |  SER(ZF)  |  BER(ZF)  | Bit Errors(ZF) |  SER(LMMSE)  |  BER(LMMSE)  | Bit Errors(LMMSE) |  SER(DIP)  |  BER(DIP)  | Bit Errors(DIP) | Time Spent(s) |\n",
      "|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|       -20.0|"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from google.colab import files\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab/DIPEqualizer')\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "from UncodedSystemFlatFading import UncodedSystemFlatFading\n",
    "\n",
    "Block_Length = 128         # Block Length (k)\n",
    "NUM_BITS_PER_SYMBOL = 4    # Mapping: 16QAM\n",
    "CONSTELLATION_TYPE = \"qam\" #\n",
    "DEMAPPING_METHOD = \"app\"   # Demapping Method: \"app\"\n",
    "NUM_TX_ANT = 4             # Transmit Antennas\n",
    "NUM_RX_ANT = 4             # Receive Antennas\n",
    "NUM_DATA_GROUP = 3         # Number of Data Group\n",
    "BATCH_SIZE = 128           # Number of Parallelly Processed Batches\n",
    "EBN0_DB_MIN = -20.0        # Minimum Eb/N0 (dB)\n",
    "EBN0_DB_MAX = 20.0         # Maximum Eb/N0 (dB)\n",
    "NUM_EBN0_POINTS = 6        # EBNO Points\n",
    "\n",
    "model_uncoded_ff = UncodedSystemFlatFading(Block_Length, \n",
    "                                           NUM_BITS_PER_SYMBOL,\n",
    "                                           CONSTELLATION_TYPE,\n",
    "                                           DEMAPPING_METHOD,\n",
    "                                           NUM_RX_ANT,\n",
    "                                           NUM_TX_ANT)\n",
    "\n",
    "model_uncoded_ff(NUM_DATA_GROUP, BATCH_SIZE, EBN0_DB_MIN, EBN0_DB_MAX, NUM_EBN0_POINTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
