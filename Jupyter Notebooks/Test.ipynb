{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SPDX-FileCopyrightText: Copyright (c) 2021-2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "#\n",
    "\"\"\"Layers for (de)mapping, constellation class, and utility functions\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sionna as sn\n",
    "\n",
    "def pam_gray(b):\n",
    "\n",
    "    if len(b)>1:\n",
    "        return (1-2*b[0])*(2**len(b[1:]) - pam_gray(b[1:]))\n",
    "    return 1-2*b[0]\n",
    "\n",
    "def qam(num_bits_per_symbol, normalize=True):\n",
    "\n",
    "    try:\n",
    "        assert num_bits_per_symbol % 2 == 0 # is even\n",
    "        assert num_bits_per_symbol >0 # is larger than zero\n",
    "    except AssertionError as error:\n",
    "        raise ValueError(\"num_bits_per_symbol must be a multiple of 2\") \\\n",
    "        from error\n",
    "    assert isinstance(normalize, bool), \"normalize must be boolean\"\n",
    "\n",
    "    # Build constellation by iterating through all points\n",
    "    c = np.zeros([2**num_bits_per_symbol], dtype=np.complex64)\n",
    "    for i in range(0, 2**num_bits_per_symbol):\n",
    "        b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n",
    "                     dtype=np.int16)\n",
    "        c[i] = pam_gray(b[0::2]) + 1j*pam_gray(b[1::2]) # PAM in each dimension\n",
    "\n",
    "    if normalize: # Normalize to unit energy\n",
    "        n = int(num_bits_per_symbol/2)\n",
    "        qam_var = 1/(2**(n-2))*np.sum(np.linspace(1,2**n-1, 2**(n-1))**2)\n",
    "        c /= np.sqrt(qam_var)\n",
    "    return c\n",
    "\n",
    "def pam(num_bits_per_symbol, normalize=True):\n",
    "\n",
    "    try:\n",
    "        assert num_bits_per_symbol >0 # is larger than zero\n",
    "    except AssertionError as error:\n",
    "        raise ValueError(\"num_bits_per_symbol must be positive\") \\\n",
    "        from error\n",
    "    assert isinstance(normalize, bool), \"normalize must be boolean\"\n",
    "\n",
    "    # Build constellation by iterating through all points\n",
    "    c = np.zeros([2**num_bits_per_symbol], dtype=np.float32)\n",
    "    for i in range(0, 2**num_bits_per_symbol):\n",
    "        b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n",
    "                     dtype=np.int16)\n",
    "        c[i] = pam_gray(b)\n",
    "\n",
    "    if normalize: # Normalize to unit energy\n",
    "        n = int(num_bits_per_symbol)\n",
    "        pam_var = 1/(2**(n-1))*np.sum(np.linspace(1,2**n-1, 2**(n-1))**2)\n",
    "        c /= np.sqrt(pam_var)\n",
    "    return c\n",
    "\n",
    "class Constellation(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 constellation_type,\n",
    "                 num_bits_per_symbol,\n",
    "                 initial_value=None,\n",
    "                 normalize=True,\n",
    "                 center=False,\n",
    "                 trainable=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        assert dtype in [tf.complex64, tf.complex128],\\\n",
    "            \"dtype must be tf.complex64 or tf.complex128\"\n",
    "        self._dtype = dtype\n",
    "\n",
    "        assert constellation_type in (\"qam\", \"pam\", \"custom\"),\\\n",
    "            \"Wrong constellation type\"\n",
    "        self._constellation_type = constellation_type\n",
    "\n",
    "        assert isinstance(normalize, bool), \"normalize must be boolean\"\n",
    "        self._normalize = normalize\n",
    "\n",
    "        assert isinstance(center, bool), \"center must be boolean\"\n",
    "        self._center = center\n",
    "\n",
    "        assert isinstance(trainable, bool), \"trainable must be boolean\"\n",
    "        self._trainable = trainable\n",
    "\n",
    "        # allow float inputs that represent int\n",
    "        assert isinstance(num_bits_per_symbol, (float,int)),\\\n",
    "            \"num_bits_per_symbol must be integer\"\n",
    "        assert (num_bits_per_symbol%1==0),\\\n",
    "            \"num_bits_per_symbol must be integer\"\n",
    "        num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "\n",
    "        if self._constellation_type==\"qam\":\n",
    "            assert num_bits_per_symbol%2 == 0 and num_bits_per_symbol>0,\\\n",
    "                \"num_bits_per_symbol must be a multiple of 2\"\n",
    "            self._num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "\n",
    "            assert initial_value is None, \"QAM must not have an initial value\"\n",
    "            points = qam(self._num_bits_per_symbol, normalize=self.normalize)\n",
    "            points = tf.cast(points, self._dtype)\n",
    "\n",
    "        if self._constellation_type==\"pam\":\n",
    "            assert num_bits_per_symbol>0,\\\n",
    "                \"num_bits_per_symbol must be integer\"\n",
    "            self._num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "\n",
    "            assert initial_value is None, \"PAM must not have an initial value\"\n",
    "            points = pam(self._num_bits_per_symbol, normalize=self.normalize)\n",
    "            points = tf.cast(points, self._dtype)\n",
    "\n",
    "        if self._constellation_type==\"custom\":\n",
    "            assert num_bits_per_symbol>0,\\\n",
    "                \"num_bits_per_symbol must be integer\"\n",
    "            self._num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "\n",
    "            # Randomly initialize points if no initial_value is provided\n",
    "            if initial_value is None:\n",
    "                points = tf.random.uniform(  # pylint: disable=E1123\n",
    "                                        [2, 2**self._num_bits_per_symbol],\n",
    "                                        minval=-0.05, maxval=0.05,\n",
    "                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n",
    "                points  = tf.complex(points[0], points[1])\n",
    "            else:\n",
    "                assert tf.rank(initial_value).numpy() == 1\n",
    "                assert tf.shape(initial_value)[0] == 2**num_bits_per_symbol,\\\n",
    "                    \"initial_value must have shape [2**num_bits_per_symbol]\"\n",
    "                points = tf.cast(initial_value, self._dtype)\n",
    "        self._points = points\n",
    "\n",
    "    def build(self, input_shape): #pylint: disable=unused-argument\n",
    "        points = self._points\n",
    "        points = tf.stack([tf.math.real(points),\n",
    "                           tf.math.imag(points)], axis=0)\n",
    "        if self._trainable:\n",
    "            self._points = tf.Variable(points,\n",
    "                                       trainable=self._trainable,\n",
    "                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n",
    "        else:\n",
    "            self._points = tf.constant(points,\n",
    "                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n",
    "\n",
    "    # pylint: disable=no-self-argument\n",
    "    def create_or_check_constellation(  constellation_type=None,\n",
    "                                        num_bits_per_symbol=None,\n",
    "                                        constellation=None,\n",
    "                                        dtype=tf.complex64):\n",
    "        constellation_object = None\n",
    "        if constellation is not None:\n",
    "            assert constellation_type in [None, \"custom\"], \\\n",
    "                \"\"\"`constellation_type` must be \"custom\".\"\"\"\n",
    "            assert num_bits_per_symbol in \\\n",
    "                     [None, constellation.num_bits_per_symbol], \\\n",
    "                \"\"\"`Wrong value of `num_bits_per_symbol.`\"\"\"\n",
    "            assert constellation.dtype==dtype, \\\n",
    "                \"Constellation has wrong dtype.\"\n",
    "            constellation_object = constellation\n",
    "        else:\n",
    "            assert constellation_type in [\"qam\", \"pam\"], \\\n",
    "                \"Wrong constellation type.\"\n",
    "            assert num_bits_per_symbol is not None, \\\n",
    "                \"`num_bits_per_symbol` must be provided.\"\n",
    "            constellation_object = Constellation(   constellation_type,\n",
    "                                                    num_bits_per_symbol,\n",
    "                                                    dtype=dtype)\n",
    "        return constellation_object\n",
    "\n",
    "    def call(self, inputs): #pylint: disable=unused-argument\n",
    "        x = self._points\n",
    "        x = tf.complex(x[0], x[1])\n",
    "        if self._center:\n",
    "            x = x - tf.reduce_mean(x)\n",
    "        if self._normalize:\n",
    "            energy = tf.reduce_mean(tf.square(tf.abs(x)))\n",
    "            energy_sqrt = tf.cast(tf.sqrt(energy), self._dtype)\n",
    "            x = x / energy_sqrt\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def normalize(self):\n",
    "        \"\"\"Indicates if the constellation is normalized or not.\"\"\"\n",
    "        return self._normalize\n",
    "\n",
    "    @normalize.setter\n",
    "    def normalize(self, value):\n",
    "        assert isinstance(value, bool), \"`normalize` must be boolean\"\n",
    "        self._normalize = value\n",
    "\n",
    "    @property\n",
    "    def center(self):\n",
    "        \"\"\"Indicates if the constellation is centered.\"\"\"\n",
    "        return self._center\n",
    "\n",
    "    @center.setter\n",
    "    def center(self, value):\n",
    "        assert isinstance(value, bool), \"`center` must be boolean\"\n",
    "        self._center = value\n",
    "\n",
    "    @property\n",
    "    def num_bits_per_symbol(self):\n",
    "        \"\"\"The number of bits per constellation symbol.\"\"\"\n",
    "        return self._num_bits_per_symbol\n",
    "\n",
    "    @property\n",
    "    def points(self):\n",
    "        \"\"\"The (possibly) centered and normalized constellation points.\"\"\"\n",
    "        return self(None)\n",
    "\n",
    "    def show(self, labels=True, figsize=(7,7)):\n",
    "\n",
    "        maxval = np.max(np.abs(self.points))*1.05\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.xlim(-maxval, maxval)\n",
    "        plt.ylim(-maxval, maxval)\n",
    "        plt.scatter(np.real(self.points), np.imag(self.points))\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "        plt.xlabel(\"Real Part\")\n",
    "        plt.ylabel(\"Imaginary Part\")\n",
    "        plt.grid(True, which=\"both\", axis=\"both\")\n",
    "        plt.title(\"Constellation Plot\")\n",
    "        if labels is True:\n",
    "            for j, p in enumerate(self.points.numpy()):\n",
    "                plt.annotate(\n",
    "                    np.binary_repr(j, self.num_bits_per_symbol),\n",
    "                    (np.real(p), np.imag(p))\n",
    "                )\n",
    "        return fig\n",
    "\n",
    "class Mapper(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 return_indices=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert dtype in [tf.complex64, tf.complex128],\\\n",
    "            \"dtype must be tf.complex64 or tf.complex128\"\n",
    "\n",
    "        # Create constellation object\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=dtype)\n",
    "\n",
    "        self._return_indices = return_indices\n",
    "\n",
    "        self._binary_base = 2**tf.constant(\n",
    "                        range(self.constellation.num_bits_per_symbol-1,-1,-1))\n",
    "\n",
    "    @property\n",
    "    def constellation(self):\n",
    "        \"\"\"The Constellation used by the Mapper.\"\"\"\n",
    "        return self._constellation\n",
    "\n",
    "    def call(self, inputs):\n",
    "        tf.debugging.assert_greater_equal(tf.rank(inputs), 2,\n",
    "            message=\"The input must have at least rank 2\")\n",
    "\n",
    "        # Reshape inputs to the desired format\n",
    "        new_shape = [-1] + inputs.shape[1:-1].as_list() + \\\n",
    "           [int(inputs.shape[-1] / self.constellation.num_bits_per_symbol),\n",
    "            self.constellation.num_bits_per_symbol]\n",
    "        inputs_reshaped = tf.cast(tf.reshape(inputs, new_shape), tf.int32)\n",
    "\n",
    "        # Convert the last dimension to an integer\n",
    "        int_rep = tf.reduce_sum(inputs_reshaped * self._binary_base, axis=-1)\n",
    "\n",
    "        # Map integers to constellation symbols\n",
    "        x = tf.gather(self.constellation.points, int_rep, axis=0)\n",
    "\n",
    "        if self._return_indices:\n",
    "            return x, int_rep\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class SymbolLogits2LLRs(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 method,\n",
    "                 num_bits_per_symbol,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert method in (\"app\",\"maxlog\"), \"Unknown demapping method\"\n",
    "        self._method = method\n",
    "        self._hard_out = hard_out\n",
    "        self._num_bits_per_symbol = num_bits_per_symbol\n",
    "        self._with_prior = with_prior\n",
    "        num_points = int(2**num_bits_per_symbol)\n",
    "\n",
    "        # Array composed of binary representations of all symbols indices\n",
    "        a = np.zeros([num_points, num_bits_per_symbol])\n",
    "        for i in range(0, num_points):\n",
    "            a[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n",
    "                              dtype=np.int16)\n",
    "\n",
    "        # Compute symbol indices for which the bits are 0 or 1\n",
    "        c0 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        c1 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        for i in range(num_bits_per_symbol-1,-1,-1):\n",
    "            c0[:,i] = np.where(a[:,i]==0)[0]\n",
    "            c1[:,i] = np.where(a[:,i]==1)[0]\n",
    "        self._c0 = tf.constant(c0, dtype=tf.int32) # Symbols with ith bit=0\n",
    "        self._c1 = tf.constant(c1, dtype=tf.int32) # Symbols with ith bit=1\n",
    "\n",
    "        if with_prior:\n",
    "            # Array of labels from {-1, 1} of all symbols\n",
    "            # [num_points, num_bits_per_symbol]\n",
    "            a = 2*a-1\n",
    "            self._a = tf.constant(a, dtype=dtype)\n",
    "\n",
    "        # Determine the reduce function for LLR computation\n",
    "        if self._method == \"app\":\n",
    "            self._reduce = tf.reduce_logsumexp\n",
    "        else:\n",
    "            self._reduce = tf.reduce_max\n",
    "\n",
    "    @property\n",
    "    def num_bits_per_symbol(self):\n",
    "        return self._num_bits_per_symbol\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            logits, prior = inputs\n",
    "        else:\n",
    "            logits = inputs\n",
    "\n",
    "        # Compute exponents\n",
    "        exponents = logits\n",
    "\n",
    "        # Gather exponents for all bits\n",
    "        # shape [...,n,num_points/2,num_bits_per_symbol]\n",
    "        exp0 = tf.gather(exponents, self._c0, axis=-1, batch_dims=0)\n",
    "        exp1 = tf.gather(exponents, self._c1, axis=-1, batch_dims=0)\n",
    "\n",
    "        # Process the prior information\n",
    "        if self._with_prior:\n",
    "            # Expanding `prior` such that it is broadcastable with\n",
    "            # shape [..., n or 1, 1, num_bits_per_symbol]\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(logits), axis=0)\n",
    "            prior = tf.expand_dims(prior, axis=-2)\n",
    "\n",
    "            # Expand the symbol labeling to be broadcastable with prior\n",
    "            # shape [..., 1, num_points, num_bits_per_symbol]\n",
    "            a = sn.utils.expand_to_rank(self._a, tf.rank(prior), axis=0)\n",
    "\n",
    "            # Compute the prior probabilities on symbols exponents\n",
    "            # shape [..., n or 1, num_points]\n",
    "            exp_ps = tf.reduce_sum(tf.math.log_sigmoid(a*prior), axis=-1)\n",
    "\n",
    "            # Gather prior probability symbol for all bits\n",
    "            # shape [..., n or 1, num_points/2, num_bits_per_symbol]\n",
    "            exp_ps0 = tf.gather(exp_ps, self._c0, axis=-1)\n",
    "            exp_ps1 = tf.gather(exp_ps, self._c1, axis=-1)\n",
    "\n",
    "        # Compute LLRs using the definition log( Pr(b=1)/Pr(b=0) )\n",
    "        # shape [..., n, num_bits_per_symbol]\n",
    "        if self._with_prior:\n",
    "            llr = self._reduce(exp_ps1 + exp1, axis=-2)\\\n",
    "                    - self._reduce(exp_ps0 + exp0, axis=-2)\n",
    "        else:\n",
    "            llr = self._reduce(exp1, axis=-2) - self._reduce(exp0, axis=-2)\n",
    "\n",
    "        if self._hard_out:\n",
    "            return sn.utils.hard_decisions(llr)\n",
    "        else:\n",
    "            return llr\n",
    "\n",
    "class SymbolLogits2LLRsWithPrior(SymbolLogits2LLRs):\n",
    "\n",
    "    def __init__(self,\n",
    "                 method,\n",
    "                 num_bits_per_symbol,\n",
    "                 hard_out=False,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(method=method,\n",
    "                         num_bits_per_symbol=num_bits_per_symbol,\n",
    "                         hard_out=False,\n",
    "                         with_prior=True,\n",
    "                         dtype=tf.float32,\n",
    "                         **kwargs)\n",
    "\n",
    "class Demapper(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 demapping_method,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._with_prior = with_prior\n",
    "\n",
    "\n",
    "        # Create constellation object\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=dtype)\n",
    "        num_bits_per_symbol = self._constellation.num_bits_per_symbol\n",
    "\n",
    "        self._logits2llrs = SymbolLogits2LLRs(demapping_method,\n",
    "                                              num_bits_per_symbol,\n",
    "                                              hard_out,\n",
    "                                              with_prior,\n",
    "                                              dtype.real_dtype,\n",
    "                                              **kwargs)\n",
    "\n",
    "    @property\n",
    "    def constellation(self):\n",
    "        return self._constellation\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            y, prior, no = inputs\n",
    "        else:\n",
    "            y, no = inputs\n",
    "\n",
    "        # Reshape constellation points to [1,...1,num_points]\n",
    "        points_shape = [1]*y.shape.rank + self.constellation.points.shape\n",
    "        points = tf.reshape(self.constellation.points, points_shape)\n",
    "\n",
    "        # Compute squared distances from y to all points\n",
    "        # shape [...,n,num_points]\n",
    "        squared_dist = tf.pow(tf.abs(tf.expand_dims(y, axis=-1) - points), 2)\n",
    "\n",
    "        # Add a dummy dimension for broadcasting. This is not needed when no\n",
    "        # is a scalar, but also does not do any harm.\n",
    "        no = tf.expand_dims(no, axis=-1)\n",
    "\n",
    "        # Compute exponents\n",
    "        exponents = -squared_dist/no\n",
    "\n",
    "        if self._with_prior:\n",
    "            llr = self._logits2llrs([exponents, prior])\n",
    "        else:\n",
    "            llr = self._logits2llrs(exponents)\n",
    "\n",
    "        # Reshape LLRs to [...,n*num_bits_per_symbol]\n",
    "        out_shape = tf.concat([tf.shape(y)[:-1],\n",
    "                               [y.shape[-1] * \\\n",
    "                                self.constellation.num_bits_per_symbol]], 0)\n",
    "        llr_reshaped = tf.reshape(llr, out_shape)\n",
    "\n",
    "        return llr_reshaped\n",
    "\n",
    "class DemapperWithPrior(Demapper):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 demapping_method,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(demapping_method=demapping_method,\n",
    "                         constellation_type=constellation_type,\n",
    "                         num_bits_per_symbol=num_bits_per_symbol,\n",
    "                         constellation=constellation,\n",
    "                         hard_out=hard_out,\n",
    "                         with_prior=True,\n",
    "                         dtype=dtype,\n",
    "                         **kwargs)\n",
    "\n",
    "class SymbolDemapper(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._hard_out = hard_out\n",
    "        self._with_prior = with_prior\n",
    "\n",
    "        # Create constellation object\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=dtype)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            y, prior, no = inputs\n",
    "        else:\n",
    "            y, no = inputs\n",
    "\n",
    "        points = sn.utils.expand_to_rank(self._constellation.points,\n",
    "                                tf.rank(y)+1, axis=0)\n",
    "        y = tf.expand_dims(y, axis=-1)\n",
    "        d = tf.abs(y-points)\n",
    "\n",
    "        no = sn.utils.expand_to_rank(no, tf.rank(d), axis=-1)\n",
    "        exp = -d**2 / no\n",
    "\n",
    "        if self._with_prior:\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(exp), axis=0)\n",
    "            exp = exp + prior\n",
    "\n",
    "        if self._hard_out:\n",
    "            return tf.argmax(exp, axis=-1, output_type=tf.int32)\n",
    "        else:\n",
    "            return tf.nn.log_softmax(exp, axis=-1)\n",
    "\n",
    "class SymbolDemapperWithPrior(SymbolDemapper):\n",
    "   \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(constellation_type=constellation_type,\n",
    "                         num_bits_per_symbol=num_bits_per_symbol,\n",
    "                         constellation=constellation,\n",
    "                         hard_out=hard_out,\n",
    "                         with_prior=True,\n",
    "                         dtype=dtype,\n",
    "                         **kwargs)\n",
    "\n",
    "class LLRs2SymbolLogits(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_bits_per_symbol,\n",
    "                 hard_out=False,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "\n",
    "        self._hard_out = hard_out\n",
    "        self._num_bits_per_symbol = num_bits_per_symbol\n",
    "        num_points = int(2**num_bits_per_symbol)\n",
    "\n",
    "        # Array composed of binary representations of all symbols indices\n",
    "        a = np.zeros([num_points, num_bits_per_symbol])\n",
    "        for i in range(0, num_points):\n",
    "            a[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n",
    "                              dtype=np.int16)\n",
    "\n",
    "        # Array of labels from {-1, 1} of all symbols\n",
    "        # [num_points, num_bits_per_symbol]\n",
    "        a = 2*a-1\n",
    "        self._a = tf.constant(a, dtype=dtype)\n",
    "\n",
    "    @property\n",
    "    def num_bits_per_symbol(self):\n",
    "        return self._num_bits_per_symbol\n",
    "\n",
    "    def call(self, inputs):\n",
    "        llrs = inputs\n",
    "\n",
    "        # Expand the symbol labeling to be broadcastable with prior\n",
    "        # shape [1, ..., 1, num_points, num_bits_per_symbol]\n",
    "        a = sn.utils.expand_to_rank(self._a, tf.rank(llrs), axis=0)\n",
    "\n",
    "        # Compute the prior probabilities on symbols exponents\n",
    "        # shape [..., 1, num_points]\n",
    "        llrs = tf.expand_dims(llrs, axis=-2)\n",
    "        logits = tf.reduce_sum(tf.math.log_sigmoid(a*llrs), axis=-1)\n",
    "\n",
    "        if self._hard_out:\n",
    "            return tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "class SymbolLogits2Moments(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "\n",
    "        # Create constellation object\n",
    "        const_dtype = tf.complex64 if dtype is tf.float32 else tf.complex128\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=const_dtype)\n",
    "\n",
    "    def __call__(self, logits):\n",
    "        p = tf.math.softmax(logits, axis=-1)\n",
    "        p_c = tf.complex(p, tf.cast(0.0, self.dtype))\n",
    "        points = self._constellation.points\n",
    "        points = sn.utils.expand_to_rank(points, tf.rank(p), axis=0)\n",
    "\n",
    "        mean = tf.reduce_sum(p_c*points, axis=-1, keepdims=True)\n",
    "        var = tf.reduce_sum(p*tf.square(tf.abs(points - mean)), axis=-1)\n",
    "        mean = tf.squeeze(mean, axis=-1)\n",
    "\n",
    "        return mean, var\n",
    "\n",
    "class QAM2PAM:\n",
    "    \n",
    "    def __init__(self, num_bits_per_symbol):\n",
    "        base = [2**i for i in range(num_bits_per_symbol//2-1, -1, -1)]\n",
    "        base = np.array(base)\n",
    "        pam1_ind = np.zeros([2**num_bits_per_symbol], dtype=np.int32)\n",
    "        pam2_ind = np.zeros([2**num_bits_per_symbol], dtype=np.int32)\n",
    "        for i in range(0, 2**num_bits_per_symbol):\n",
    "            b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n",
    "                         dtype=np.int32)\n",
    "            pam1_ind[i] = np.sum(b[0::2]*base)\n",
    "            pam2_ind[i] = np.sum(b[1::2]*base)\n",
    "        self._pam1_ind = tf.constant(pam1_ind, dtype=tf.int32)\n",
    "        self._pam2_ind = tf.constant(pam2_ind, dtype=tf.int32)\n",
    "\n",
    "    def __call__(self, ind_qam):\n",
    "\n",
    "        ind_pam1 = tf.gather(self._pam1_ind, ind_qam, axis=0)\n",
    "        ind_pam2 = tf.gather(self._pam2_ind, ind_qam, axis=0)\n",
    "\n",
    "        return ind_pam1, ind_pam2\n",
    "\n",
    "class PAM2QAM:\n",
    "    \n",
    "    def __init__(self, num_bits_per_symbol, hard_in_out=True):\n",
    "        num_pam_symbols = 2**(num_bits_per_symbol//2)\n",
    "        base = np.array([2**i for i in range(num_bits_per_symbol-1, -1, -1)])\n",
    "\n",
    "        # Create an array of QAM symbol indices, index by two PAM indices\n",
    "        ind = np.zeros([num_pam_symbols, num_pam_symbols], np.int32)\n",
    "        for i in range(0, num_pam_symbols):\n",
    "            for j in range(0, num_pam_symbols):\n",
    "                b1 = np.array(list(np.binary_repr(i,num_bits_per_symbol//2)),\n",
    "                              dtype=np.int16)\n",
    "                b2 = np.array(list(np.binary_repr(j,num_bits_per_symbol//2)),\n",
    "                              dtype=np.int16)\n",
    "                b = np.zeros([num_bits_per_symbol], np.int32)\n",
    "                b[0::2] = b1\n",
    "                b[1::2] = b2\n",
    "                ind[i, j] = np.sum(b*base)\n",
    "        self._qam_ind = tf.constant(ind, dtype=tf.int32)\n",
    "        self._hard_in_out = hard_in_out\n",
    "\n",
    "    def __call__(self, pam1, pam2):\n",
    "\n",
    "        # PAM indices to QAM indices\n",
    "        if self._hard_in_out:\n",
    "            shape = tf.shape(pam1)\n",
    "            ind_pam1 = tf.reshape(pam1, [-1, 1])\n",
    "            ind_pam2 = tf.reshape(pam2, [-1, 1])\n",
    "            ind_pam = tf.concat([ind_pam1, ind_pam2], axis=-1)\n",
    "            ind_qam = tf.gather_nd(self._qam_ind, ind_pam)\n",
    "            ind_qam = tf.reshape(ind_qam, shape)\n",
    "            return ind_qam\n",
    "\n",
    "        # PAM logits to QAM logits\n",
    "        else:\n",
    "            # Compute all combination of sums of logits\n",
    "            logits_mat = tf.expand_dims(pam1, -1) + tf.expand_dims(pam2, -2)\n",
    "\n",
    "            # Flatten to a vector\n",
    "            logits = sn.utils.flatten_last_dims(logits_mat)\n",
    "\n",
    "            # Gather symbols in the correct order\n",
    "            gather_ind = tf.reshape(self._qam_ind, [-1])\n",
    "            logits = tf.gather(logits, gather_ind, axis=-1)\n",
    "            return logits\n",
    "\n",
    "class SymbolInds2Bits(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "               num_bits_per_symbol,\n",
    "               dtype=tf.float32,\n",
    "               **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        num_symbols = 2**num_bits_per_symbol\n",
    "        b = np.zeros([num_symbols, num_bits_per_symbol])\n",
    "        for i in range(0, num_symbols):\n",
    "            b[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n",
    "                              dtype=np.int16)\n",
    "        self._bit_labels = tf.constant(b, self.dtype)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        symbol_ind = inputs\n",
    "        return tf.gather(self._bit_labels, symbol_ind)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ebnodb2no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber, compute_ser\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = 8\n",
    "BATCH_SIZE = 2\n",
    "EBN0_DB_MIN = -3.0\n",
    "EBN0_DB_MAX = 3.0\n",
    "\n",
    "for EBN0_DB in np.linspace(EBN0_DB_MIN,EBN0_DB_MAX,20):\n",
    "    print('EBN0_DB =',EBN0_DB)\n",
    "    no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                            num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                            coderate=1.0)\n",
    "    print('no =',no)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWGN (Additive White Gaussian **Noise**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils import expand_to_rank, complex_normal\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = 8\n",
    "BATCH_SIZE = 2\n",
    "EBN0_DB = -10\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "print('bits =\\n',bits)\n",
    "\n",
    "no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                        coderate=1.0)\n",
    "print('no =',no)\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "\n",
    "x = mapper(bits)\n",
    "print('x =\\n',x)\n",
    " \n",
    "# Create tensors of real-valued Gaussian noise for each complex dim.\n",
    "noise = complex_normal(tf.shape(x), dtype=x.dtype)\n",
    "print('noise =\\n',noise)\n",
    "\n",
    "# Add extra dimensions for broadcasting\n",
    "no = expand_to_rank(no, tf.rank(x), axis=-1)\n",
    "print('no =',no)\n",
    "\n",
    "# Apply variance scaling\n",
    "real_dtype = tf.dtypes.as_dtype(tf.complex64).real_dtype\n",
    "no = tf.cast(no, real_dtype)\n",
    "print('no =',no)\n",
    "noise *= tf.cast(tf.sqrt(no), noise.dtype)\n",
    "print('noise =\\n',noise)\n",
    "\n",
    "# Add noise to input\n",
    "y = x + noise\n",
    "#print('y = x + noise =\\n',y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logits2llrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.float32, **kwargs):\n",
    "    # pylint: disable=line-too-long\n",
    "    r\"\"\"\n",
    "    SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.float32, **kwargs)\n",
    "\n",
    "    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n",
    "    from a tensor of logits (i.e., unnormalized log-probabilities) on constellation points.\n",
    "    If the flag ``with_prior`` is set, prior knowledge on the bits is assumed to be available.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : One of [\"app\", \"maxlog\"], str\n",
    "        The method used for computing the LLRs.\n",
    "\n",
    "    num_bits_per_symbol : int\n",
    "        The number of bits per constellation symbol, e.g., 4 for QAM16.\n",
    "\n",
    "    hard_out : bool\n",
    "        If `True`, the layer provides hard-decided bits instead of soft-values.\n",
    "        Defaults to `False`.\n",
    "\n",
    "    with_prior : bool\n",
    "        If `True`, it is assumed that prior knowledge on the bits is available.\n",
    "        This prior information is given as LLRs as an additional input to the layer.\n",
    "        Defaults to `False`.\n",
    "\n",
    "    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n",
    "        The dtype for the input and output.\n",
    "        Defaults to `tf.float32`.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    logits or (logits, prior):\n",
    "        Tuple:\n",
    "\n",
    "    logits : [...,n, num_points], tf.float\n",
    "        Logits on constellation points.\n",
    "\n",
    "    prior : [num_bits_per_symbol] or [...n, num_bits_per_symbol], tf.float\n",
    "        Prior for every bit as LLRs.\n",
    "        It can be provided either as a tensor of shape `[num_bits_per_symbol]`\n",
    "        for the entire input batch, or as a tensor that is \"broadcastable\"\n",
    "        to `[..., n, num_bits_per_symbol]`.\n",
    "        Only required if the ``with_prior`` flag is set.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    : [...,n, num_bits_per_symbol], tf.float\n",
    "        LLRs or hard-decisions for every bit.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    With the \"app\" method, the LLR for the :math:`i\\text{th}` bit\n",
    "    is computed according to\n",
    "\n",
    "    .. math::\n",
    "        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert \\mathbf{z},\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert \\mathbf{z},\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n",
    "                \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                e^{z_c}\n",
    "                }{\n",
    "                \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                e^{z_c}\n",
    "                }\\right)\n",
    "\n",
    "    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n",
    "    sets of :math:`2^K` constellation points for which the :math:`i\\text{th}` bit is\n",
    "    equal to 1 and 0, respectively. :math:`\\mathbf{z} = \\left[z_{c_0},\\dots,z_{c_{2^K-1}}\\right]` is the vector of logits on the constellation points, :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]`\n",
    "    is the vector of LLRs that serves as prior knowledge on the :math:`K` bits that are mapped to\n",
    "    a constellation point and is set to :math:`\\mathbf{0}` if no prior knowledge is assumed to be available,\n",
    "    and :math:`\\Pr(c\\lvert\\mathbf{p})` is the prior probability on the constellation symbol :math:`c`:\n",
    "\n",
    "    .. math::\n",
    "        \\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert\\mathbf{p} \\right)\n",
    "        = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n",
    "\n",
    "    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where 0 is\n",
    "    replaced by -1.\n",
    "    The definition of the LLR has been\n",
    "    chosen such that it is equivalent with that of logits. This is\n",
    "    different from many textbooks in communications, where the LLR is\n",
    "    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n",
    "\n",
    "    With the \"maxlog\" method, LLRs for the :math:`i\\text{th}` bit\n",
    "    are approximated like\n",
    "\n",
    "    .. math::\n",
    "        \\begin{align}\n",
    "            LLR(i) &\\approx\\ln\\left(\\frac{\n",
    "                \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                    e^{z_c}\n",
    "                }{\n",
    "                \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                    e^{z_c}\n",
    "                }\\right)\n",
    "                .\n",
    "        \\end{align}\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 method,\n",
    "                 num_bits_per_symbol,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert method in (\"app\",\"maxlog\"), \"Unknown demapping method\"\n",
    "        self._method = method\n",
    "        self._hard_out = hard_out\n",
    "        self._num_bits_per_symbol = num_bits_per_symbol\n",
    "        self._with_prior = with_prior\n",
    "        num_points = int(2**num_bits_per_symbol)\n",
    "\n",
    "        # Array composed of binary representations of all symbols indices\n",
    "        a = np.zeros([num_points, num_bits_per_symbol])\n",
    "        for i in range(0, num_points):\n",
    "            a[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n",
    "                              dtype=np.int16)\n",
    "\n",
    "        # Compute symbol indices for which the bits are 0 or 1\n",
    "        c0 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        c1 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        for i in range(num_bits_per_symbol-1,-1,-1):\n",
    "            c0[:,i] = np.where(a[:,i]==0)[0]\n",
    "            c1[:,i] = np.where(a[:,i]==1)[0]\n",
    "        self._c0 = tf.constant(c0, dtype=tf.int32) # Symbols with ith bit=0\n",
    "        self._c1 = tf.constant(c1, dtype=tf.int32) # Symbols with ith bit=1\n",
    "\n",
    "        if with_prior:\n",
    "            # Array of labels from {-1, 1} of all symbols\n",
    "            # [num_points, num_bits_per_symbol]\n",
    "            a = 2*a-1\n",
    "            self._a = tf.constant(a, dtype=dtype)\n",
    "\n",
    "        # Determine the reduce function for LLR computation\n",
    "        if self._method == \"app\":\n",
    "            self._reduce = tf.reduce_logsumexp\n",
    "        else:\n",
    "            self._reduce = tf.reduce_max\n",
    "\n",
    "    @property\n",
    "    def num_bits_per_symbol(self):\n",
    "        return self._num_bits_per_symbol\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            logits, prior = inputs\n",
    "        else:\n",
    "            logits = inputs\n",
    "\n",
    "        # Compute exponents\n",
    "        exponents = logits\n",
    "\n",
    "        # Gather exponents for all bits\n",
    "        # shape [...,n,num_points/2,num_bits_per_symbol]\n",
    "        exp0 = tf.gather(exponents, self._c0, axis=-1, batch_dims=0)\n",
    "        exp1 = tf.gather(exponents, self._c1, axis=-1, batch_dims=0)\n",
    "\n",
    "        # Process the prior information\n",
    "        if self._with_prior:\n",
    "            # Expanding `prior` such that it is broadcastable with\n",
    "            # shape [..., n or 1, 1, num_bits_per_symbol]\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(logits), axis=0)\n",
    "            prior = tf.expand_dims(prior, axis=-2)\n",
    "\n",
    "            # Expand the symbol labeling to be broadcastable with prior\n",
    "            # shape [..., 1, num_points, num_bits_per_symbol]\n",
    "            a = sn.utils.expand_to_rank(self._a, tf.rank(prior), axis=0)\n",
    "\n",
    "            # Compute the prior probabilities on symbols exponents\n",
    "            # shape [..., n or 1, num_points]\n",
    "            exp_ps = tf.reduce_sum(tf.math.log_sigmoid(a*prior), axis=-1)\n",
    "\n",
    "            # Gather prior probability symbol for all bits\n",
    "            # shape [..., n or 1, num_points/2, num_bits_per_symbol]\n",
    "            exp_ps0 = tf.gather(exp_ps, self._c0, axis=-1)\n",
    "            exp_ps1 = tf.gather(exp_ps, self._c1, axis=-1)\n",
    "\n",
    "        # Compute LLRs using the definition log( Pr(b=1)/Pr(b=0) )\n",
    "        # shape [..., n, num_bits_per_symbol]\n",
    "        if self._with_prior:\n",
    "            llr = self._reduce(exp_ps1 + exp1, axis=-2)\\\n",
    "                    - self._reduce(exp_ps0 + exp0, axis=-2)\n",
    "        else:\n",
    "            llr = self._reduce(exp1, axis=-2) - self._reduce(exp0, axis=-2)\n",
    "\n",
    "        if self._hard_out:\n",
    "            return sn.utils.hard_decisions(llr)\n",
    "        else:\n",
    "            return llr\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = 8\n",
    "BATCH_SIZE = 2\n",
    "EBN0_DB = -10\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "\n",
    "# AWGN channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "#print('bits =\\n',bits)\n",
    "\n",
    "no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                        coderate=1.0)\n",
    "#print('no =',no)\n",
    "\n",
    "x = mapper(bits)\n",
    "#print('x =\\n',x)\n",
    "\n",
    "y = awgn_channel([x, no])\n",
    "\n",
    "# Reshape constellation points to [1,...1,num_points]\n",
    "points_shape = [1]*y.shape.rank + constellation.points.shape\n",
    "points = tf.reshape(constellation.points, points_shape)\n",
    "\n",
    "# Compute squared distances from y to all points\n",
    "# shape [...,n,num_points]\n",
    "squared_dist = tf.pow(tf.abs(tf.expand_dims(y, axis=-1) - points), 2)\n",
    "\n",
    "# Add a dummy dimension for broadcasting. This is not needed when no\n",
    "# is a scalar, but also does not do any harm.\n",
    "no = tf.expand_dims(no, axis=-1)\n",
    "\n",
    "# Compute exponents\n",
    "exponents = -squared_dist/no\n",
    "#print('exponents =\\n',exponents)\n",
    "\n",
    "logits2llrs = SymbolLogits2LLRs(\"app\",NUM_BITS_PER_SYMBOL)\n",
    "print('logits2llrs =\\n',logits2llrs)\n",
    "\n",
    "# if self._with_prior:\n",
    "#     llr = self._logits2llrs([exponents, prior])\n",
    "# else:\n",
    "llr = logits2llrs(exponents)\n",
    "\n",
    "# Reshape LLRs to [...,n*num_bits_per_symbol]\n",
    "out_shape = tf.concat([tf.shape(y)[:-1],\n",
    "                        [y.shape[-1] * \\\n",
    "                        constellation.num_bits_per_symbol]], 0)\n",
    "llr_reshaped = tf.reshape(llr, out_shape)\n",
    "\n",
    "# return llr_reshaped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bits2symbol"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber, compute_ser\n",
    "\n",
    "CODERATE = 0.5\n",
    "n = 16\n",
    "k = int(n*CODERATE)\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "print('NUM_BITS_PER_SYMBOL =',NUM_BITS_PER_SYMBOL)\n",
    "BLOCK_LENGTH = k\n",
    "BATCH_SIZE = 2 # How many examples are processed by Sionna in parallel\n",
    "EBN0_DB_MIN = -10.0 # Minimum value of Eb/N0 [dB] for simulations\n",
    "EBN0_DB_MAX = 10.0 # Maximum value of Eb/N0 [dB] for simulations\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "\n",
    "bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "print('bits =\\n',bits)\n",
    "\n",
    "new_shape = [-1] + bits.shape[1:-1].as_list() + \\\n",
    "           [int(bits.shape[-1] / NUM_BITS_PER_SYMBOL),\n",
    "            NUM_BITS_PER_SYMBOL]\n",
    "print('new_shape =\\n',new_shape)\n",
    "\n",
    "bits_reshaped = tf.cast(tf.reshape(bits, new_shape), tf.int32)\n",
    "print('symbols =\\n',bits_reshaped)\n",
    "\n",
    "binary_base = 2**tf.constant(\n",
    "                        range(NUM_BITS_PER_SYMBOL-1,-1,-1))\n",
    "print('binary_base =\\n',binary_base)\n",
    "\n",
    "int_rep = tf.reduce_sum(bits_reshaped * binary_base, axis=-1)\n",
    "print('int_rep =\\n',int_rep)\n",
    "\n",
    "x = tf.gather(constellation.points, int_rep, axis=0)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber, compute_ser\n",
    "\n",
    "def bits2symbol(bits,num_bits_per_symbol):\n",
    "    new_shape = [-1] + bits.shape[1:-1].as_list() + \\\n",
    "            [int(bits.shape[-1] / NUM_BITS_PER_SYMBOL),\n",
    "                NUM_BITS_PER_SYMBOL]\n",
    "    #print('new_shape =',new_shape)\n",
    "    #print('bits.shape[1:-1]',bits.shape[1:-1])\n",
    "    # print('bits.shape[-1]=',bits.shape[-1])\n",
    "\n",
    "    symbols = tf.cast(tf.reshape(bits, new_shape), tf.int32)\n",
    "    # print('symbols =',symbols)\n",
    "    return symbols\n",
    "\n",
    "\n",
    "CODERATE = 0.5\n",
    "n = 16\n",
    "k = int(n*CODERATE)\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = k\n",
    "BATCH_SIZE = 2 # How many examples are processed by Sionna in parallel\n",
    "EBN0_DB_MIN = -10.0 # Minimum value of Eb/N0 [dB] for simulations\n",
    "EBN0_DB_MAX = 10.0 # Maximum value of Eb/N0 [dB] for simulations\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "\n",
    "#bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "bits = binary_source([2,3,4,5,6])\n",
    "# print('bits =',bits)\n",
    "# print('bits.ndim =',bits.ndim)\n",
    "\n",
    "symbols = bits2symbol(bits,NUM_BITS_PER_SYMBOL)\n",
    "# print('symbols =',symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "\n",
    "BATCH_SIZE = 1000000\n",
    "NUM_TX_ANT = 4\n",
    "NUM_RX_ANT = 16\n",
    "NUM_BITS_PER_SYMBOL = 4\n",
    "\n",
    "channel = FlatFadingChannel(num_tx_ant=NUM_TX_ANT, num_rx_ant=NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "no = 0.2 # Noise variance of the channel\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "qam_source = QAMSource(num_bits_per_symbol=NUM_BITS_PER_SYMBOL)\n",
    "x = qam_source([BATCH_SIZE, NUM_TX_ANT])\n",
    "# print('x =',x)\n",
    "# Get symbol indices for the transmitted symbols\n",
    "x_ind = symbol_demapper([x, no])\n",
    "# print('x_ind =',x_ind)\n",
    "\n",
    "# Create transmit and receive correlation matrices\n",
    "r_tx = exp_corr_mat(0.4, NUM_TX_ANT)\n",
    "r_rx = exp_corr_mat(0.9, NUM_RX_ANT)\n",
    "\n",
    "print('r_tx =',r_tx)\n",
    "print('r_rx =',r_rx)\n",
    "print('r_tx.shape =',r_tx.shape)\n",
    "print('r_rx.shape =',r_rx.shape)\n",
    "\n",
    "# Add the spatial correlation model to the channel\n",
    "channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "#print('h_corr =',KroneckerModel(r_tx, r_rx))\n",
    "\n",
    "h = channel.generate(BATCH_SIZE)\n",
    "print('h.shape =',h.shape)\n",
    "\n",
    "# Compute empirical covariance matrices\n",
    "r_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/NUM_RX_ANT\n",
    "r_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/NUM_TX_ANT\n",
    "\n",
    "# Test that the empirical results match the theory\n",
    "# assert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\n",
    "# assert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n",
    "\n",
    "y, h = channel([x, no]) # type: ignore\n",
    "s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "x_hat, no_eff = lmmse_equalizer(y, h, s)\n",
    "\n",
    "# Get symbol indices for the received soft-symbols\n",
    "x_ind_hat = symbol_demapper([x_hat, no])\n",
    "compute_ser(x_ind, x_ind_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FlatFadingChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b shape = (32, 4, 512)\n",
      "x shape = (32, 4, 128)\n",
      "x reshape = (4096, 4)\n",
      "batch_size = tf.Tensor(4096, shape=(), dtype=int32)\n",
      "h shape = (4096, 16, 4)\n",
      "h = tf.Tensor(\n",
      "[[[ 1.2106943 -0.57531357j -0.16533719+0.3895905j\n",
      "   -0.1602286 +0.8083027j  -0.9215764 -0.03920262j]\n",
      "  [-1.1231408 -0.76993793j  0.21325897+0.04296628j\n",
      "   -0.5221998 +1.2066145j   1.3783945 -0.31628877j]\n",
      "  [ 0.8965064 -0.12762327j -0.6455877 -0.3811652j\n",
      "   -1.7724121 -0.19522943j  0.7525839 -0.42759407j]\n",
      "  ...\n",
      "  [ 0.6631029 -0.1177212j   0.280737  -0.14437845j\n",
      "    0.84232557+0.22630343j  0.65941656-0.02572032j]\n",
      "  [-0.6040951 -0.37555417j -0.6060022 -0.77499133j\n",
      "   -0.71687335-0.30254802j  0.2920682 +0.11929827j]\n",
      "  [ 1.7277184 +1.6393815j   0.53525054+0.6290777j\n",
      "   -0.0562429 +0.52128416j -0.7860079 -1.0565555j ]]\n",
      "\n",
      " [[-0.7330225 +1.4971594j  -0.28901926+0.07351026j\n",
      "   -0.5539348 +0.20673583j -0.60231996-0.3816234j ]\n",
      "  [ 0.80606776-0.4482717j  -0.26762336+1.9391681j\n",
      "   -0.39329344-0.33786756j -0.5783194 -0.268788j  ]\n",
      "  [-0.32890016+0.16010037j -1.1172493 +0.7748073j\n",
      "   -0.8909023 -0.03574862j  0.16404478-0.17641577j]\n",
      "  ...\n",
      "  [-0.16759732-0.6054775j   0.28272223-0.2474445j\n",
      "   -0.03771289+0.8060286j  -0.35887927+0.4151725j ]\n",
      "  [-1.0647324 +0.13704719j -0.99746686+0.15185735j\n",
      "   -1.0219169 -0.8521126j   0.20527622+0.8631279j ]\n",
      "  [ 0.3769181 -0.4343401j   0.9676978 +1.6530007j\n",
      "   -0.5047888 +1.589793j    0.692099  +0.12364984j]]\n",
      "\n",
      " [[-0.45520058+0.60051656j -0.11613375+0.15086955j\n",
      "   -0.46465027-0.5791605j   0.24424282+2.2634947j ]\n",
      "  [ 0.35086602+0.82284504j -0.6346    -0.60698354j\n",
      "    0.73251295+0.1238371j  -0.4514151 +0.34147403j]\n",
      "  [ 0.18894911-0.33402842j  0.66023153-0.34309003j\n",
      "   -0.15558074+0.90807956j -1.2998484 +1.037905j  ]\n",
      "  ...\n",
      "  [-0.95200634-0.17142355j  1.2890072 -0.45265204j\n",
      "   -0.79009223+0.04623677j -0.04365751-1.2453983j ]\n",
      "  [-0.5805038 +0.47901213j -0.5073962 +0.7223951j\n",
      "   -0.04781335+0.04681444j -0.13489805+0.27507198j]\n",
      "  [ 0.90787286-0.22249177j -0.12776965-1.2736357j\n",
      "    0.51698333-1.0195056j   0.19748226+0.8345062j ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.3504827 +0.65818286j -1.2799274 -1.0783912j\n",
      "   -0.7683469 -0.43462336j -0.45767966+0.58970696j]\n",
      "  [ 0.49896455+0.59569573j -0.4956412 +1.0570983j\n",
      "    0.6449413 -1.0454427j   1.8203    +1.2466846j ]\n",
      "  [ 0.21253116+0.33432755j  0.58483326+0.0823579j\n",
      "   -0.33624232-0.40921655j  0.03520089+1.3362987j ]\n",
      "  ...\n",
      "  [-0.3185644 -0.5393044j   0.18137337+0.21525335j\n",
      "    0.68860453-0.34955198j -0.10203208+0.3580961j ]\n",
      "  [-0.85062665-0.66048855j  0.16599204-0.8269364j\n",
      "    1.4819826 +0.7138624j   1.6073787 +0.80762285j]\n",
      "  [ 0.27966976-2.513037j   -0.24102163-0.02195356j\n",
      "   -0.40625334+0.27918753j  0.44940323-0.5345899j ]]\n",
      "\n",
      " [[ 0.61895174-0.3464509j  -0.804764  -0.72906965j\n",
      "   -1.4334726 +0.05716273j -0.33784154+1.333262j  ]\n",
      "  [-0.06726669+1.1804951j  -0.26846594-1.2130965j\n",
      "    0.16685334+1.4040694j  -0.06098498+0.43661264j]\n",
      "  [-0.16039859-0.26267633j  1.9007653 -0.24288476j\n",
      "    0.7902664 -0.51067406j -0.33670717+0.3242341j ]\n",
      "  ...\n",
      "  [-1.1662343 +0.28266746j  0.56842136+0.69268733j\n",
      "   -0.17432924-0.2639666j   0.14587094-0.27837035j]\n",
      "  [ 0.6722571 -0.49440473j -0.8219144 -0.12374986j\n",
      "   -0.55522776-0.2117025j   0.47759244-0.25176114j]\n",
      "  [ 0.11040144+0.5292954j   0.42072362+0.96741676j\n",
      "    0.05682142+0.6159406j   0.51401   +0.10966955j]]\n",
      "\n",
      " [[-0.7720596 +0.26721787j  0.4385211 -0.3080621j\n",
      "    0.10084855+0.10418357j  0.07847558+0.7735779j ]\n",
      "  [ 0.2003141 +0.624013j    0.08704434-0.3974101j\n",
      "    0.18426546-0.8340741j   1.1858749 +0.03579108j]\n",
      "  [-0.3645557 +0.4108567j   1.046996  -0.6458077j\n",
      "    0.3721212 -0.25138593j  0.16613396+0.88863003j]\n",
      "  ...\n",
      "  [ 0.28296986+1.0880635j  -1.0500168 -0.20304869j\n",
      "   -0.3768386 -1.3519056j  -0.9390552 +0.85090286j]\n",
      "  [ 0.02328013-0.5378241j  -0.4312452 +1.2336087j\n",
      "    0.07969272-1.4260607j   0.6487793 -0.26552296j]\n",
      "  [ 0.45050824-0.26634413j -0.351692  -0.29266766j\n",
      "    0.41096655+0.9900504j  -0.6247422 -1.2059103j ]]], shape=(4096, 16, 4), dtype=complex64)\n",
      "x reshape(app_chn) = (4096, 4, 1)\n",
      "noise shape = (4096, 16)\n"
     ]
    }
   ],
   "source": [
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from sionna.utils import expand_to_rank, complex_normal\n",
    "\n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "\n",
    "# from sionna.channel import AWGN\n",
    "from sionna.utils import complex_normal\n",
    "\n",
    "class AWGN(Layer):\n",
    "    def __init__(self, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._real_dtype = tf.dtypes.as_dtype(self._dtype).real_dtype\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x, no = inputs\n",
    "\n",
    "        # Create tensors of real-valued Gaussian noise for each complex dim.\n",
    "        noise = complex_normal(tf.shape(x), dtype=x.dtype)\n",
    "\n",
    "        # Add extra dimensions for broadcasting\n",
    "        no = expand_to_rank(no, tf.rank(x), axis=-1)\n",
    "\n",
    "        # Apply variance scaling\n",
    "        no = tf.cast(no, self._real_dtype)\n",
    "        noise *= tf.cast(tf.sqrt(no), noise.dtype)\n",
    "        print('noise shape =',noise.shape)\n",
    "        # Add noise to input\n",
    "        y = x + noise\n",
    "\n",
    "        return y\n",
    "\n",
    "class GenerateFlatFadingChannel():\n",
    "    def __init__(self, num_tx_ant, num_rx_ant, spatial_corr=None, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._dtype = dtype\n",
    "        self.spatial_corr = spatial_corr\n",
    " \n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._spatial_corr\n",
    " \n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._spatial_corr = value\n",
    " \n",
    "    def __call__(self, batch_size):\n",
    "        # Generate standard complex Gaussian matrices\n",
    "        shape = [batch_size, self._num_rx_ant, self._num_tx_ant]\n",
    "        h = complex_normal(shape, dtype=self._dtype)\n",
    " \n",
    "        # Apply spatial correlation\n",
    "        if self.spatial_corr is not None:\n",
    "            h = self.spatial_corr(h)\n",
    " \n",
    "        return h\n",
    "\n",
    "class ApplyFlatFadingChannel(tf.keras.layers.Layer):\n",
    "    def __init__(self, add_awgn=True, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "        self._add_awgn = add_awgn\n",
    " \n",
    "    def build(self, input_shape): #pylint: disable=unused-argument\n",
    "        if self._add_awgn:\n",
    "            self._awgn = AWGN(dtype=self.dtype)\n",
    " \n",
    "    def call(self, inputs):\n",
    "        if self._add_awgn:\n",
    "            x, h, no = inputs\n",
    "        else:\n",
    "            x, h = inputs\n",
    " \n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "        print('x reshape(app_chn) =',x.shape)\n",
    "        y = tf.matmul(h, x)\n",
    "        y = tf.squeeze(y, axis=-1)\n",
    " \n",
    "        if self._add_awgn:\n",
    "            y = self._awgn((y, no))\n",
    " \n",
    "        return y\n",
    "\n",
    "class FlatFadingChannel(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_tx_ant,\n",
    "                 num_rx_ant,\n",
    "                 spatial_corr=None,\n",
    "                 add_awgn=True,\n",
    "                 return_channel=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._add_awgn = add_awgn\n",
    "        self._return_channel = return_channel\n",
    "        self._gen_chn = GenerateFlatFadingChannel(self._num_tx_ant,\n",
    "                                                  self._num_rx_ant,\n",
    "                                                  spatial_corr,\n",
    "                                                  dtype=dtype)\n",
    "        self._app_chn = ApplyFlatFadingChannel(add_awgn=add_awgn, dtype=dtype)\n",
    " \n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._gen_chn.spatial_corr\n",
    " \n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._gen_chn.spatial_corr = value\n",
    " \n",
    "    @property\n",
    "    def generate(self):\n",
    "        \"\"\"Calls the internal :class:`GenerateFlatFadingChannel`.\"\"\"\n",
    "        return self._gen_chn\n",
    " \n",
    "    @property\n",
    "    def apply(self):\n",
    "        \"\"\"Calls the internal :class:`ApplyFlatFadingChannel`.\"\"\"\n",
    "        return self._app_chn\n",
    " \n",
    "    def call(self, inputs):\n",
    "        if self._add_awgn:\n",
    "            x, no = inputs\n",
    "        else:\n",
    "            x = inputs\n",
    " \n",
    "        # Generate a batch of channel realizations\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        print('batch_size =', batch_size)\n",
    "        h = self._gen_chn(batch_size)\n",
    "        print('h shape =',h.shape)\n",
    "        print('h =',h)\n",
    " \n",
    "        # Apply the channel to the input\n",
    "        if self._add_awgn:\n",
    "            y = self._app_chn([x, h, no])\n",
    "        else:\n",
    "            y = self._app_chn([x, h])\n",
    " \n",
    "        if self._return_channel:\n",
    "            return y, h\n",
    "        else:\n",
    "            return y\n",
    "\n",
    "no = 0.2\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 32 # Parallel in 32 Batches\n",
    "k = 512 # Message Bits\n",
    "NUM_RX_ANT = 16 # Receiver Antennas\n",
    "NUM_TX_ANT = 4 # Transmitter Antennas\n",
    "\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "\n",
    "y, h = flatfading_channel([x_reshape, no]) # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complex_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Layer\n",
    "def complex_normal(shape, var=1.0, dtype=tf.complex64):\n",
    "    # Half the variance for each dimension\n",
    "    var_dim = tf.cast(var, dtype.real_dtype)/tf.cast(2, dtype.real_dtype) # var_dim = 1/2\n",
    "    print('var_dim =',var_dim)\n",
    "    stddev = tf.sqrt(var_dim) # standard deviation = sqrt(variance) = sqrt(1/2) = 0.7071\n",
    "    print('stddev =',stddev)\n",
    " \n",
    "    # Generate complex Gaussian noise with the right variance\n",
    "    xr = tf.random.normal(shape, stddev=stddev, dtype=dtype.real_dtype)\n",
    "    xi = tf.random.normal(shape, stddev=stddev, dtype=dtype.real_dtype)\n",
    "    x = tf.complex(xr, xi)\n",
    "    print('x =',x)\n",
    " \n",
    "    return x\n",
    "\n",
    "shape = [4,3,2];\n",
    "cn = complex_normal(shape);\n",
    "print('cn shape=', cn.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# equalization\n",
    "# whiten_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# GPU Configuration and Imports\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "    \n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "# from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from sionna.utils import expand_to_rank, matrix_inv, matrix_pinv\n",
    "# from sionna.mimo.utils import whiten_channel\n",
    "from sionna.utils import matrix_sqrt_inv, expand_to_rank\n",
    "\n",
    "def whiten_channel(y, h, s, return_s=True):\n",
    "    # Compute whitening matrix\n",
    "    s_inv_1_2 = matrix_sqrt_inv(s)\n",
    "    s_inv_1_2 = expand_to_rank(s_inv_1_2, tf.rank(h), 0)\n",
    "\n",
    "    # Whiten obervation and channel matrix\n",
    "    yw = tf.expand_dims(y, -1)\n",
    "    yw = tf.matmul(s_inv_1_2, yw)\n",
    "    yw = tf.squeeze(yw, axis=-1)\n",
    "\n",
    "    hw = tf.matmul(s_inv_1_2, h)\n",
    "\n",
    "    if return_s:\n",
    "        # Ideal interference covariance matrix after whitening\n",
    "        sw = tf.eye(tf.shape(s)[-2], dtype=s.dtype)\n",
    "        sw = expand_to_rank(sw, tf.rank(s), 0)\n",
    "        return yw, hw, sw\n",
    "    else:\n",
    "        return yw, hw\n",
    "\n",
    "def lmmse_equalizer(y, h, s, whiten_interference=True):\n",
    "    if not whiten_interference:\n",
    "        # Compute G (G = H^H(HH^H + S}^-1).\n",
    "        print('H^H shape=',(np.linalg.pinv(h)).shape)\n",
    "        g = tf.matmul(h, h, adjoint_b=True) + s\n",
    "        print('H(H^H) shape=',(tf.matmul(h, h, adjoint_b=True)).shape)\n",
    "        print('H(H^H)+S shape=',g.shape)\n",
    "        print('(H(H^H)+S)^-1 shape',(matrix_inv(g)).shape)\n",
    "        g = tf.matmul(h, matrix_inv(g), adjoint_a=True)\n",
    "        print('H^H(H(H^H)+S)^-1 shape',g.shape)\n",
    "\n",
    "    else:\n",
    "        # Whiten channel\n",
    "        y, h  = whiten_channel(y, h, s, return_s=False) # type: ignore\n",
    "\n",
    "        # Compute G (G = ((H^H)H + i)^-1)H^H).\n",
    "        print('h =',h)\n",
    "        print('h^H =',np.linalg.pinv(h))\n",
    "        # print('h^H shape=',(np.linalg.pinv(h)).shape)\n",
    "        i = expand_to_rank(tf.eye(h.shape[-1], dtype=s.dtype), tf.rank(s), 0)\n",
    "        print('i =',i)\n",
    "        g = tf.matmul(h, h, adjoint_a=True) + i\n",
    "        print('(h^H)h =',tf.matmul(h, h, adjoint_a=True))\n",
    "        # print('(h^H)h shape=',(tf.matmul(h, h, adjoint_a=True)).shape)\n",
    "        print('(h^H)h+i =',g)\n",
    "        # print('(h^H)h+i shape=',g.shape)\n",
    "        print('((h^H)h+i)^-1 =',matrix_inv(g))\n",
    "        # print('((h^H)h+i)^-1 shape=',(matrix_inv(g)).shape)\n",
    "        g = tf.matmul(matrix_inv(g), h, adjoint_b=True)\n",
    "        print('(((h^H)h+i)^-1)h^H =',g)\n",
    "        # print('(((h^H)H+i)^-1)h^H shape=',g.shape)\n",
    "\n",
    "    # Compute Gy\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    gy = tf.squeeze(tf.matmul(g, y), axis=-1)\n",
    "\n",
    "    # Compute GH\n",
    "    gh = tf.matmul(g, h)\n",
    "\n",
    "    # Compute diag(GH)\n",
    "    d = tf.linalg.diag_part(gh)\n",
    "\n",
    "    # Compute x_hat (x_hat=(diag(GH)^-1)Gy)\n",
    "    x_hat = gy/d\n",
    "\n",
    "    # Compute residual error variance\n",
    "    one = tf.cast(1, dtype=d.dtype)\n",
    "    no_eff = tf.math.real(one/d - one)\n",
    "\n",
    "    return x_hat, no_eff\n",
    "\n",
    "def zf_equalizer(y, h, s):\n",
    "    # Compute G\n",
    "    g = matrix_pinv(h)\n",
    "\n",
    "    # Compute x_hat\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    x_hat = tf.squeeze(tf.matmul(g, y), axis=-1)\n",
    "\n",
    "    # Compute residual error variance\n",
    "    gsg = tf.matmul(tf.matmul(g, s), g, adjoint_b=True)\n",
    "    no_eff = tf.math.real(tf.linalg.diag_part(gsg))\n",
    "\n",
    "    return x_hat, no_eff\n",
    "\n",
    "def mf_equalizer(y, h, s):\n",
    "    # Compute G\n",
    "    hth = tf.matmul(h, h, adjoint_a=True)\n",
    "    d = tf.linalg.diag(tf.cast(1, h.dtype)/tf.linalg.diag_part(hth))\n",
    "    g = tf.matmul(d, h, adjoint_b=True)\n",
    "\n",
    "    # Compute x_hat\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    x_hat = tf.squeeze(tf.matmul(g, y), axis=-1)\n",
    "\n",
    "    # Compute residual error variance\n",
    "    gsg = tf.matmul(tf.matmul(g, s), g, adjoint_b=True)\n",
    "    gh = tf.matmul(g, h)\n",
    "    i = expand_to_rank(tf.eye(gsg.shape[-2], dtype=gsg.dtype), tf.rank(gsg), 0)\n",
    "\n",
    "    no_eff = tf.abs(tf.linalg.diag_part(tf.matmul(i-gh, i-gh, adjoint_b=True) + gsg))\n",
    "    return x_hat, no_eff\n",
    "\n",
    "# k = 512 # Block Length\n",
    "# no = 0.2 # Noise variance of the channel\n",
    "# NUM_TX_ANT = 4 # Transmit Antennas\n",
    "# NUM_RX_ANT = 16 # Receive Antennas\n",
    "# NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "# BATCH_SIZE = 8 # Parallelly Processed Batches\n",
    "# EBN0_DB_MIN = -30.0 # Minimum Eb/N0 [dB]\n",
    "# EBN0_DB_MAX = 10.0 # Maximum Eb/N0 [dB]\n",
    "# snrs = []\n",
    "# bers = []\n",
    "# sers_zf = []\n",
    "# sers_lmmse = []\n",
    "\n",
    "k = 8 # Block Length\n",
    "no = 0.2 # Noise variance of the channel\n",
    "NUM_TX_ANT = 2 # Transmit Antennas\n",
    "NUM_RX_ANT = 4 # Receive Antennas\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 1 # Parallelly Processed Batches\n",
    "EBN0_DB_MIN = -30.0 # Minimum Eb/N0 [dB]\n",
    "EBN0_DB_MAX = 10.0 # Maximum Eb/N0 [dB]\n",
    "snrs = []\n",
    "bers = []\n",
    "sers_zf = []\n",
    "sers_lmmse = []\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "\n",
    "# SymbolDemapper\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "\n",
    "y, h = flatfading_channel([x_reshape, no])\n",
    "print('y shape =',y.shape)\n",
    "# print('h =',h)\n",
    "print('h shape =',h.shape)\n",
    "\n",
    "s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "print('s =',s)\n",
    "print('tf.rank(s) =',tf.rank(s))\n",
    "\n",
    "x_hat_lmmse, no_eff_lmmse = lmmse_equalizer(y, h, s)\n",
    "print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "print('no_eff_lmmse shape =',no_eff_lmmse.shape)\n",
    "\n",
    "noise_var_eff_lmmse = np.var(x_reshape-x_hat_lmmse)\n",
    "noise_var_est_lmmse = np.mean(no_eff_lmmse)\n",
    "print('noise_var_eff_lmmse =',noise_var_eff_lmmse)\n",
    "print('noise_var_est_lmmse =',noise_var_est_lmmse)\n",
    "\n",
    "plt.axes().set_aspect(1.0)\n",
    "plt.scatter(np.real(x_hat_lmmse), np.imag(x_hat_lmmse))\n",
    "plt.scatter(np.real(x), np.imag(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SymbolDemapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna\n",
    "\n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer\n",
    "# from sionna.mapping import SymbolDemapper\n",
    "from sionna.mapping import Constellation, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "\n",
    "class SymbolDemapper(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._hard_out = hard_out\n",
    "        self._with_prior = with_prior\n",
    " \n",
    "        # Create constellation object\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=dtype)\n",
    " \n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            y, prior, no = inputs\n",
    "        else:\n",
    "            y, no = inputs\n",
    "\n",
    "        # print('y =',y)\n",
    "        # print('y shape=',y.shape)\n",
    "        # print('tf.rank(y) =',tf.rank(y))\n",
    "        # print('tf.rank(y)+1 =',(tf.rank(y)+1))\n",
    "        # print('self._constellation.points =',self._constellation.points)\n",
    "        points = sn.utils.expand_to_rank(self._constellation.points,\n",
    "                                tf.rank(y)+1, axis=0)\n",
    "        # print('points =',points)\n",
    "        # print('points shape=',points.shape)\n",
    "\n",
    "        y = tf.expand_dims(y, axis=-1)\n",
    "        # print('y =',y)\n",
    "        # print('y shape=',y.shape)\n",
    "        d = tf.abs(y-points)\n",
    "        # print('d =',d)\n",
    "        # print('d shape=',d.shape)\n",
    " \n",
    "        no = sn.utils.expand_to_rank(no, tf.rank(d), axis=-1)\n",
    "        # print('no =',no)\n",
    "        # print('no shape=',no.shape)\n",
    "        exp = -d**2 / no\n",
    "        print('exp =',exp)\n",
    "        # print('exp shape=',exp.shape)\n",
    " \n",
    "        if self._with_prior:\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(exp), axis=0)\n",
    "            exp = exp + prior\n",
    " \n",
    "        if self._hard_out:\n",
    "            # tf.argmax: Get the Index of the maximum value in a tensor at the last dimension (axis=-1)\n",
    "            print('tf.argmax(exp, axis=-1, output_type=tf.int32) =',tf.argmax(exp, axis=-1, output_type=tf.int32))\n",
    "            # print('tf.argmax(exp, axis=-1, output_type=tf.int32) shape=',(tf.argmax(exp, axis=-1, output_type=tf.int32)).shape)\n",
    "            return tf.argmax(exp, axis=-1, output_type=tf.int32)\n",
    "        else:\n",
    "            # print('tf.nn.log_softmax(exp, axis=-1) =',tf.nn.log_softmax(exp, axis=-1))\n",
    "            print('tf.nn.log_softmax(exp, axis=-1) shape=',(tf.nn.log_softmax(exp, axis=-1)).shape)\n",
    "            return tf.nn.log_softmax(exp, axis=-1)\n",
    "        \n",
    "num_tx_ant = 2\n",
    "num_rx_ant = 4\n",
    "num_bits_per_symbol = 4\n",
    "batch_size = 3\n",
    "qam_source = QAMSource(num_bits_per_symbol)\n",
    "x = qam_source([batch_size, num_tx_ant])\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "channel = FlatFadingChannel(num_tx_ant, num_rx_ant, add_awgn=True, return_channel=True)\n",
    "no = 0.2 # Noise variance of the channel\n",
    "\n",
    "# y and h are the channel output and channel realizations, respectively.\n",
    "y, h = channel([x, no])\n",
    "print('y shape =',y.shape)\n",
    "print('h shape =',h.shape)\n",
    "\n",
    "s = tf.cast(no*tf.eye(num_rx_ant, num_rx_ant), y.dtype)\n",
    "x_hat, no_eff = lmmse_equalizer(y, h, s)\n",
    "print('x_hat shape =',x_hat.shape)\n",
    "\n",
    "plt.axes().set_aspect(1.0)\n",
    "plt.scatter(np.real(x_hat), np.imag(x_hat));\n",
    "plt.scatter(np.real(x), np.imag(x));\n",
    "\n",
    "print('no_eff shape =',no_eff.shape)\n",
    "\n",
    "noise_var_eff = np.var(x-x_hat)\n",
    "noise_var_est = np.mean(no_eff)\n",
    "print('noise_var_eff =',noise_var_eff)\n",
    "print('noise_var_est =',noise_var_est)\n",
    "\n",
    "symbol_demapper = SymbolDemapper(\"qam\", num_bits_per_symbol, hard_out=True)\n",
    "\n",
    "# Get symbol indices for the transmitted symbols\n",
    "x_ind = symbol_demapper([x, no])\n",
    "\n",
    "# # Get symbol indices for the received soft-symbols\n",
    "# x_ind_hat = symbol_demapper([x_hat, no])\n",
    "\n",
    "# compute_ser(x_ind, x_ind_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp_corr_mat & KroneckerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# GPU Configuration and Imports\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "    \n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "# from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel import FlatFadingChannel, SpatialCorrelation\n",
    "# from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from sionna.utils import expand_to_rank, matrix_sqrt\n",
    "\n",
    "def exp_corr_mat(a, n, dtype=tf.complex64):\n",
    "\n",
    "    # Cast to desired output dtype and expand last dimension for broadcasting\n",
    "    a = tf.cast(a, dtype=dtype)\n",
    "    a = tf.expand_dims(a, -1)\n",
    " \n",
    "    # Check that a is valid\n",
    "    msg = \"The absolute value of the elements of `a` must be smaller than one\"\n",
    "    tf.debugging.assert_less(tf.abs(a), tf.cast(1, a.dtype.real_dtype), msg)\n",
    " \n",
    "    # Vector of exponents, adapt dtype and dimensions for broadcasting\n",
    "    exp = tf.range(0, n)\n",
    "    exp = tf.cast(exp, dtype=dtype)\n",
    "    exp = expand_to_rank(exp, tf.rank(a), 0)\n",
    " \n",
    "    # First column of R\n",
    "    col = tf.math.pow(a, exp)\n",
    " \n",
    "    # For a=0, one needs to remove the resulting nans due to 0**0=nan\n",
    "    cond = tf.math.is_nan(tf.math.real(col))\n",
    "    col = tf.where(cond, tf.ones_like(col), col)\n",
    " \n",
    "    # First row of R (equal to complex-conjugate of the first column)\n",
    "    row = tf.math.conj(col)\n",
    " \n",
    "    # Create Toeplitz operator\n",
    "    operator = tf.linalg.LinearOperatorToeplitz(col, row)\n",
    " \n",
    "    # Generate dense tensor from operator\n",
    "    r = operator.to_dense()\n",
    " \n",
    "    return r\n",
    "\n",
    "class KroneckerModel(SpatialCorrelation):\n",
    "    def __init__(self, r_tx=None, r_rx=None):\n",
    "        super().__init__()\n",
    "        self.r_tx = r_tx\n",
    "        self.r_rx = r_rx\n",
    " \n",
    "    @property\n",
    "    def r_tx(self):\n",
    "        return self._r_tx\n",
    " \n",
    "    @r_tx.setter\n",
    "    def r_tx(self, value):\n",
    "        self._r_tx = value\n",
    "        if self._r_tx is not None:\n",
    "            self._r_tx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_tx_sqrt = None\n",
    " \n",
    "    @property\n",
    "    def r_rx(self):\n",
    "        return self._r_rx\n",
    " \n",
    "    @r_rx.setter\n",
    "    def r_rx(self, value):\n",
    "        self._r_rx = value\n",
    "        if self._r_rx is not None:\n",
    "            self._r_rx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_rx_sqrt = None\n",
    " \n",
    "    def __call__(self, h):\n",
    "        if self._r_tx_sqrt is not None:\n",
    "            r_tx_sqrt = expand_to_rank(self._r_tx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(h, r_tx_sqrt, adjoint_b=True)\n",
    " \n",
    "        if self._r_rx_sqrt is not None:\n",
    "            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(r_rx_sqrt, h)\n",
    "        # print('h =',h)\n",
    "        return h\n",
    "\n",
    "k = 512 # Block Length\n",
    "no = 0.2 # Noise variance of the channel\n",
    "NUM_TX_ANT = 4 # Transmit Antennas\n",
    "NUM_RX_ANT = 4 # Receive Antennas\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 1024 # Parallelly Processed Batches\n",
    "EBN0_DB_MIN = -30.0 # Minimum Eb/N0 [dB]\n",
    "EBN0_DB_MAX = 10.0 # Maximum Eb/N0 [dB]\n",
    "snrs = []\n",
    "bers = []\n",
    "sers_zf = []\n",
    "sers_lmmse = []\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "\n",
    "# SymbolDemapper\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "x_ind = symbol_demapper([x, no])\n",
    "print('x_ind shape',x_ind.shape)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "\n",
    "# Adding Spatial Correlation\n",
    "# Create transmit and receive correlation matrices\n",
    "r_tx = exp_corr_mat(0.1, NUM_TX_ANT)\n",
    "r_rx = exp_corr_mat(0.1, NUM_RX_ANT)\n",
    "print('r_tx =',r_tx)\n",
    "print('r_rx =',r_rx)\n",
    "\n",
    "# Add the spatial correlation model to the channel\n",
    "flatfading_channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "\n",
    "y, h = flatfading_channel([x_reshape, no])\n",
    "print('y shape =',y.shape)\n",
    "# print('h =',h)\n",
    "print('h shape =',h.shape)\n",
    "\n",
    "# Compute empirical covariance matrices\n",
    "r_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/NUM_RX_ANT\n",
    "r_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/NUM_TX_ANT\n",
    "\n",
    "# Test that the empirical results match the theory\n",
    "assert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\n",
    "assert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n",
    "\n",
    "s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "\n",
    "x_hat_lmmse, no_eff_lmmse = lmmse_equalizer(y, h, s)\n",
    "print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "print('no_eff_lmmse shape =',no_eff_lmmse.shape)\n",
    "\n",
    "# Confirm the correctness of estimate x by comparing \n",
    "# the average estimated effective noise variance between \n",
    "# the transmitted and equalized symbols.\n",
    "noise_var_eff_lmmse = np.var(x_reshape-x_hat_lmmse)\n",
    "noise_var_est_lmmse = np.mean(no_eff_lmmse)\n",
    "# print('noise_var_eff_lmmse =',noise_var_eff_lmmse)\n",
    "# print('noise_var_est_lmmse =',noise_var_est_lmmse)\n",
    "\n",
    "x_hat_lmmse = tf.reshape(x_hat_lmmse, shape)\n",
    "\n",
    "x_ind_hat_lmmse = symbol_demapper([x_hat_lmmse, no])\n",
    "print('x_ind_hat_lmmse shape',x_ind_hat_lmmse.shape)\n",
    "\n",
    "print('SER =',compute_ser(x_ind, x_ind_hat_lmmse))\n",
    "\n",
    "plt.axes().set_aspect(1.0)\n",
    "plt.scatter(np.real(x_hat_lmmse), np.imag(x_hat_lmmse))\n",
    "plt.scatter(np.real(x), np.imag(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepImagePrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 19:16:43.474781: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 0\n",
      "b shape = (1, 4, 8)\n",
      "b = tf.Tensor(\n",
      "[[[1. 0. 0. 1. 1. 1. 0. 1.]\n",
      "  [1. 0. 0. 1. 0. 0. 1. 1.]\n",
      "  [1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "  [0. 1. 0. 0. 1. 0. 0. 1.]]], shape=(1, 4, 8), dtype=float32)\n",
      "x shape = (1, 4, 2)\n",
      "x = tf.Tensor(\n",
      "[[[-0.3162278+0.9486833j -0.3162278-0.9486833j]\n",
      "  [-0.3162278+0.9486833j  0.9486833+0.9486833j]\n",
      "  [-0.9486833+0.3162278j -0.9486833-0.9486833j]\n",
      "  [ 0.3162278-0.3162278j -0.3162278+0.9486833j]]], shape=(1, 4, 2), dtype=complex64)\n",
      "x reshape = (2, 4)\n",
      "TX_ANT_CORRELATION_INDEX = 0.1\n",
      "RX_ANT_CORRELATION_INDEX = 0.1\n",
      "h.shape =\n",
      " (2, 16, 4)\n",
      "y.shape =\n",
      " (2, 16)\n",
      "Y shape= (2, 16)\n",
      "Y = tf.Tensor(\n",
      "[[  3.979923   -1.2577324j    8.067277   -3.955019j\n",
      "    4.655363   +6.46085j      3.1919937  -5.1065345j\n",
      "   -2.430389   +7.1592674j   -0.04395366 +3.9714246j\n",
      "  -19.785105  -12.086312j    -8.703782   +4.2686114j\n",
      "   -0.02105239 +6.463314j     2.8954153  -9.718775j\n",
      "    2.9155006  +5.7738156j  -12.098549   -5.8574195j\n",
      "    9.164595   +1.0592384j   10.834409   -8.361681j\n",
      "    2.523401   -1.3651795j   -8.259767  +19.141478j  ]\n",
      " [  5.748241  +16.030458j     1.9299939  -8.878938j\n",
      "    1.6955953 -11.479931j    -3.719088   -2.189886j\n",
      "    0.7724427  -5.819427j     3.6103694  -0.6577479j\n",
      "    9.241739   +0.48185992j  -3.830353   -0.53976893j\n",
      "    6.041432   +0.26964545j -11.782206   +7.738495j\n",
      "    6.3264503  +8.831793j     0.4515128  +4.49879j\n",
      "    1.0969795 -10.600309j    -3.2755938  +0.40453494j\n",
      "    5.66591    -0.91411066j   3.0041075  -2.234287j  ]], shape=(2, 16), dtype=complex64)\n",
      "H shape= (2, 16, 4)\n",
      "H = tf.Tensor(\n",
      "[[[-0.7343505 +0.17998466j -0.4443169 -1.6453273j\n",
      "   -1.6152505 -1.5198717j  -0.66618884+1.9847796j ]\n",
      "  [ 1.4201188 -0.25535408j -1.1380517 -0.8821775j\n",
      "   -1.0003704 -0.46576977j  0.8560566 -0.09793015j]\n",
      "  [-0.41432178-0.2580635j  -1.5771072 -0.10496606j\n",
      "   -0.17241052-0.19568631j  1.1381124 -0.2473832j ]\n",
      "  [-0.50090295-0.07018991j  0.02537499-0.15658395j\n",
      "    0.19652444-0.96873504j -0.04940052-0.16681203j]\n",
      "  [-0.01342029+0.4575927j  -0.648062  +0.45291945j\n",
      "    0.725005  -0.30236426j  0.13097401+0.68602693j]\n",
      "  [ 0.2112347 -0.81555575j -1.1826233 +1.1372958j\n",
      "   -1.0890459 -0.30893415j  0.14211234+0.5234777j ]\n",
      "  [-0.3157057 +0.9633734j   0.37827885-0.28796062j\n",
      "    0.5227672 +0.02677158j  0.65545034+0.6309772j ]\n",
      "  [-0.03771867+0.10668264j  0.19550262+0.39627454j\n",
      "   -0.21010649-0.83806616j  0.19645737+0.7670349j ]\n",
      "  [ 1.3414426 -1.0356622j  -0.15442589-0.26914364j\n",
      "   -0.7762739 -0.11140464j -0.9040986 -0.39853767j]\n",
      "  [ 0.46334597-0.09274535j  0.10105816-0.13001087j\n",
      "   -1.2322748 +0.898309j   -1.0135455 -1.1418891j ]\n",
      "  [ 0.04438362-0.14440353j -0.17961405-0.04960788j\n",
      "    1.0226427 +0.64113903j  0.71694785-0.86396897j]\n",
      "  [ 1.3188994 -0.52989465j -0.12375493-0.03456305j\n",
      "    0.16006951+0.39652765j  0.36778465+1.3121349j ]\n",
      "  [ 0.03413161-0.78403723j -0.13965216+1.0208662j\n",
      "    2.0181935 -0.19205013j  0.76908636-0.5543625j ]\n",
      "  [ 0.12511344+1.4749348j   0.21264382+0.6574627j\n",
      "   -1.0680743 +0.5140386j  -0.29833114-0.52414566j]\n",
      "  [ 0.43274614+1.2634754j   0.67013806-0.14981441j\n",
      "   -0.24748407-0.24386092j -0.37788153-0.24953558j]\n",
      "  [-0.3169691 -0.069906j   -1.342051  +0.6034453j\n",
      "   -0.24698864-0.86562955j -0.35747802+0.52736974j]]\n",
      "\n",
      " [[ 0.48629147-0.31094444j  1.4756799 +1.646348j\n",
      "    0.88403845-0.949008j   -0.12374974+0.08940354j]\n",
      "  [ 0.15515128-0.30548427j -0.8126419 -1.0507283j\n",
      "    0.7847277 +0.6290003j   0.29027325+0.66909385j]\n",
      "  [ 0.8540365 -0.5861757j  -0.18993819+0.82724047j\n",
      "    0.49685723-1.3782796j  -0.8347571 +1.447276j  ]\n",
      "  [ 0.45895597+0.28699255j -0.5664751 -0.18366995j\n",
      "   -0.36034334-1.2398514j   0.53021705+0.12281051j]\n",
      "  [-0.04534743+1.1212554j  -0.1967602 -0.80995935j\n",
      "   -0.7019759 +0.8377493j   0.11048856-0.04192101j]\n",
      "  [-0.63811904+1.0399168j   0.08319441-0.6124954j\n",
      "   -0.91062903-0.6258698j   0.70286465+0.39252928j]\n",
      "  [ 0.03681339-0.2042739j   0.9577442 +0.01797128j\n",
      "   -0.19438699-0.01220778j -0.13298887-0.7791391j ]\n",
      "  [ 0.02765553-0.92958605j  0.60229415-1.1651543j\n",
      "    1.5461931 +0.6111035j   1.5370741 -0.41961005j]\n",
      "  [-0.8208712 -1.7307677j   0.02909848-1.2222726j\n",
      "    1.4328605 -0.5912541j   0.5469095 -1.3942208j ]\n",
      "  [ 0.29313776-1.1686423j   0.00604602+0.1697823j\n",
      "   -0.16465639+0.01479224j  1.0303185 -1.142019j  ]\n",
      "  [ 1.2052776 -0.00373182j  0.06840091+0.591492j\n",
      "   -0.66260326-0.00569433j  0.7325783 +1.1110339j ]\n",
      "  [ 0.837062  +0.22381818j -0.49247706+0.5135241j\n",
      "    0.45565844-1.8872387j   0.76572746-0.06856342j]\n",
      "  [ 0.24456216+0.6687299j   0.9093613 +0.74608016j\n",
      "    0.16835009+0.8713473j   2.191259  +0.18187615j]\n",
      "  [ 1.2861897 -0.09730271j -1.0018628 +0.83059156j\n",
      "    0.5905898 -0.7063204j   0.4611737 +0.53852195j]\n",
      "  [ 0.19814198+0.9196466j   0.25647902-0.35695446j\n",
      "   -0.03093316-0.04484797j  0.8037797 +0.8280128j ]\n",
      "  [ 0.5084815 +0.00777614j  0.8157807 +0.49538037j\n",
      "    0.8187691 +0.01312153j -0.5563833 +0.15482336j]]], shape=(2, 16, 4), dtype=complex64)\n",
      "y_torch = tensor([[[[  3.9799],\n",
      "          [  8.0673],\n",
      "          [  4.6554],\n",
      "          [  3.1920],\n",
      "          [ -2.4304],\n",
      "          [ -0.0440],\n",
      "          [-19.7851],\n",
      "          [ -8.7038],\n",
      "          [ -0.0211],\n",
      "          [  2.8954],\n",
      "          [  2.9155],\n",
      "          [-12.0985],\n",
      "          [  9.1646],\n",
      "          [ 10.8344],\n",
      "          [  2.5234],\n",
      "          [ -8.2598]]]])\n",
      "H_torch = tensor([[[[-0.7344, -0.4443, -1.6153, -0.6662],\n",
      "          [ 1.4201, -1.1381, -1.0004,  0.8561],\n",
      "          [-0.4143, -1.5771, -0.1724,  1.1381],\n",
      "          [-0.5009,  0.0254,  0.1965, -0.0494],\n",
      "          [-0.0134, -0.6481,  0.7250,  0.1310],\n",
      "          [ 0.2112, -1.1826, -1.0890,  0.1421],\n",
      "          [-0.3157,  0.3783,  0.5228,  0.6555],\n",
      "          [-0.0377,  0.1955, -0.2101,  0.1965],\n",
      "          [ 1.3414, -0.1544, -0.7763, -0.9041],\n",
      "          [ 0.4633,  0.1011, -1.2323, -1.0135],\n",
      "          [ 0.0444, -0.1796,  1.0226,  0.7169],\n",
      "          [ 1.3189, -0.1238,  0.1601,  0.3678],\n",
      "          [ 0.0341, -0.1397,  2.0182,  0.7691],\n",
      "          [ 0.1251,  0.2126, -1.0681, -0.2983],\n",
      "          [ 0.4327,  0.6701, -0.2475, -0.3779],\n",
      "          [-0.3170, -1.3421, -0.2470, -0.3575]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/im/Documents/GitHub/sionna/Jupyter Notebooks/xyDIP.py:105: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686209/work/aten/src/ATen/native/Copy.cpp:276.)\n",
      "  y_torch = torch.from_numpy((Y[bs]).numpy()).reshape(1, 1, self.user_num, 1).type(dtype)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [1, 8].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 233\u001b[0m\n\u001b[1;32m    230\u001b[0m x_hat_lmmse, no_eff_lmmse \u001b[39m=\u001b[39m lmmse_equalizer(y, h, s)\n\u001b[1;32m    231\u001b[0m \u001b[39m# print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m x_dip_ay,num_stop_point \u001b[39m=\u001b[39m dip\u001b[39m.\u001b[39;49mDIP(y,h)\n\u001b[1;32m    234\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx_dip_ay.shape =\u001b[39m\u001b[39m'\u001b[39m,x_dip_ay\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    235\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx_dip_ay =\u001b[39m\u001b[39m'\u001b[39m,x_dip_ay)\n",
      "File \u001b[0;32m~/Documents/GitHub/sionna/Jupyter Notebooks/xyDIP.py:133\u001b[0m, in \u001b[0;36mDeepImagePrior.DIP\u001b[0;34m(self, Y, H)\u001b[0m\n\u001b[1;32m    131\u001b[0m out1 \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtype(dtype) \u001b[39m# Tx * Block Length=(4)*(2)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# print('out1 shape =',out1.shape)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m Y_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(H_torch,out1)\u001b[39m.\u001b[39mtype(dtype)\n\u001b[1;32m    134\u001b[0m total_loss \u001b[39m=\u001b[39m mse(Y_hat,y_torch)\n\u001b[1;32m    135\u001b[0m total_loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [1, 8]."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from myDIP import DeepImagePrior, Decoder, EarlyStop\n",
    "\n",
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# GPU Configuration and Imports\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "    \n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from xyDIP import DeepImagePrior\n",
    "\n",
    "k = 8 # Block Length：512\n",
    "# no = 0.2 # Noise variance of the channel\n",
    "NUM_TX_ANT = 4 # Transmit Antennas\n",
    "NUM_RX_ANT = 16 # Receive Antennas\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 1 # Parallelly Processed Batches: 32\n",
    "EBN0_DB_MIN = -25.0 # Minimum Eb/N0 [dB]\n",
    "EBN0_DB_MAX = 25.0 # Maximum Eb/N0 [dB]\n",
    "TX_ANT_CORRELATION_INDEX = 0\n",
    "RX_ANT_CORRELATION_INDEX = 0\n",
    "CORRELATION_INDEX_MIN = 0.1\n",
    "CORRELATION_INDEX_MAX = 0.9\n",
    "snrs = np.linspace(EBN0_DB_MIN,EBN0_DB_MAX,51)\n",
    "# print('snrs[25] =',snrs[25])\n",
    "bers = []\n",
    "sers_zf = np.zeros((9, 51))\n",
    "sers_lmmse = np.zeros((9, 51))\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "\n",
    "# SymbolDemapper\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "\n",
    "# Deep Image Prior\n",
    "dip = DeepImagePrior(user_num=NUM_RX_ANT,      # Number of transmitted symbol in real domain\n",
    "                    M=16,              # Modulation order, 4 for 4QAM, 16 for 16QAM; 16QAM: 4 bits per symbol\n",
    "                    iteration=100,    # Number of max iterations used for DIP: 100\n",
    "                    LR=0.01,          # Learning rate,  typically set to 0.01\n",
    "                    buffer_size=30,   # Iterations stored,  typically set to 30\n",
    "                    threshold=0.001,  # Threshold of DIP stop,, typically set to 0.001\n",
    "                    stop=True)        # True\n",
    "\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "print('b =',b)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "print('x =',x)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "# print('x_reshape =',x_reshape)\n",
    "\n",
    "# Tx_Symbols = bits2symbol(b,NUM_BITS_PER_SYMBOL)\n",
    "# print('Tx_Symbols =',Tx_Symbols)\n",
    "\n",
    "# # Adding Spatial Correlation\n",
    "# # Create transmit and receive correlation matrices\n",
    "# r_tx = exp_corr_mat(TX_ANT_CORRELATION_INDEX, NUM_TX_ANT)\n",
    "# r_rx = exp_corr_mat(RX_ANT_CORRELATION_INDEX, NUM_RX_ANT)\n",
    "# # print('r_tx =',r_tx)\n",
    "# # print('r_rx =',r_rx)\n",
    "\n",
    "# # Add the spatial correlation model to the channel\n",
    "# flatfading_channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "\n",
    "for TX_ANT_CORRELATION_INDEX in np.linspace(CORRELATION_INDEX_MIN,CORRELATION_INDEX_MAX,3):\n",
    "    r_tx = exp_corr_mat(TX_ANT_CORRELATION_INDEX, NUM_TX_ANT)\n",
    "    for RX_ANT_CORRELATION_INDEX in np.linspace(CORRELATION_INDEX_MIN,CORRELATION_INDEX_MAX,3):\n",
    "        print('TX_ANT_CORRELATION_INDEX =',TX_ANT_CORRELATION_INDEX)\n",
    "        print('RX_ANT_CORRELATION_INDEX =',RX_ANT_CORRELATION_INDEX)\n",
    "        r_rx = exp_corr_mat(RX_ANT_CORRELATION_INDEX, NUM_RX_ANT)\n",
    "        flatfading_channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "        if i == 0:\n",
    "            LINE_COLOR_ZF = 'red'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'lawngreen'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "        elif i == 1:\n",
    "            LINE_COLOR_ZF = 'orange'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'deepskyblue'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '-.'\n",
    "        elif i == 2:\n",
    "            LINE_COLOR_ZF = 'chocolate'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'dodgerblue'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "        elif i == 3:\n",
    "            LINE_COLOR_ZF = 'goldenrod'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'darkorchid'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '-.'\n",
    "        elif i == 4:\n",
    "            LINE_COLOR_ZF = 'springgreen'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'fuchsia'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "        elif i == 5:\n",
    "            LINE_COLOR_ZF = 'black'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'gold'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '-.'\n",
    "        elif i == 6:\n",
    "            LINE_COLOR_ZF = 'brown'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'darkcyan'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "        elif i == 7:\n",
    "            LINE_COLOR_ZF = 'darkorange'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'crimson'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '-.'\n",
    "        else:\n",
    "            LINE_COLOR_ZF = 'olive'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'lightcoral'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "\n",
    "        for EBN0_DB in np.linspace(EBN0_DB_MIN,EBN0_DB_MAX,1): # 51\n",
    "\n",
    "            # snrs += [EBN0_DB]\n",
    "\n",
    "            no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                                    num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                                    coderate=1.0) # Coderate set to 1 as we do uncoded transmission here\n",
    "            # print('no =',no)\n",
    "\n",
    "            x_ind = symbol_demapper([x, no])\n",
    "            # print('x_ind.shape =',x_ind.shape)\n",
    "            # print('x_ind =',x_ind)\n",
    "\n",
    "            # y and h are the Channel Output and Channel Realizations, respectively.\n",
    "            y, h = flatfading_channel([x_reshape, no])\n",
    "            print('h.shape =\\n',h.shape)\n",
    "            # print('h =',h)\n",
    "            print('y.shape =\\n',y.shape)\n",
    "            # print('y =',y)\n",
    "\n",
    "            # Compute empirical covariance matrices\n",
    "            r_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/NUM_RX_ANT\n",
    "            r_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/NUM_TX_ANT\n",
    "\n",
    "            # # Test that the empirical results match the theory\n",
    "            # assert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\n",
    "            # assert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n",
    "\n",
    "            s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "\n",
    "            x_hat_zf, no_eff_zf = zf_equalizer(y, h, s)\n",
    "            # print('x_hat_zf.shape =',x_hat_zf.shape)\n",
    "            x_hat_lmmse, no_eff_lmmse = lmmse_equalizer(y, h, s)\n",
    "            # print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "\n",
    "            x_dip_ay,num_stop_point = dip.DIP(y,h)\n",
    "            print('x_dip_ay.shape =',x_dip_ay.shape)\n",
    "            print('x_dip_ay =',x_dip_ay)\n",
    "            print('num_stop_point =',num_stop_point)\n",
    "\n",
    "            # Confirm the correctness of estimate x by comparing \n",
    "            # the average estimated effective noise variance between \n",
    "            # the transmitted and equalized symbols.\n",
    "            noise_var_eff_zf = np.var(x_reshape-x_hat_zf)\n",
    "            noise_var_est_zf = np.mean(no_eff_zf)\n",
    "            noise_var_eff_lmmse = np.var(x_reshape-x_hat_lmmse)\n",
    "            noise_var_est_lmmse = np.mean(no_eff_lmmse)\n",
    "            # print('noise_var_eff_lmmse =',noise_var_eff_lmmse)\n",
    "            # print('noise_var_est_lmmse =',noise_var_est_lmmse)\n",
    "\n",
    "            x_hat_zf = tf.reshape(x_hat_zf, shape)\n",
    "            # print('x_hat_zf.shape =',x_hat_zf.shape)\n",
    "            x_hat_lmmse = tf.reshape(x_hat_lmmse, shape)\n",
    "            # print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "\n",
    "            no_eff_zf = tf.reshape(no_eff_zf, shape)\n",
    "            # print('no_eff_zf.shape =',no_eff_zf.shape)\n",
    "            no_eff_lmmse = tf.reshape(no_eff_lmmse, shape)\n",
    "            # print('no_eff_lmmse.shape =',no_eff_lmmse.shape)\n",
    "\n",
    "            # llr_zf = demapper([x_hat_zf, no_eff_zf])\n",
    "            # b_hat_zf = decoder(llr_zf)\n",
    "\n",
    "            x_ind_hat_zf = symbol_demapper([x_hat_zf, no_eff_zf])\n",
    "            # print('x_ind_hat_zf.shape =',x_ind_hat_zf.shape)\n",
    "            # print('x_ind_hat_zf =',x_ind_hat_zf)\n",
    "            x_ind_hat_lmmse = symbol_demapper([x_hat_lmmse, no_eff_lmmse])\n",
    "            # print('x_ind_hat_lmmse.shape =',x_ind_hat_lmmse.shape)\n",
    "\n",
    "            ser_zf = compute_ser(x_ind, x_ind_hat_zf)\n",
    "            ser_lmmse = compute_ser(x_ind, x_ind_hat_lmmse)\n",
    "            # sers_zf += [ser_zf]\n",
    "            # sers_lmmse += [ser_lmmse]\n",
    "            sers_zf[i][j] = ser_zf\n",
    "            sers_lmmse[i][j] = ser_lmmse\n",
    "            j = j + 1\n",
    "        \n",
    "        j = 0 \n",
    "        # print(snrs)\n",
    "        # print(sers_zf[i])\n",
    "        # print(sers_lmmse[i])\n",
    "        # print('snrs shape =',len(snrs))\n",
    "        # print('sers_zf shape=',len(sers_zf))\n",
    "        # print('sers_lmmse shape=',len(sers_lmmse))\n",
    "        plt.rcParams['figure.figsize']=(10,10)\n",
    "        plt.semilogy(snrs, sers_zf[i], color = LINE_COLOR_ZF, linestyle = LINE_STYLE_ZF, \\\n",
    "                     label='ZF ({},{})'.format(TX_ANT_CORRELATION_INDEX,RX_ANT_CORRELATION_INDEX))\n",
    "        plt.semilogy(snrs, sers_lmmse[i], color = LINE_COLOR_LMMSE, linestyle = LINE_STYLE_LMMSE, \\\n",
    "                     label='LMMSE ({},{})'.format(TX_ANT_CORRELATION_INDEX,RX_ANT_CORRELATION_INDEX))\n",
    "        # plt.text(snrs[25], sers_zf[i][25], '({},{}).format(TX_ANT_CORRELATION_INDEX,RX_ANT_CORRELATION_INDEX)', \\\n",
    "        #          fontsize=8, color = \"r\", style = \"italic\", weight = \"light\", verticalalignment='center', \\\n",
    "        #          horizontalalignment='right', rotation=90)\n",
    "        plt.scatter(snrs[25], sers_zf[i][25], marker='o', color='red')\n",
    "        plt.scatter(snrs[25], sers_lmmse[i][25], marker='o', color='green')\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        plt.legend(handles[::-1], labels[::-1], loc='lower left', fontsize=10)\n",
    "        i = i + 1\n",
    "title = \"SER: Uncoded MIMO with ZF,MMSE\"\n",
    "xlabel = \"$E_b/N_0$ (dB)\"\n",
    "ylabel = \"SER\"\n",
    "plt.title(title, fontsize=15)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel(ylabel, fontsize=15)\n",
    "plt.grid(which=\"both\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder Debug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constellation = [-0.70710678  0.70710678]\n",
      "net_input = tensor([[-0.6823,  0.1965, -0.1067,  0.8085]])\n",
      "x = tensor([[-0.6823,  0.1965, -0.1067,  0.8085]])\n",
      "nn1 = tensor([[ 0.1597, -0.3540, -0.2885, -0.7414,  0.2953,  0.1158,  0.2866,  0.5733]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "o1 = tensor([[ 0.1584, -0.3399, -0.2808, -0.6300,  0.2870,  0.1152,  0.2790,  0.5178]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "nn2 = tensor([[ 0.0026, -0.0246,  0.0367,  0.4040,  0.0383,  0.3631, -0.0752, -0.1903,\n",
      "          0.2346,  0.6832, -0.3954,  0.1268, -0.2634,  0.3085, -0.1021,  0.1200]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "o2 = tensor([[ 0.0026, -0.0246,  0.0367,  0.3833,  0.0383,  0.3479, -0.0751, -0.1881,\n",
      "          0.2304,  0.5936, -0.3760,  0.1261, -0.2574,  0.2991, -0.1018,  0.1194]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "nn3 = tensor([[-0.0105, -0.2657,  0.0159, -0.3150,  0.0316,  0.0507, -0.1769,  0.1651,\n",
      "         -0.1346,  0.0509,  0.2669,  0.1090, -0.2130, -0.1471, -0.0518, -0.2691,\n",
      "         -0.0928, -0.0916, -0.2771, -0.2713, -0.0297,  0.0503,  0.3862, -0.0244,\n",
      "          0.1895, -0.1879, -0.2781,  0.1211, -0.0517,  0.3379, -0.1228,  0.0984]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "o3 = tensor([[-0.0105, -0.2596,  0.0159, -0.3050,  0.0316,  0.0507, -0.1751,  0.1636,\n",
      "         -0.1338,  0.0509,  0.2607,  0.1086, -0.2099, -0.1460, -0.0518, -0.2628,\n",
      "         -0.0925, -0.0913, -0.2702, -0.2648, -0.0297,  0.0502,  0.3681, -0.0244,\n",
      "          0.1873, -0.1858, -0.2711,  0.1205, -0.0516,  0.3256, -0.1222,  0.0981]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "nn4 = tensor([[ 0.0810, -0.0409, -0.0118, -0.1327,  0.0320, -0.0612,  0.3484,  0.1243,\n",
      "         -0.1946,  0.0845, -0.2314, -0.0361, -0.3657, -0.0239, -0.1938,  0.0437]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "o4 = tensor([[ 0.0809, -0.0409, -0.0118, -0.1319,  0.0319, -0.0611,  0.3350,  0.1236,\n",
      "         -0.1922,  0.0843, -0.2273, -0.0361, -0.3503, -0.0239, -0.1914,  0.0437]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "net_output shape = torch.Size([1, 16])\n",
      "net_output = tensor([[ 0.0809, -0.0409, -0.0118, -0.1319,  0.0319, -0.0611,  0.3350,  0.1236,\n",
      "         -0.1922,  0.0843, -0.2273, -0.0361, -0.3503, -0.0239, -0.1914,  0.0437]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "max_constellation = 0.7071067811865475\n",
      "out shape = torch.Size([1, 16])\n",
      "out1 shape = torch.Size([1, 1, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,user_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nn1 = nn.Linear(4,8) # Define numbers of input (4) and output (8) of fully connected layer\n",
    "                                  # Weight.shape = (number of output (8),number of input (4))\n",
    "                                  # Bias.shape = number of output (8)\n",
    "        self.nn2 = nn.Linear(8,16)\n",
    "        self.nn3 = nn.Linear(16,32)\n",
    "        self.nn4 = nn.Linear(32,user_num)\n",
    "        self.act = nn.Tanh() # Define Activation Function: Tanh()\n",
    "         \n",
    "    def forward(self,x):\n",
    "        print('x =', x)\n",
    "        nn1 = self.nn1(x)\n",
    "        print('nn1 =', nn1)\n",
    "        o1 = self.act(nn1)\n",
    "        print('o1 =', o1)\n",
    "        nn2 = self.nn2(o1)\n",
    "        print('nn2 =', nn2)\n",
    "        o2 = self.act(nn2)\n",
    "        print('o2 =', o2)\n",
    "        nn3 = self.nn3(o2)\n",
    "        print('nn3 =', nn3)\n",
    "        o3 = self.act(nn3)\n",
    "        print('o3 =', o3)\n",
    "        nn4 = self.nn4(o3)\n",
    "        print('nn4 =', nn4)\n",
    "        o4 = self.act(nn4)\n",
    "        print('o4 =', o4)\n",
    "        return o4\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters() \n",
    "\n",
    "LR = 0.01\n",
    "M = 6\n",
    "constellation = np.linspace(int(-np.sqrt(M) + 1), int(np.sqrt(M) - 1), int(np.sqrt(M)))\n",
    "alpha = np.sqrt((constellation ** 2).mean())\n",
    "constellation /= (alpha * np.sqrt(2))\n",
    "print('constellation =', constellation)\n",
    "\n",
    "user_num = 16\n",
    "dtype = torch.FloatTensor\n",
    "net = Decoder(user_num).type(dtype)\n",
    "# for param in net.parameters():\n",
    "#     print(param)\n",
    "mse = torch.nn.MSELoss().type(dtype)        ###Loss function\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr= LR)     ###Adam optimizer\n",
    "WR = weight_reset\n",
    "# net.apply(WR)\n",
    "# for param in net.parameters():\n",
    "#     print(param)\n",
    "net_input = torch.randn(1,4)\n",
    "print('net_input =', net_input)\n",
    "\n",
    "net_output = net(net_input).type(dtype)\n",
    "print('net_output shape =', net_output.shape)\n",
    "print('net_output =', net_output)\n",
    "max_constellation= np.max(constellation)\n",
    "print('max_constellation =', max_constellation)\n",
    "out = net_output*max_constellation\n",
    "print('out shape =', out.shape)\n",
    "out1 = out.reshape(1,1,user_num,1).type(dtype)\n",
    "print('out1 shape =', out1.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAHBCAYAAACYFepwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHIklEQVR4nO3deXhbZ533/4+8x05sWdnaJE6b42zdWy+lQMsWOW3ZCq3dwAADA9ga5hkGaMEiMAxkHsC1WX/MUHDCVngGSCT2aaGxCi2FFupYTbqniY/TpNkTWbETx7Zs6/eHIzWO7cSLrKPl/bouX63kY+mrbxT5k/vc575t4XA4LAAAgCSTYXUBAAAAU0GIAQAASYkQAwAAkhIhBgAAJCVCDAAASEqEGAAAkJQIMQAAICkRYgAAQFIixADTtHHjRpWXl8tms6m0tFQ1NTUyTTP6/fLycrlcLgsrvHANfr9fNpttwo/ndrtls9nk8/liUZ6k+PQpXn8WTU1NstlsY3653e4Zf/7xJMJ7EYilLKsLAJJZU1OTGhoatGnTJpWVlck0TXk8Hvl8PtXV1UmS1q9fL7vdbmmdsa5h48aNMgxDHo9HTqczJo8Zjz7F68/i+PHjstvt6ujoGPU9K98LifBeBGIqDGDKJIU9Ho/VZUxbW1tbeKIfB21tbWHDMMLNzc1hu90+6edqaWkJG4Yx6Z9LtOc4n/r6+in1Jlasfv1AvHA6CZimdPuXbXNzs5xOp5xOp4LBYExPKQHAZBBigGlwOp1yuVzn/UVeVVU1Yh5EMBhUTU2NiouLVV5eLrfbrdLSUpWXl0uSampq1NTUJJfLpeLiYpWWlsrn88nn86m0tFQ2m001NTWjnifyOMXFxaPmPYxVQ1VVlWw2m8rLyycVRLZs2aKamhoZhiHDMNTc3DzmcU1NTdF6I89RU1OjqqoqmaYZnSMSDAZH1ehyuUa9xrPn7Xi93hHzkLxeb/S4iT7HRPo23p9FLJxby7nzkiby3NPpsdWvH4gFQgwwDR6PR3a7PRoIampq5Pf7z/szbrdbDodDnZ2dcrlc8nq9am9vV1tbm6ThgOF2u1VTU6OOjg6VlZWppqZGzc3NamtrU1tbm7xerzZu3Bh9zMjztrS0qKOjQ4FAQFVVVePWUFNTo0AgoPb2dj300ENqbW2d0Ov1+XwKBoPReTDV1dUjAkSEy+XS5s2b5fF41NnZqcbGRgWDQXk8Hnk8HhmGoXA4rHA4POZIVk1NzajHbW5uVnV1tSQpEAho06ZNCofDam5uHtH3iT5H5HnO17ex/iziNTH2Qs893R5Lif36gQmx8FQWkDLa2trC9fX1YcMwRs2TcTqd4fr6+uhtu90ebmtri96WFG5vbx9xfFlZWfR2S0tLWFK4paUlel9ZWVn0MSPzWTo7O0fUZLfboz9zdg3t7e2jnnOic2Kqq6vDTqdz1M+d/Xo7OztHPf7ZPB7PmPM1xurT2Y977u2zGYYRbmxsnNRzTLRvY/1ZXEh9fX1Y0qivs2s69/We+2dwvueORY9n8vUD8cJIDBADZWVlamxsVHt7u6qrqyd9Ga3D4Rhxu6KiYtT3zr7PMIzoKYJt27bJMIxR/9quqKhQS0vLqOfy+/2y2+0yDGNSNUrDp3HOPs1TVlYmu90+4pSSz+eb8uOf7c4779TmzZujNQeDwehIjDR8hVRNTY3Ky8tHXNI+URPt21h/FhNht9ujIyGRr/b29knVON5zx6LHM/36gXggxAAxtn79epmmGQ0Z53I6nWpoaJA0PKchEgTONtbw/3inBMZ7nliLnN5xu90qLi6OfkUm98a6jsipNknavHnziABTXl4uj8cjl8ultrY2lZWVTfrxJ1qvlRO3Z/K5k+H1AxdCiAGmYawRANM0ZbfbLxg6SktL1dLSooceemhaNTidzjFD07Zt21RZWTnq+MgozmRHLyJzUjo7O0d8RebybNmyRdLw6MxUHv9ckXDn8/nk9XqjczFM04zO45jOGjWT7dtMCwQCEz42Fj1OtNcPTAUhBpgiv9+v0tJSud1u+Xw+maYpr9er2tpaNTY2jvtzpmlq3bp1amlpUXNz87T/pVtWVian06k1a9ZEfylFrh46e/Ti7OMjk4Ujvwhra2vP+xyR0ZaxJnVGHi9ySskwDNXV1UVXLg4Gg/J6vdFTbIZhRO+P9G08dXV1amxslGma0cASOaURmdjs9XpHTaaeyHNMtm+xZhhGtG7TNCd1CjIWPbb69QOxQIgBpqisrEwtLS0yTVM1NTUqLS2Nrt4bWa13LIZhRI8/3yXTkxEZlSgvL9eyZcvkcDiiIyRjeeihh+RwOKKX1bpcrvPOr9iyZYsMwxh35MPlckXnrUivrCVTVVWl4uJiNTc3a926dZJeCT3Lli07b9iTpHXr1o1Y/VgaPr1RX18fvew38trPDoMTfY7J9i2WXC6Xtm3bNuE/g3PFosdWvn4gFmzhcDhsdRFAuoiM1HR0dER/6fr9fq1Zs0aNjY3nDT8AgJEYiQHiqLW1dcxRgzvvvJN/AQPAJBFigDiKnB7xer3RUy9erze6Ci4AYOI4nQTEmc/nU2Njo7Zt2yZpeI7M+vXrmUwJAJNEiAEAAEmJ00kAACApEWIAAEBSIsQAAICklGV1ATNlaGhIBw4c0Jw5c2Sz2awuBwAATEA4HFZ3d7cWLVqkjIzzj7WkbIg5cOCASkpKrC4DAABMwb59+7RkyZLzHpOyIWbOnDmShptQWFhocTXWC4VC2rp1q9auXavs7Gyry0lZ9Dk+6HN80Of4odev6OrqUklJSfT3+PmkbIiJnEIqLCwkxGj4L0h+fr4KCwvT/i/ITKLP8UGf44M+xw+9Hm0iU0GY2AsAAJISIQYAACQlQgwAAEhKhBgAAJCUCDEAACApEWIAAEBSsiTE+P1+lZeXX/A40zTV1NQkr9erpqYmBYPBmS8OAAAkhbivE+P1emUYhvx+/wWPrampUVtbm6ThQFNbWyuPxzPTJQIAgCQQ9xBTXV09oeNM0xxx2zAM+Xy+mSgJAAAkoYSdE+Pz+eRwOEbc53A4JjSCAwAAUl/Cbjsw3vyXQCAw5v19fX3q6+uL3u7q6pI0vJRzKBSKeX3JJtIDejGz6HN80Of4oM/xQ69fMZkeJGyIGc944aahoUEbNmwYdf/WrVuVn58/w1Ulj5aWFqtLSAv0OT7oc3zQ5/ih11JPT8+Ej03YEGO320eNugQCAdnt9jGPX79+ve66667o7cgumGvXrmUDSA0n25aWFlVVVbG52Ayiz/FBn+ODPsdPIvR6aCisU/0DOnF6QCdOh9TVG9KJ0wPq7g3pZN+gTvYO6FT/gE72Dehk76BO9g1o+YICffqWVTGtI3ImZSISNsQ4nU41NzePur+iomLM43Nzc5Wbmzvq/uzsbP7ynYV+xAd9jg/6HB/0OX5i1evQ4JA6T/Xr+Kl+HT/Zr+On+qL/DZwKqet0SCfO+eruDWkoPLnn6QkNxvy9MZnHszTEBIPBESMrfr9fdrtdhmHIMIwRx5qmqYqKinFHYgAASHU9/QM6dKJXh7p6dbirVwdP9OrwiV4d6R4OKcfOhJUTp6c+tyY3K0NFs7KjX4WzsjUnL0sFuVmak5ul2blZmn3m9qKiWTF8dZMX9xDj8/mi5/waGhpUWVkZvew6cru+vl6S5PF45Ha7VVlZqdbWVtaIAQCkrKGwdLirV4e6u7Wvs0d7j5/W/mDPcFA5E1i6ewcm/HgZNslRkCNHQY7mFuRq7uwczS3IUXFBjuyzslWUn63CvOxRgSUvO3MGX2VsxT3EOJ1OOZ1ONTY2jvreuSHFMIzocRNdXwYAgEQ1MDikfZ2n1X7kpDqOndLeQM+ZwNKjvcczNfC3P1/wMQpyMrWwKE8XFebpojP/XViYp3mzc+UoyNG82TmaOztXRbOylZlhi8Orsk7CzokBACBZneob0K4jJ9V+5KTaj56UefSU2o+e1J7jpxQaHG/iiU2ZGTZdXJSnkuJ8LXXka0nxLF1UlKeLi2bpoqJcLSzM05w85idFEGIAAJiicDisAyd69dyBLj1/8JWvlwI9Co+TVfKyM2TMmy1jfoGWOobDysWFOdq94+969223KD9v9EUqGBshBgCACTp0oldP7u3U9n1B7Xg5qOcOdKlrnHkq82bnasWC2SpdUCBj3myVLpit0vkFWlQ0SxnnnOYJhUIK7pSyMxN2If2ERIgBAGAMvaFB7dgX1JP7gtq+N6jt+4I61NU76risDJuWL5ityy4u1GUXzznz30LNm82IykwjxAAAoOHQ4n+pU38zj+tvZkDb9wXVPzg04pgMm7TqokJdW2LXdSV2XbG4UMsXzFZuVvJc0ZNKCDEAgLQ0MDik7fuC+vOLR8cNLQvm5KpsabGuXTocWq5aUqT8HH51Jgr+JAAAaeNIV68efvGoHtl5VI/uOjpqPstFhXm6wXDoBmOuXmXM1aVz82WzpfZlysmMEAMASFnhcFjPH+zWH549JN9zh/XcwZH78tjzs3XTivm6cflc3WDM1VIHoSWZEGIAACklHA5r+76g/vDsIf3hmUN66fjIXZGvXlKkN6ycr9evWqBrS+wpvyBcKiPEAABSwvMHu/SrJ/frdzsO6OCJV64iys3K0OtWztfNV1ykN6yaz1VDKYQQAwBIWodO9Oo32/frV0/u1wuHuqP3F+Rk6k2XLdQtZ4JLQS6/7lIRf6oAgKTSPzCkrc8d0s+f2Ke/th+Lroybk5mhN61eoHeWLdbrV85Pqo0MMTWEGABAUtgX6NFPn9grz7Z9OnayP3p/5aXFeud1S/SWqy5WUT77CqUTQgwAIGENDYX1p51H9OPHX9Kfdx2NjrosmJOrd1WWqLq8REvn5ltbJCxDiAEAJJze0KB+6d+v7/3FlHn0VPT+m1bM03tedYnWXLaAfYZAiAEAJI7jJ/v0k7+9pJ88/pKOnxo+ZTQnL0vvvn6p3vOqpbpkboHFFSKREGIAAJY70tWr7z5i6n/+/pL6BoaX/l9sn6UP3rhM6ypLNJurizAG3hUAAMsc6erVdx5p10//vjcaXq5eUqTamwzdeuVFyuKUEc6DEAMAiLtjJ/v033/crZ8+sVf9Z8JL2VK7Pu5cqZtWzGPpf0wIIQYAEDc9/QP6/qMd+u4j7TrVPyhJqrikWB9zrtCNywkvmBxCDABgxg0MDsnb9rK+3vKijnT3SZKuWlyk+ltWEV4wZYQYAMCMemz3MX3hd8/qxcMnJUkljln61M2r9darLlYGmy9iGggxAIAZcehEr754/3P636cOSpLs+dn66JtW6L03LFVuFlsCYPoIMQCAmOofGNIP/9qh/++hXerpH1SGTXrvDZfo7qpVbAuAmCLEAABipu2lTrl/8ZR2Hxk+dVR+SbH+87YrdMWiIosrQyoixAAApq2nf0BfffBF/fCxDoXD0tyCHH361tW6o2wJ814wYwgxAIBpeaz9mD79i6e1N9AjSaouX6LPveVyTh1hxhFiAABT0tM/oC/d/7z+5+97JUmLivL05duv0htWLbC4MqQLQgwAYNKeejmoj/98u8xjwztMv+dVS/XpW1drTh6jL4gfQgwAYMIGh8La+GdTX9u6UwNDYV1UmKev3XmNXrt8ntWlIQ0RYgAAE3LwxGl9YvN2/c0MSJJuvfIiNdx+lez5ORZXhnRFiAEAXNBfdh3Tv/38SQVO9Ss/J1NfeNsVqqlYwnYBsBQhBgAwrqGwdO/Dpr75x90Kh6XLLy7Ut99TpmXzCqwuDSDEAADGFuwJadMLGXouuFuStK6iRBtuu0J52WwZgMRAiAEAjPLCoS59+EetejmYodysDP3f267UnZUlVpcFjECIAQCM0PLcYX3850/qVP+g5uaG9f0PXq9rL5lrdVnAKIQYAIAkKRwOq/nPphr/8ILCYenVhkNvcxzRFYsKrS4NGFOG1QUAAKzXNzCouz07dM/vhwPMe29Yqu//Y5kKWLsOCYyRGABIcyd6Qqr9yTY90RFQZoZNX3jb5Xrfqy9VKBSyujTgvAgxAJDGDp44rff/4Am9ePik5uRl6TvvKdeNK1h9F8mBEAMAaerFw916/w+e0METvVpYmKv7Pni9Vl/E/BckD0IMAKShJzoC+vB9rerqHdDyBbN13wev12L7LKvLAiaFEAMAaeaPLxzWP/8/v/oHhlR+SbG+//4K9j9CUiLEAEAa+f3TB/VvP39SocGwnJct1H//w3WswIukRYgBgDTxqydf1t1bdmgoLL3tmkX6+p3XKDuTlTaQvAgxAJAGfv7EXq3/1dMKh6Wa8iW6546rlZnBDtRIboQYAEhxP358j/7jN89Kkt53wyXa8PYrlEGAQQogxABACvvp3/dGA0ztTcv0mTdfJpuNAIPUQIgBgBTlbXtZn/3105KkutcZWn/ragIMUgozugAgBf1m+37Ve3coHJY+8JpLCTBISYQYAEgxv3/6oO46cxXSu69fqs+/7XICDFISIQYAUsgjLx7VR3/2pAaHwqouX6IvveNKAgxSFiEGAFLE9n1BfeT/tWlgKKy3Xn2xGu+4mquQkNIIMQCQAtqPntQ//fAJ9fQP6qYV8/T1O69lHRikPEIMACS5Qyd69Y/ff0KdPSFds6RI331vuXKy+HhH6uNdDgBJ7ERPSO//wRPaHzwtY16BfvCBShXksnoG0gMhBgCSVN/AoGp/sk07D3drYWGu7vvg9Zo7O9fqsoC4sSSum6Ypr9crwzBkmqbq6upkt9vHPdbn88nhcMg0TVVXV8swjPgWDAAJJhwOa/0vntYTHQHNyc3SfR+8XiWOfKvLAuLKkhBTU1OjtrY2ScMhpba2Vh6PZ8xjvV6v6uvro7ddLpeam5vjUicAJKr//uNu/fLJ/crMsOne95Zp9UWFVpcExF3cTyeZpjnitmEY8vl84x6/efPmmS4JAJLKb3cc0NdaXpQk/d/brtRNK+ZbXBFgjbiHmMipobM5HA75/f4xj3c4HCovL4+eVqqqqopHmQCQkNpeCuiTnh2Shjd0/IdXLbW4IsA6cT+dFAwGx7w/EAiMeb/H49GaNWtUWlqqurq6cU8l9fX1qa+vL3q7q6tLkhQKhRQKhaZXdAqI9IBezCz6HB/p2ueXO0+r9sfb1D8wpKrLFuhu5/IZ7UG69tkK9PoVk+lBwlyHN1648fl8amxslGmacrlckjRmkGloaNCGDRtG3b9161bl5zPZLaKlpcXqEtICfY6PdOpz/6D0zWcyFeixaUlBWFVzDujBPxyIy3OnU5+tRq+lnp6eCR8b9xBjt9tHjboEAoExr04yTVOtra1qbGyUJDmdTpWXl8vtdo+6Qmn9+vW66667ore7urpUUlKitWvXqrCQCW+hUEgtLS2qqqpSdna21eWkLPocH+nW53A4rLu9T2t/zyHNLcjRTz9ygy4uypvx5023PluJXr8iciZlIuIeYpxO55gjKRUVFaPu8/v9qqysjN42DEPr168fc9QmNzdXubmj10fIzs5O+zfE2ehHfNDn+EiXPm/6s6nfPXVIWRk23fueMi2dNyeuz58ufU4E9FqTev1xn9h77giKaZqqqKiIjsT4/f7oFUxlZWVqbW0dcfzx48dVVlYWl1oBwGp/2XVMDb9/XpL0ubderlcZcy2uCEgclsyJ8Xg8crvdqqysVGtr64g1YhoaGlRZWan6+noZhqGqqio1NTVFQ05kXgwApLp9gR7968/8GgpL1eVL9I+vvsTqkoCEYkmIMQwjOs+lurp6xPfOXfTO6XTK6XTGrTYASASn+wdV95M2Bc9s6vjFd1wpm41dqYGzsXcSACSgz//2GT1/sEvzZufoO+8tV152ptUlAQmHEAMACeYXbS9ry7aXlWGTvvXu67TIPsvqkoCERIgBgASy63C3/v3Xz0iSPrZmpV5TOs/iioDERYgBgATR0z+gf/kfv06HBnXj8nn61zctt7okIKERYgAgQXzu189q15GTWjAnV99817XKzGAiL3A+hBgASABbtu3TL/yvzIOZN3v04p0ARiLEAIDFdh3u1n/8ZngezF1VK3UDC9oBE0KIAQAL9Q0M6t9+vl29oSHdtGKe/uUNzIMBJooQAwAW+uqDO/X8wS45CnL0tZprlME8GGDCCDEAYJG/7DqmTY92SJIa77haCwpnfmdqIJUQYgDAAp2n+nW3Z7sk6T2vWqqqyxdaWxCQhAgxABBn4XBYn/7lUzrc1SdjfoH+/S2XW10SkJQIMQAQZ1u27dODzx5WdqZN33rXdZqVw75IwFQQYgAgjvYcO6Uv/PY5SdLda1fpysVFFlcEJC9CDADEyeBQWJ/y7tDp0KBetcyh2psMq0sCkhohBgDi5Id/7VDrnk4V5GTqqzXXsK0AME2EGACIg/ajJ/WVB3dKkj7zlstU4si3uCIg+RFiAGCGDQ6FdfeWHeobGF6V9x+uX2p1SUBKIMQAwAzb+GdT2/cFNSc3S413XC2bjdNIQCwQYgBgBr14uFvfaHlRkvS5t12uRfZZFlcEpA5CDADMkIHBId29ZYf6B4f0ptULVFO+xOqSgJRCiAGAGfL9v3To6f0nVJiXpYbbr+I0EhBjhBgAmAF7jp3S1yOnkd56uRayuSMQc4QYAIixcDisz/zqafUNDOm1y+eqmtNIwIwgxABAjHnaXtZj7ceVl52hL7+T00jATCHEAEAMHenu1Zfuf16SdFfVSl0yt8DiioDURYgBgBja8LvndOJ0SFcuLtQHX7vM6nKAlEaIAYAY8T13WPc/dVCZGTbdc/vVysrkIxaYSfwNA4AY6O4N6XO/eUaSVHuToSsXF1lcEZD6CDEAEANf2/qiDp7o1SVz8/Vx5wqrywHSAiEGAKbpmf0n9OPH90iSvvzOq5SXnWltQUCaIMQAwDQMDYX12V8/o6Gw9PZrFum1y+dZXRKQNggxADANP2vdqx37gpqdm6V/f8tlVpcDpBVCDABM0bGTfWr6w05J0t1rV2oBWwsAcUWIAYApuuf3L+jE6ZAuv7hQ77vhEqvLAdIOIQYApuCJjoC8bS/LZpO+9M4rWRMGsAB/6wBgkkKDQ/rcr4fXhHlX5VJdt7TY4oqA9ESIAYBJ+uFfO7TzcLccBTmqv3mV1eUAaYsQAwCTcCB4Wt/07ZIkffrW1SouyLG4IiB9EWIAYBK+/MDz6ukfVMUlxaouW2J1OUBaI8QAwAT93Tyu/33qoDJs0obbrlBGhs3qkoC0RogBgAkYHArrC797TpL0ruuX6opFbPAIWI0QAwAT8LMn9ur5g10qzMvSJ9cymRdIBIQYALiAYE+/vrp1eGXeu6pWysFkXiAhEGIA4AK+0fKigj0hrVw4W+9lZV4gYRBiAOA8XjjUpf/3972SpC+87QpW5gUSCH8bAWAc4XBYG377nAaHwrr1yov0muXzrC4JwFkIMQAwjj88c0iPm8eVm5Whz7z5MqvLAXAOQgwAjKE3NKgv3v+8JMn1+lKVOPItrgjAuQgxADCGjX82tT94WouK8vSR15daXQ6AMRBiAOAch7t69Z2H2yVJ6998mWblZFpcEYCxEGIA4BxffXCnTocGVX5Jsd569cVWlwNgHIQYADjLswdOyOt/WZL02bdcJpuN/ZGAREWIAYAzwuGwvnT/8wqHpbdds0hlS4utLgnAeRBiAOCMP75wRI+1H1dOVobqb2Z/JCDREWIAQFJocEhfemD4kuoPvnYZl1QDSYAQAwAa3qXaPHpKjoIc/csbuaQaSAZZVjypaZryer0yDEOmaaqurk52u33c430+n0zTlGEYkiSn0xmnSgGkgxOnQ/pGy4uSpE9UrVRhXrbFFQGYCEtCTE1Njdra2iQNB5ra2lp5PJ4xj/X5fPJ4PGpubpZpmqqqqlJ7e3s8ywWQ4u7902519oS0fMFsvbuyxOpyAExQ3EOMaZojbhuGIZ/PN+7xLpcrGngMw1BLS8uM1gcgvewL9OiHf90jSfrsmy9jl2ogicT9b6vP55PD4Rhxn8PhkN/vH3WsaZoKBAKy2+3y+/0KBoPRU0oAEAv3/OEF9Q8O6cbl8/SGVfOtLgfAJMR9JCYYDI55fyAQGHWf3++Xw+GQ1+uV0+nUxo0bZRiGqqurRx3b19envr6+6O2uri5JUigUUigUik3xSSzSA3oxs+hzfMSqz0/uDer+pw7KZpPq167QwMBALMpLGbyf44dev2IyPbBkTsxYxgo3gUBApmnK6XTKbrerrq5OxcXFCofDo45taGjQhg0bRt2/detW5edzqWQEp+Pigz7Hx3T6HA5L33wmU5JNr5o/pI4nH1XHk7GrLZXwfo4fei319PRM+Ni4hxi73T5q1CVyyuhchmHIbrdHvxf5r9/vV1lZ2Yhj169fr7vuuit6u6urSyUlJVq7dq0KCwtj+hqSUSgUUktLi6qqqpSdzZUXM4U+x0cs+vzgs4e15287NCs7Q1/7wOu1YE5ujKtMfryf44devyJyJmUi4h5inE6nmpubR91fUVEx6r7JzH/Jzc1Vbu7oD6Hs7Oy0f0OcjX7EB32Oj6n2eWBwSN94aLck6cM3GVrsmB3r0lIK7+f4odea1OuP+8Tec4OJaZqqqKgYMcoSuYLJMAxVVFRETzVF1oo5dxQGACbjF/6X1X70lIrzs1X7Oi4WAJKVJXNiPB6P3G63Kisr1draOmKNmIaGBlVWVqq+vn7EseXl5Wpra+N8IYBp6Q0N6hstuyRJ/+eNy1nYDkhiloQYwzDU2NgoSaOuNDp30Tu73T7m6ScAmIr7HtujQ129WlSUp/fecInV5QCYBlZ1ApA2TpwO6d6Hh1f8/kTVSuVlZ1pcEYDpIMQASBvffaRdJ06HtHLhbN1etsTqcgBMEyEGQFo43NWrH/61Q5L0qZtXKzPDZnFFAKaLEAMgLXzTt0u9oSFVXFIs52ULrC4HQAwQYgCkvPajJ7Vl2z5JkvvW1bLZGIUBUgEhBsAIGzdulNvttrqMmPra1p0aHAprzeoFqrzUceEfAJAUEmbvJADWMU0zuuzBli1bVFdXZ3FFsbNjX1APPH1INpv0qVtWWV0OgBgixACQYRjR9Zi2bdtmcTWx1fTgC5Kkd163WKsvYh81IJVwOglJJxgMRremmCq/3x+japDIHt11VH/dfVw5mRn6hHOl1eUAiDFCDJKKaZpyu92T2hx0LIZhyOVyxagqJKKhobAa/zA8CvOeG5aqxJFvcUUAYo0Qg6Tidrtjsg2F3W6Xy+UiyKSw+58+qGf2d2l2bpb+9Y3LrS4HwAwgxCBp1NTUaP369TF7vLKyMtntdnm93pg9JhJDaHBIX9u6U5JUe5OhubNzLa4IwEwgxCApROawlJWVxfRxGxsb1dDQENPHhPV+3rpPe473aN7sHH34pmVWlwNghhBikBTcbndMR2HO5nQ6tXHjxhl5bMRfT/+AvvXQLknSR9+0QgW5XIQJpCpCDBKeaZoyTTPmozARLpcrukYKkt8P/tKho919WurI17uvX2p1OQBmECEGCa+5uVnV1dUz9viRK5247Dr5dZ7qV/Mjw5ff3712pXKy+IgDUhl/w5HwfD6fqqqqZvQ5nE6nfD7fjD5HsggGgwoGg1aXMSXf/tNudfcN6PKLC/W2qxdZXQ6AGUaISVB+v18ul0s1NTXjXgbs9XpVXFycFL9wIkGkuLhYNptt3K+xFrHz+/2qqKiY8HO53W4VFxerqqpqRG9M01RTU9OYP1NeXq6WlpZJv65UEQwG5Xa75XK5ZJqmtmzZIpfLNW6/EtH+4Gn9+PGXJEn1t6xSRgabPAKpjhlvCcg0TW3evFnNzc0KBoPRX8jnnlJpaGhQMBiU3W63ptAJcrvdampqktPpVF1dnUzTjF7WXF9fr7lz50oaXrvl3EXs/H6/7Hb7hF+jy+XSxo0bZRiGfD6f1qxZo7a2tuj3PB7PmD9XUVGRcpseTobdbo/OC4rFOjxW+GbLi+ofHNINhkOvXznf6nIAxAEhJgE1NjaO2scmEAiMOs7v98vpdE74ce+77z694x3vmHJddrtdHo9nUs9ZVVUln8+ntra2ERNzIyMzpaWl591sMBAITHh1Xr/fL9M01dnZKbvdLr/fL7fbraqqKgUCATU2No4bhgzDmNKIViSgTdVUeorRdh3u1i/8L0uS3Lesls3GKAyQDjidlGDOHVmJhJk777xzxHGR+RuTmSvy/ve/X/39/QqHw1P66uzsnNQv240bN8rn88nj8Yy6ssjpdEZ/gZ/PZPdI8ng80f6VlZWppaVFLpdL69evn1Dtk32+xsbGET3q7+/Xr3/96wn3ebI9Pd+puGT8ipWmB3dqKCzdcsVFum5pccweF0BiI8QkGLvdPmI9FK/XG11Z9myR+RuJ+i/4yByL6urqca8scjgcFwwNwWBQDodjQs85Vp8ioyQXurop8nPJML8II7W9FFDLc4eVYZM+eTObPALphNNJCSjyCzUyb2Ssib2RkZiZWjtluiLzdc63N5FpmhcMYcePH5/SnJ9gMKiGhga5XK5pbxaZSMLhsNUlJJRwOKzG3w9vL1BTXqLlC+ZYXBGAeCLEJLDxTiVJk58PE28+n092u33cGie6jcDcuXMnvX6L3++Xz+eb0gJ2qRR40sHDLx7TE3sCys3K0MerVlhdDoA443RSAvP5fDIMY9RIxFTmw0jDE3tzcnKmNYdhomupmKZ53suiI/sVXWgXabvdPuak5vFs3LhRpmmqvr5+1PfOF4Yip5EmO+rjdrtH9CcnJ0fveMc7JtVn1qeZmqGw9LWW4e0FPvCaS3Vx0SyLKwIQb4SYBBX5pTrWSEVkMuxkR2KmO7E3HA5P+DkdDse4gSAYDMrr9aqxsfGCIx+TuWqoqalJhmGMOf/F6/WeNywEAoEpnbaa7sTeyfR0LBs3bkzbS8Pbjtm08/BJFeZl6SNvKLW6HAAWmHSIcTgc+shHPqLt27fPQDmIiPxCHWtSa6LPh5GGA9Z4k3Zra2tVVlY25mjJuQzDmNAVQxs3boyurRO5rPvs77nd7vM+n9/vn/AEYquZpimXyyWXy5W2AaZvYEgP7Bv++PrnN5TKnp9jcUUArDDpENPR0aGysjJ9+MMf1ooVK7R+/Xrt2bNnBkqD0+mMrhMTUVNTM6EJsVZrbGyUaZqjRj8ip48iC9BdSOR02vmCjGmaamlpUVtbmzwejwzDiK5BU1xcfN5F7s5+jETvaYRhGGpublZzc/Ok5/Bc6PTdTNm4caOKi4vl9/sVDAanvU/Vz1r3KdBn08I5ufqn1yyLUZUAks2kQ0xRUZFqa2u1bds2bdu2TYZhqKamRpWVlfrqV7+qrq6umagzLUV+IdfU1ESXhI/Mg5npvYSmy263q6OjQ83NzdHaa2pqVFVVdcFAca4L7WvU3NysTZs2jbgdWRnYMIxRC+2NpaWlJeF7GguTmV8UK5HTgQ899JDcbre2bds2rVHE7t6Q7n14ONT+6xtLNSsnMxZlAkhCU746afv27WpublZLS4vKysrkcrkUDAZVXV2tm2++WXfffXcs60xLYy0GFzl9cL5VbhPFRBazmwiXy6XGxsZxX/NYVyFFRiomatu2bWm9d9JY/H6/Nm/erMrKSgUCAVVUVETDx8aNG9Xe3j7uz1ZVVUVHtux2u+rq6hQMBtXY2Djt06Dfe7RDnT0hLcgLq7qMTR6BdDbpEPOVr3xFzc3Nstlscrlcuueee1RUVBT9/h133KGKigpCzDSNtyeS1+uNrnabLpxOZzQkz8Tr9nq9Y17Gns6amprU2to6IoTW1NREb082REf2wCorK5Pf759ykDl2sk/fe3R4FOYtS4eUlcm1CUA6m/QnQHt7uzwej3bt2qVPfvKTIwJMhFXn3VNFZHfqcydter1emaaZlpM5Ixs7zoTIKS8M8/l8crvdI07R+f1+VVZWTunxmpqa1NzcLJ/PFx3dmar//uNuneof1FWLC3WNg4X/gHQ36ZGY7373uxc8pra2dkrFYNjmzZtlt9u1bt266H2RZfzr6+uTZgJqLNXX16u8vHxCVzRNRmQtHha5e4Xb7VZZWZl8Pt+IOTRT6b3f71d1dbUcDofWrFkjj8cz5dN2e4/36H/+/pIk6ZNVKxTc+fcpPQ6A1MGKvQmoqqpKLpcrOuQeDAa1Zs0aVVdXT2kV2lTR2Ngot9sd0x40NjbGZN5OonG5XGNe0bVt27YxJzC7XK7o+jp+v18ej+eC+01NxNmnjSZ6Rdp4vt6yU6HBsG5aMU+vKZ2rB3ZOtzoAyY4Qk4Dq6urkdrujOzJHJkSm4wjM2ZxOZ3RLgVj0IhKIUnF+0XiTms+e1zKW8y2yaKXnDnTpNzsOSJLct6y2uBoAiYIQk6DSecTlfOrr66NbC0znFJDX69W6desS7pe11c4X6GIVHqei6cEXFA5Lb736Yl25uEihUMiSOgAkFkIMkk4sLi+PxamSRBAMBie8LcNE1dXVye/3jwiJXq/XshGrv5nH9fDOo8rKsOmTa1dZUgOAxESIAZJMMBhUQ0ODgsGgTNPUli1bJEmlpaUxmfgcuVorEAjI4XAoEAjI6XRaMvk5HA7rnt+/IEl61/UlunReQdxrAJC4CDFAkrHb7dHTjZNZ0G8yEuV05oPPHtb2fUHNys7Uv61ZYXU5ABIMK0UBaWT9+vVWlzBhA4ND+sqDw6MwH7pxmRbMybO4IgCJhhADpJFkmsj8S/9+tR89peL8bNW9nnV8AIxGiAGQcHpDg/p6y4uSpP/zxuUqzMu2uCIAiYgQAyDh/OixPTrU1avF9ll67w2XWF0OgARFiAGQUE70hHTvn3ZLku6qWqm87EyLKwKQqAgxABLKvY/sVlfvgFYtnKN3XLfY6nIAJDBCDICEcSB4Wj/86x5JkvvWVcrMsFlbEICERogBkDC+6XtR/QNDun6ZQ29ctcDqcgAkOEIMgISw63C3vG0vS5I+fetq2WyMwgA4P0IMgITQ9OBODYWlm69YqLKlxVaXAyAJEGIAWG7bnoBanjusDJv0qZtXW10OgCRBiAFgqbM3eVxXWaLlC2ZbXBGAZEGIAWAp3/NHtO2lTuVlZ+hja1ZaXQ6AJEKIAWCZwaGwmv4wPArzT69dpouK2OQRwMQRYgBY5hf+l7XryEkVzcrWP7++1OpyACQZQgwAS/SGBvWNM5s8/usbl6toFps8ApgcQgwAS9z32B4dPNGrRUV5et+r2eQRwOQRYgDE3YmekO59uF2S9Ak2eQQwRYQYAHF378O7deJ0SCsXztbtZUusLgdAkrIkxJimqaamJnm9XjU1NSkYDE7o59xu94SPBZCY9gV6ops8rr/1MjZ5BDBlloSYmpoa1dfXq7q6WtXV1aqtrb3gz/j9fjU1NcWhOgAz6SsP7lT/4JBeu3yu3rBqvtXlAEhicQ8xpmmOuG0Yhnw+34R+zjCMmSoLQBxs3xfUb3cckM0mfebNl7HJI4BpyYr3E/p8PjkcjhH3ORwO+f1+lZWVjfkzXq9X1dXVcrvd4z5uX1+f+vr6ore7urokSaFQSKFQKAaVJ7dID+jFzKLP4wuHw/ri/z4rSXrHtYu0cn7+lPtEn+ODPscPvX7FZHoQ9xAz3pyWQCAw7vF2u/2Cj9vQ0KANGzaMun/r1q3Kz8+fTIkpraWlxeoS0gJ9Hu2pgE3bXspUti2sa2179cADe6f9mPQ5Puhz/NBrqaenZ8LHxj3EjGe8cLNlyxbV1dVd8OfXr1+vu+66K3q7q6tLJSUlWrt2rQoLC2NVZtIKhUJqaWlRVVWVsrNZVGym0OexhQaH9I3/ekxSjz78OkP/4Fwxvcejz3FBn+OHXr8iciZlIuIeYux2+6hRl0AgMOZoi8/n05133jmhx83NzVVubu6o+7Ozs9P+DXE2+hEf9Hmkn23boz3HezRvdo7+z5tWKjs7Nh899Dk+6HP80GtN6vXHPcQ4nU41NzePur+iomLM47ds2RL9f9M01dDQoHXr1o07fwZAYunqDembvl2SpI87V2p2bsIMAANIcnH/NDn3CiPTNFVRUREdifH7/bLb7TIMQ06nc8SxLpdLLpeLq5SAJPKdh9sVONWv0vkFeldlidXlAEghlqwT4/F45Ha75fV61dzcLI/HE/1eQ0ODvF7viOODwWB0jZjGxkb5/f641gtgavYHT+v7f+mQNHxJdVYmi4QDiB1LxnUNw1BjY6Mkqbq6esT3zg40EXa7XfX19aqvr49LfQBi46sP7lT/wJBuMBx60+oFVpcDIMXwzyIAM+Lpl0/oV0/ulyR99s2Xs7AdgJgjxACIuXA4rP/7v89JGl7Y7qolRRZXBCAVEWIAxNwDTx/SE3sCysvOUP0tq60uB0CKIsQAiKne0KC+/MDzkqR/fn2pFtlnWVwRgFRFiAEQU9971NT+4GktKsqT63WlVpcDIIURYgDEzKETvfr2n9olSe5bV2tWTqbFFQFIZYQYADHT9IcXdDo0qPJLivX2axZZXQ6AFEeIARATT+7t1C/PXFL9H2/lkmoAM48QA2DahobC2vC74Uuqq8uX6JoSu7UFAUgLhBgA0/abHfu1fV9QBTmZqr95ldXlAEgThBgA09LTP6DG3++UJP3LG5drQWGexRUBSBeEGADT8t2H23Woq1cljln60I3LrC4HQBohxACYsr3He/TdP5uSpM/cepnysrmkGkD8EGIATNl//u+z6h8Y0muXz9UtV15kdTkA0gwhBsCUPPT8YfmeP6KsDJs2vP0KLqkGEHeEGACT1hsajF5S/aGblmn5gjkWVwQgHRFiAExa8yOm9gZ6dFFhnv7tTSusLgdAmiLEAJiUfYEe3fvwbknSv7/1MhXkZllcEYB0RYgBMCkbfvec+gaG9JrSuXrLVRdbXQ6ANEaIATBhf3zhsHzPH1ZWhk3/eRuTeQFYixADYEJ6Q4P6wm/PTOa9kcm8AKxHiAEwIWdP5v3oGibzArAeIQbABZlHT+rbZybzfvYtl2k2k3kBJABCDIDzCofD+uyvnlH/wJBet3K+3no1k3kBJAZCDIDz+qV/vx43jysvO0NfvO1KJvMCSBiEGADjCpzq1xfvH57M+7E1K7V0br7FFQHAKwgxAMb1pfufV2dPSKsvmqMP37TM6nIAYARCDIAxPbb7mH7hf1k2m/Tl269SdiYfFwASC59KAEbpDQ3qs79+RpL03lddorKlxRZXBACjEWIAjHLvn3ar49gpLZiTq0/dssrqcgBgTIQYACO8eLhb33mkXZL0hbdfocK8bIsrAoCxEWIARA0MDulTnh0KDYblvGyBbr3yIqtLAoBxEWIARH3vLx3a8fIJzcnL0hffcRVrwgBIaIQYAJKk9qMn9fWWFyVJn3vr5bqoKM/iigDg/AgxADQ4FFa996no1gI15UusLgkALogQA0A/emyP2l7q1OzcLDXczmkkAMmBEAOkuZeOn9JXHnxBkrT+zau12D7L4ooAYGIIMUAaGxoKy/2Lp9QbGtJrSufqH65fanVJADBhhBggjf3osT36mxnQrOxM3XP71ZxGApBUCDFAmtp1uFv3/GH4NNJn33IZO1QDSDqEGCAN9Q8M6RNbtqt/YEhvWDVf73kVp5EAJB9CDJCGvvXQLj2zv0v2/Gw13cFpJADJiRADpJm2lzp178O7JUlffudVWlDIonYAkhMhBkgjp/oGdPeW7RoKS++8brHefNXFVpcEAFNGiAHSyJceeF57jvfo4qI8feHtV1hdDgBMCyEGSBMPPntIP/37XknS12quUdGsbIsrAoDpIcQAaeBA8LTqvU9JkmpvWqbXLJ9ncUUAMH2EGCDFDQwO6WM/f1InTod09ZIiferm1VaXBAAxQYgBUty3Htql1j3Dmzv+17uvU04Wf+0BpAY+zYAU9lj7Mf3Xn85cTn37VbpkboHFFQFA7BBigBR1/GSfPrF5u8Jh6c6KJXr7NYusLgkAYooQA6SgoaGwPuV9Soe7+lQ6v4DLqQGkJEIMkIK+80i7/vjCEeVkZei//6FM+TlZVpcEADFHiAFSzF93H9PXtu6UJP3n26/QZRcXWlwRAMwMQgyQQg6eOK2P/uxJDZ2ZB/Ou69mdGkDqIsQAKaJ/YEj/8j9+BU7164pFhfrP2660uiQAmFGEGCBFfOn+5/Tk3qAK87L0nfeUKy870+qSAGBGWTLbzzRNeb1eGYYh0zRVV1cnu90+5rF+v18+n0+S1Nraqk2bNo17LJCufvXky7rv8ZckSd9817VaOjff4ooAYOZZEmJqamrU1tYmaTjQ1NbWyuPxjHmsz+dTfX29JKmpqUlr1qyJ/iwAace+oNy/eFqS9NE3LdebVi+0uCIAiI+4n04yTXPEbcMwoiMt5/L7/WpoaIjerq6ult/vH/UYQLo63NWr2h9vU//AkJyXLdAnnCutLgkA4ibuIzE+n08Oh2PEfQ6HQ36/X2VlZSPuLysr06ZNm6K3g8Fg9Phz9fX1qa+vL3q7q6tLkhQKhRQKhWJVftKK9IBezKx49rk3NKja+1p1pLtPKxYUqOn2KzU4OKDBwRl/asvxfo4P+hw/9PoVk+lB3ENMJIicKxAIjHl/dXV19P83b94sp9M55pyYhoYGbdiwYdT9W7duVX4+8wMiWlparC4hLcx0n8Nh6Se7M/TUsQzlZ4X1rsUn9Ogft87ocyYi3s/xQZ/jh15LPT09Ez42YZbxHC/cnP19r9c77nyY9evX66677ore7urqUklJidauXavCQhb7CoVCamlpUVVVlbKzs60uJ2XFq8/Nf+5Q27Fdysqwqfl9FbrBGD06mcp4P8cHfY4fev2KyJmUiYh7iLHb7aNGXQKBwAWvOHK73WppaRn3uNzcXOXm5o66Pzs7O+3fEGejH/Exk31+4OmD+ppvlyTp82+/QjetSt+JvLyf44M+xw+91qRef9wn9jqdzjHvr6ioGPdnmpqa5Ha7ZRiGgsHgBUdtgFTV9lJAHz+zM/U/vvoSve+GS6wuCQAsE/cQYxjGiNumaaqioiI6wnLu1Uder1dlZWXRALNlyxbWiUFa6jh2Sh++75UrkT7/NnamBpDeLJkT4/F45Ha7VVlZqdbW1hFrxDQ0NKiyslL19fUyTVM1NTUjftZut6uuri7eJQOWOn6yTx/44RPq7Anp6iVF+ta7r1Nmhs3qsgDAUpaEGMMw1NjYKGnk1UeSRgQawzAUDofjWhuQaE73D+pD923TS8d7tKR4lr7//krl5yTMnHwAsAx7JwEJLDQ4pI/+zK/t+4IqmpWtH/3T9Zo/Z/QEdgBIR4QYIEENDYVV731KvuePKDcrQ5v+sULLF8y2uiwASBiEGCABhcNhfeF3z+pXT+5XVoZN976nTNcvS6+1YADgQggxQAL6esuL+vHjL8lmk7525zVac1n6rgUDAOMhxAAJ5nuPmvqvP+6WJP3nbVfqtmsXW1wRACQmQgyQQH78+B598f7nJUmfunkVi9kBwHkQYoAE8ePH9+g/fvOsJOmfX1+qf3lDqcUVAUBiI8QACeAnZwUY1+sMuW9ZJZuNxewA4HwIMYDFfvL4Hn3urADz6VtXE2AAYAIIMYCF7nvslQBTR4ABgElh7XLAAuFwWN/+0259deuLkqTam5ZpPQEGACaFEAPEWTgc1pcfeF6bHu2QJP3bmhX6hHMFAQYAJokQA8TR4FBYn/nl09q8bZ8k6XNvvVwfunGZxVUBQHIixABx0jcwqLs279D9Tx9Uhk26546rdWdFidVlAUDSIsQAcRDs6Vfdj9v0xJ6AsjNt+q93X6dbrrzY6rIAIKkRYoAZtvd4jz7woydkHj2lOblZ+u77yvXa5fOsLgsAkh4hBphBT+7t1Ifv26bjp/q12D5LP/ynSq1cOMfqsgAgJRBigBny+6cP6hNbtqs3NKQrFxfqB++v1ILCPKvLAoCUQYgBYmwoLH3Dt1v3PmJKkt60eoH+693XqSCXv24AEEt8qgIx1N07oO/vzNAzncMB5sM3LtOnb12trEwWxwaAWCPEADHSfvSkau/bJrMzQzlZGbrn9qt0e9kSq8sCgJRFiAFi4IGnD8rtfUrdfQOy54T1gw9WquxSrkACgJlEiAGmoTc0qC8/8Lx+/PhLkqSKS+y6bd4xXbW4yOLKACD1caIemKI9x07pju88Fg0wH3lDqX78TxUqzLG4MABIE4zEAJMUDof12x0H9NlfPaOTfQMqzs/W19ddqzeuWqBQKGR1eQCQNggxwCR0nurXv//mGd3/1EFJUuWlxfrWu6/TxUWzLK4MANIPIQaYoId3HlG99ykd6e5TZoZNH33Tcv3rG5dz+TQAWIQQA1xAd29I9/z+Bf3P3/dKkkrnF+gb667V1Uvs1hYGAGmOEAOcR8tzh/W5Xz+jQ129kqQPvOZSffrW1crLzrS4MgAAIQYYw5GuXn3+t8/q988ckiQtdeSr4far2H0aABIIIQY4y+BQWD9v3at7fv+CunsHlJlhU+1Nhj62ZoVm5TD6AgCJhBADnNG6J6ANv3tWz+zvkiRds6RIDbdfrcsXFVpcGQBgLIQYpL0DwdNq+P0L+t2OA5KkOXlZ+oRzpd7/mkuVmWGzuDoAwHgIMUhbp/oGtOlRU999pF29oSHZbNK7Kkt099pVmjc71+ryAAAXQIhB2ukbGNRP/75X3/7Tbh072S9peNG6z7/tCl3JnkcAkDQIMUgbg0Nh/erJ/fpGy4vaHzwtSbpkbr4+uXaV3nr1xbLZOHUEAMmEEIOUNzA4pN89dUDf/lO7dh85KUlaMCdXH3Ou0J0VJcpmxV0ASEqEGKSsvoFB/aJtv777SLv2BnokSUWzsvWRN5Tq/a++lEumASDJEWKQcrp7Q9rcuk/fe7QjutKuoyBHH7pxmd736ktUmJdtcYUAgFggxCBl7Dl2Sj96bI882/bpVP+gJGlhYa7qXleqd19fovwc3u4AkEr4VEdSC4fDeqz9uH741w499MIRhcPD9y9fMFsfunGZbi9brNwsThsBQCoixCApHenu1S/a9mvLtn3qOHYqev8bV83XB29cphuXz+NqIwBIcYQYJI3BobD+/OJR/bx1rx56/ogGhoaHXQpyMnVH+RK9/zWXqnT+bIurBADECyEGCS0cDmvHyyf0m+37df9TB3Wkuy/6vbKldr2rcqnecvXFKsjlrQwA6YZPfiSkXYe79dsdB/TbHQf00vGe6P3F+dm6vWyJ1lWWaOXCORZWCACwGiEGCWFoKKyn9p/Q1mcPqeW5w9p1ZlE6SZqVnamqyxfqtmsX6aYV85WTxeJ0AABCDCzUNzCox9uPa+tzh+V77vCIU0VZGTa9fuV8vf3aRaq6fCGXRwMARuE3A+ImHA6r/ehJ/fnFY3p011H9zQzodGgw+v2CnEy9YdUCVV2+UG9ctUBF+SxKBwAYHyEGM+rQiV79veO4/rLrmB7ddSy6gm7EwsJcOS9bqKrLF+rVpXNZ0wUAMGGEGMRMOByWeeyUWjsCemJPQK17AtoXOD3imJysDL1qmUM3rZinm1bM1+qL5rCeCwBgSggxmLJgT7+eevmEnt5/Qjv2BdX2UqeOn+ofcUyGTbrs4kK9dvk83bRiniovdSgvm9EWAMD0EWIwIcGefj1/sFvP7D+hHS8H9fT+EyMufY7IycrQtSV2XX+pQ5XLHCpbatccNlwEAMwAQgxG6A0NaveRk9p5qFs7D3frhUPd2nmoS4e7+sY8/pK5+bp6iV1XLy7SdUvtumpJEfNaAABxQYhJQ+FwWIe7+mQeO6k9x3rUceykOo71nLl9SmdW8x9lsX2WrlxcOBxalhTpqsVFsufnxLd4AADOIMSkqFN9A9ofPK39naf1cvC09h0/qSd2Zug7HY/rpeM9Iy5tPpc9P1urFs7R6ovmaNVFhVp10RytXDib00IAgIRCiElCp/oGdKS7T0e6enWku0+Hu3qjgWV/cPgr2BMa4yczJHVLkjIzbCopnqVl8wp06bwCGWf+u2rhHM2fk8sVQwCAhEeISQBDQ2F19w6os6dfgZ5+BXv6FTgV0rGTfTrS1acj3cNh5eiZ4HKqf/xRlLPNycvSYvssLSmepYsLc9V9aI/efFOFli8sVIkjX9mZLN8PAEheloQY0zTl9XplGIZM01RdXZ3sdvu0j7XS0FBYJ/sH1N07oO7e0Dn/Hf7q6g2p81S/Onv61XkqFA0snT0hDY43EWUc+TmZWjAnVwvm5Gl+Ya6W2GdpcfEsLbbP0qIz/1941umfUCikBx7o0BtXzVd2NqeFAADJz5IQU1NTo7a2NknDIaW2tlYej2fax8bDswdO6KsP7jwrnAwHlZP9AwpPLoeMUpCTqeKCHBXn56i4IEdzC3K0YE6u5s/J1YLCvDOhZfj/Z+cyiAYASG9x/01omuaI24ZhyOfzTfvYeOnpH9Sfdh4d9/s5mRmak5d15itbs3Nf+f/CWVly5OfIXpAjR36OiguyVZyfI0dBjuz52VyaDADAJMQ9xPh8PjkcjhH3ORwO+f1+lZWVTfnYeDHmFajpjqujweTswDInL4vVaAEAiJO4h5hgMDjm/YFAYFrH9vX1qa/vlQXZurq6JA3PBQmFxrpSZ2oKczP0zmsvGue7QwqFhmL2XLEU6UEse4HR6HN80Of4oM/xQ69fMZkeJMzEivECy0SPbWho0IYNG0bdv3XrVuXn50+jstTS0tJidQlpgT7HB32OD/ocP/Ra6ukZvaXNeOIeYux2+6iRlEAgMOYVR5M5dv369brrrruit7u6ulRSUqK1a9eqsLAwJrUns1AopJaWFlVVVXF10gyiz/FBn+ODPscPvX5F5EzKRMQ9xDidTjU3N4+6v6KiYlrH5ubmKjc3d9T92dnZaf+GOBv9iA/6HB/0OT7oc/zQa03q9cd9tTPDMEbcNk1TFRUV0dEVv98fvSrpQscCAID0ZcmcGI/HI7fbrcrKSrW2to5Y96WhoUGVlZWqr6+/4LEAACB9WRJiDMNQY2OjJKm6unrE984NKec7FgAApC82zwEAAEmJEAMAAJISIQYAACQlQgwAAEhKhBgAAJCUCDEAACApEWIAAEBSSpgNIGMtHA5LmtweDKksFAqpp6dHXV1dab+k9Uyiz/FBn+ODPscPvX5F5Pd25Pf4+aRsiOnu7pYklZSUWFwJAACYrO7ubhUVFZ33GFt4IlEnCQ0NDenAgQOaM2eObDab1eVYLrKr9759+9jVewbR5/igz/FBn+OHXr8iHA6ru7tbixYtUkbG+We9pOxITEZGhpYsWWJ1GQmnsLAw7f+CxAN9jg/6HB/0OX7o9bALjcBEMLEXAAAkJUIMAABISoSYNJGbm6vPf/7zys3NtbqUlEaf44M+xwd9jh96PTUpO7EXAACkNkZiAABAUiLEAACApESIAQAASSll14nBxLjdbq1fv152u93qUlKO3++Xz+eTJLW2tmrTpk30OQZM05TX65VhGDJNU3V1dfR1BvD+jT8+jyePib1pzO/3q7y8XJ2dnfylmQFNTU2qr6+P/v/mzZvV1tZmcVXJr7y8PNpH0zTldrvl8Xgsrir18P6NLz6Pp4bTSWnMNE0ZhmF1GSnJ7/eroaEheru6ulp+v1+maVpYVfI7t3+GYURHCxA7vH/jj8/jqSHEpCmv16vq6mqry0hZZWVl2rRpU/R2MBiUJDkcDosqSg0+n29UDx0Oh/x+v0UVpSbev/HF5/HUEWLSUDAYZLgyDs7+UNq8ebOcTid9n6bIL9NzBQKB+BaSBnj/xgefx9NDiElDW7ZskdPptLqMtBEMBuX1epm3MYPGCzeYPt6/M4vP4+nh6qQUsXHjRrW3t4/7/aqqKjmdTvl8Pt15551xrCy1TLTPZ3O73WppaeFfWzFgt9tHjboEAgF6O4N4/84cPo+nj6uT0ozP5xsxOc/lcqm+vl7r1q1TWVmZhZWlpqamJlVXV8swjOhoAb8Mps40TdXU1Iy4Sqa4uFgdHR30dQbw/p1ZfB5PHyEmzdlsNrW3tzMrfgZ4vV7Z7XY5nU4Fg0Ft2bJFdXV1VpeV9M69xNrlcqmlpcXiqlIP79/44/N48ggxaSoYDGrjxo1yu92qq6uTy+Ui+ceQaZoqLS0dcZ/dbldnZ6dFFaUO0zTV3NysyspKtba2sjjYDOD9G198Hk8dIQYAACQlrk4CAABJiRADAACSEiEGAAAkJUIMAABISoQYAACQlAgxAAAgKRFiAABAUiLEAACApESIAQAASYkQAwAAkhIhBkDS8Hq9Ki0tjX7ZbDY1NTVZXRYAi7B3EoCktHHjRjU2Nqq9vd3qUgBYhBADIOkEg0EtW7ZMDz30ELv9AmmMEAMg6VRVVckwDDU3N1tdCgALEWIAJBWv16va2lp1dnZaXQoAizGxF0DSCAaDqq2tlcfjsboUAAmAEAMgabjdbgWDQblcrugVSlydBKQvTicBAICkxEgMAABISoQYAACQlAgxAAAgKRFiAABAUiLEAACApESIAQAASYkQAwAAkhIhBgAAJCVCDAAASEqEGAAAkJQIMQAAICn9/w899iwfNMlGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = sigmoid(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"Sigmoid Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\frac{1}{1 + e^{-z}}$\"\n",
    "ax.text(-4.5, 0.5, formula, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanh Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(x)\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = tanh(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"Tanh Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}$\"\n",
    "ax.text(-4.5, 0.5, formula, fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = relu(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"Relu Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\max(0,z)$\"\n",
    "ax.text(-4.5, 2.2, formula, fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeakyReLU Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def leaky_relu(z, alpha=0.1):\n",
    "    return np.where(z > 0, z, alpha * z)\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = leaky_relu(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"LeakyReLU Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\begin{cases} x, & \\text{if } x > 0 \\\\ \\alpha x, & \\text{if } x \\leq 0 \\end{cases}$\"\n",
    "ax.text(-4.5, 1, formula, fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELU Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def elu(z, alpha=1.0):\n",
    "    return np.where(z > 0, z, alpha * (np.exp(z) - 1))\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = elu(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"ELU Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\begin{cases} z, & \\text{if } z > 0 \\\\ \\alpha(e^z-1), & \\text{if } z \\leq 0 \\end{cases}$\"\n",
    "ax.text(-4.5, 2, formula, fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math\n",
    "\n",
    "# display(Math(r\"\"))\n",
    "display(Math(r\"\\mathcal{L}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\"))\n",
    "display(Math(r\"m \\leftarrow \\beta_1 \\cdot m + (1-\\beta_1) \\cdot \\frac{\\partial \\mathcal{L}}{\\partial w^2_{1,1}}\"))\n",
    "display(Math(r\"v \\leftarrow \\beta_2 \\cdot v + (1-\\beta_2) \\cdot (\\frac{\\partial \\mathcal{L}}{\\partial w^2_{1,1}})^2\"))\n",
    "display(Math(r\"w^2_{1,1} \\leftarrow w^2_{1,1} - \\eta \\cdot \\frac{m}{\\sqrt{v}}\"))\n",
    "display(Math(r\"w^2_{1,1} \\leftarrow w^2_{1,1} - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial w^2_{1,1}}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constellation = [-1.  1.]\n",
      "alpha = 1.0\n",
      "constellation = [-0.70710678  0.70710678]\n"
     ]
    }
   ],
   "source": [
    "M = 4                  ####modulation order, 4 for 4qam, 16 for 16qam\n",
    "\n",
    "constellation = np.linspace(int(-np.sqrt(M) + 1), int(np.sqrt(M) - 1), int(np.sqrt(M)))\n",
    "print('constellation =', constellation)\n",
    "alpha = np.sqrt((constellation ** 2).mean())\n",
    "print('alpha =', alpha)\n",
    "constellation /= (alpha * np.sqrt(2))\n",
    "print('constellation =', constellation)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[39mreturn\u001b[39;00m(a, b)\n\u001b[1;32m     50\u001b[0m \u001b[39m# Deep Image Prior\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m dip \u001b[39m=\u001b[39m DeepImagePrior(user_num\u001b[39m=\u001b[39;49mNUM_RX_ANT,      \u001b[39m# Number of transmitted symbol in real domain\u001b[39;49;00m\n\u001b[1;32m     52\u001b[0m                     M\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,              \u001b[39m# Modulation order, 4 for 4qam, 16 for 16qam\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m                     iteration\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,    \u001b[39m# Number of max iterations used for DIP: 100\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m                     LR\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,          \u001b[39m# Learning rate,  typically set to 0.01\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m                     buffer_size\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,   \u001b[39m# Iterations stored,  typically set to 30\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m                     threshold\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m,  \u001b[39m# Threshold of DIP stop,, typically set to 0.001\u001b[39;49;00m\n\u001b[1;32m     57\u001b[0m                     stop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)        \u001b[39m# True\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# print(dip.QAM_const())\u001b[39;00m\n\u001b[1;32m     60\u001b[0m dip\u001b[39m.\u001b[39mQAM_const()\n",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36mDeepImagePrior.__init__\u001b[0;34m(self, user_num, M, iteration, LR, buffer_size, threshold, stop)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold \u001b[39m=\u001b[39m threshold        \u001b[39m###Threshold of DIP stop,, typically set to 0.001\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop \u001b[39m=\u001b[39m stop                  \u001b[39m###True\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m constellation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39mint\u001b[39m(\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msqrt(M) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39msqrt(M) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39msqrt(M)))\n\u001b[1;32m     16\u001b[0m alpha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt((constellation \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean())\n\u001b[1;32m     18\u001b[0m constellation \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m (alpha \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "class DeepImagePrior(object):\n",
    "\n",
    "    def __init__(self,user_num,M, iteration,LR,buffer_size,threshold,stop):\n",
    "        \n",
    "        self.user_num = user_num    ####number of transmitted symbol in real domain\n",
    "        self.M = M                  ####modulation order, 4 for 4qam, 16 for 16qam\n",
    "        self.iteration = iteration  ####number of max iterations used for DIP\n",
    "        self.LR = LR                ####Learning rate,  typically set to 0.01; \n",
    "                                    ####Control step size of updating the model parameters at each iteration\n",
    "        self.buffer_size = buffer_size    ###iterations stored,  typically set to 30\n",
    "        self.threshold = threshold        ###Threshold of DIP stop,, typically set to 0.001\n",
    "        self.stop = stop                  ###True\n",
    "        \n",
    "        constellation = np.linspace(int(-np.sqrt(M) + 1), int(np.sqrt(M) - 1), int(np.sqrt(M)))\n",
    "\n",
    "        alpha = np.sqrt((constellation ** 2).mean())\n",
    "\n",
    "        constellation /= (alpha * np.sqrt(2))\n",
    "        print('constellation =', constellation)\n",
    "        self.constellation = constellation\n",
    "\n",
    "        constellation_expanded = np.expand_dims(self.constellation, axis=1)\n",
    "\n",
    "        constellation_expanded= np.repeat(constellation_expanded[None,...],1,axis=0)\n",
    "\n",
    "        constellation_expanded_transpose = np.repeat(constellation_expanded.transpose(0,2,1), self.user_num, axis=1)\n",
    "\n",
    "        self.constellation_expanded =torch.from_numpy(constellation_expanded)\n",
    "\n",
    "        self.constellation_expanded_transpose = torch.from_numpy(constellation_expanded_transpose)\n",
    "\n",
    "    def QAM_const(self):\n",
    "        mod_n = self.M\n",
    "        sqrt_mod_n = np.int(np.sqrt(mod_n))\n",
    "        real_qam_consts = np.empty((mod_n), dtype=np.int64)\n",
    "        # print('real_qam_consts =', real_qam_consts)\n",
    "        imag_qam_consts = np.empty((mod_n), dtype=np.int64)\n",
    "        # print('imag_qam_consts =', imag_qam_consts)\n",
    "        for i in range(sqrt_mod_n):\n",
    "            for j in range(sqrt_mod_n):\n",
    "                    index = sqrt_mod_n*i + j\n",
    "                    real_qam_consts[index] = i\n",
    "                    imag_qam_consts[index] = j\n",
    "        print('real_qam_consts =', real_qam_consts)\n",
    "        print('imag_qam_consts =', imag_qam_consts)\n",
    "        a = self.constellation[real_qam_consts]\n",
    "        b = self.constellation[imag_qam_consts]\n",
    "        return(a, b)\n",
    "\n",
    "# Deep Image Prior\n",
    "dip = DeepImagePrior(user_num=NUM_RX_ANT,      # Number of transmitted symbol in real domain\n",
    "                    M=16,              # Modulation order, 4 for 4qam, 16 for 16qam\n",
    "                    iteration=100,    # Number of max iterations used for DIP: 100\n",
    "                    LR=0.01,          # Learning rate,  typically set to 0.01\n",
    "                    buffer_size=30,   # Iterations stored,  typically set to 30\n",
    "                    threshold=0.001,  # Threshold of DIP stop,, typically set to 0.001\n",
    "                    stop=True)        # True\n",
    "\n",
    "# print(dip.QAM_const())\n",
    "dip.QAM_const()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tf.Tensor(\n",
      "[[1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j\n",
      "  1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j]\n",
      " [1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j\n",
      "  1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j]], shape=(2, 16), dtype=complex128)\n",
      "y_reshape_1col_real = tf.Tensor(\n",
      "[[ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]], shape=(32, 2), dtype=float64)\n",
      "X = tf.Tensor(\n",
      "[[1.+1.j]\n",
      " [2.+2.j]\n",
      " [3.+3.j]], shape=(3, 1), dtype=complex128)\n",
      "H = tf.Tensor(\n",
      "[[ 1. +2.j  3. +4.j  5. +6.j]\n",
      " [ 7. +8.j  9.+10.j 11.+12.j]\n",
      " [13.+14.j 15.+16.j 17.+18.j]], shape=(3, 3), dtype=complex128)\n",
      "Y = tf.Tensor(\n",
      "[[-6. +50.j]\n",
      " [-6.+122.j]\n",
      " [-6.+194.j]], shape=(3, 1), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "\n",
    "NUM_TX_ANT = 4\n",
    "y = tf.constant([[1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j],[1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j]]);\n",
    "print('y =',y)\n",
    "# y_reshape_1row = tf.reshape(y,shape=[1,-1])\n",
    "# print('x_reshape_1row =',x_reshape_1row)\n",
    "# y_reshape_2col4row = tf.reshape(y,shape=[-1,NUM_TX_ANT])\n",
    "# print('y_reshape_2col4row =',y_reshape_2col4row)\n",
    "# y_reshape_1col = tf.transpose(y)\n",
    "# print('y_reshape_1col =',y_reshape_1col)\n",
    "shape_y = tf.shape(y)\n",
    "# print('shape_y =',shape_y)\n",
    "y_reshape_1col = tf.reshape(y,shape=[-1,1])\n",
    "# print('y_reshape_1col =',y_reshape_1col)\n",
    "\n",
    "# y_channel = tf.expand_dims(y_reshape_2col4row, axis=-1)\n",
    "# print('y_channel =',y_channel)\n",
    "\n",
    "# hdd = [];\n",
    "\n",
    "y_reshape_1col_real_part = tf.math.real(y_reshape_1col);\n",
    "# print('y_reshape_1col_real_part =',y_reshape_1col_real_part)\n",
    "y_reshape_1col_imag_part = tf.math.imag(y_reshape_1col);\n",
    "# print('y_reshape_1col_imag_part =',y_reshape_1col_imag_part)\n",
    "y_reshape_1col_real = tf.concat([y_reshape_1col_real_part, y_reshape_1col_imag_part], axis=1) #(batch,168)\n",
    "print('y_reshape_1col_real =',y_reshape_1col_real)\n",
    "\n",
    "# y_reshape_2col4row_real_part = tf.math.real(y_reshape_2col4row);\n",
    "# print('y_real_part =',y_reshape_2col4row_real_part)\n",
    "# y_reshape_2col4row_imag_part = tf.math.imag(y_reshape_2col4row);\n",
    "# print('y_imag_part =',y_reshape_2col4row_imag_part)\n",
    "\n",
    "# y_reshape_2col4row_real = tf.concat([y_reshape_2col4row_real_part, y_reshape_2col4row_imag_part], axis=1) # (batch,158), axis=1(Second Diomension)\n",
    "# print('y_reshape_real =',y_reshape_2col4row_real)\n",
    "\n",
    "# y_reshape_1col_real_part = tf.math.real(y_reshape_1col);\n",
    "# print('y_reshape_1col_real_part =',y_reshape_1col_real_part)\n",
    "# y_reshape_1col_imag_part = tf.math.imag(y_reshape_1col);\n",
    "# print('y_reshape_1col_imag_part =',y_reshape_1col_imag_part)\n",
    "\n",
    "# y_reshape_real = tf.concat([y_reshape_1col_real_part, y_reshape_1col_imag_part], axis=1) # (batch,158), axis=1(Second Diomension)\n",
    "# print('y_reshape_real =',y_reshape_real)\n",
    "\n",
    "\n",
    "# y_real_part = np.real(y);\n",
    "# y_imag_part = np.imag(y);\n",
    "# y_real = np.concatenate([y_real_part, y_imag_part], axis=1) #(batch,168)\n",
    "# Hr = np.real(hdd);\n",
    "# Hi = np. imag(hdd);\n",
    "# hdd_real = np.concatenate([np.concatenate([Hr, -Hi], axis=2), np.concatenate([Hi, Hr], axis=2)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[1.+2.j]\n",
      " [3.+4.j]\n",
      " [5.+6.j]], shape=(3, 1), dtype=complex128)\n",
      "H = tf.Tensor(\n",
      "[[ 1. +2.j  3. +4.j  5. +6.j]\n",
      " [ 7. +8.j  9.+10.j 11.+12.j]\n",
      " [13.+14.j 15.+16.j 17.+18.j]], shape=(3, 3), dtype=complex128)\n",
      "Y = tf.Tensor(\n",
      "[[-21. +88.j]\n",
      " [-39.+214.j]\n",
      " [-57.+340.j]], shape=(3, 1), dtype=complex128)\n",
      "sum_complex = tf.Tensor(\n",
      "[[-21. +88.j]\n",
      " [-39.+214.j]\n",
      " [-57.+340.j]], shape=(3, 1), dtype=complex128)\n",
      "Y = sum_complex!!!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "NUM_RX_ANT = 3\n",
    "NUM_TX_ANT = 3\n",
    "X = tf.constant([[1+2j],[3+4j],[5+6j]])\n",
    "print('X =',X)\n",
    "H = tf.constant([[1+2j,3+4j,5+6j],[7+8j,9+10j,11+12j],[13+14j,15+16j,17+18j]])\n",
    "print('H =',H)\n",
    "H_shape = tf.shape(H)\n",
    "# print('H_shape =',H_shape)\n",
    "Y = tf.matmul(H, X)\n",
    "print('Y =',Y)\n",
    "\n",
    "X_real_part = tf.math.real(X);\n",
    "# print('X_real_part =',X_real_part)\n",
    "X_imag_part = tf.math.imag(X);\n",
    "# print('X_imag_part =',X_imag_part)\n",
    "X_real = tf.concat([X_real_part, X_imag_part], axis=1)\n",
    "# print('X_real =',X_real)\n",
    "e = tf.reshape(X_real,[BATCH_SIZE,NUM_TX_ANT,2,1]) # [BATCH_SIZE,NUM_TX_ANT,2,1] = [1,-1,2,1]\n",
    "# print('e =',e)\n",
    "repeat_times = NUM_RX_ANT\n",
    "f = tf.repeat(e, repeat_times, axis=0)\n",
    "# print('f =',f)\n",
    "\n",
    "Y_real_part = tf.math.real(Y);\n",
    "# print('Y_real_part =',Y_real_part)\n",
    "Y_imag_part = tf.math.imag(Y);\n",
    "# print('Y_imag_part =',Y_imag_part)\n",
    "Y_real = tf.concat([Y_real_part, Y_imag_part], axis=1)\n",
    "# print('Y_real =',Y_real)\n",
    "\n",
    "H_Reshaped = tf.reshape(H,[-1,1])\n",
    "# print('H_Reshaped =',H_Reshaped)\n",
    "H_Reshaped_real_part = tf.math.real(H_Reshaped);\n",
    "# print('H_Reshaped_real_part =',H_Reshaped_real_part)\n",
    "H_Reshaped_imag_part = tf.math.imag(H_Reshaped);\n",
    "# print('H_Reshaped_imag_part =',H_Reshaped_imag_part);\n",
    "\n",
    "H_real_part_Reshaped = tf.reshape(H_Reshaped_real_part,[1,-1,1])\n",
    "# print('H_real_part_Reshaped =',H_real_part_Reshaped)\n",
    "H_imag_part_Reshaped = tf.reshape(H_Reshaped_imag_part,[1,-1,1])\n",
    "# print('H_imag_part_Reshaped =',H_imag_part_Reshaped)\n",
    "\n",
    "b = tf.concat([H_real_part_Reshaped, -H_imag_part_Reshaped], axis=2)\n",
    "# print('b =',b)\n",
    "c = tf.concat([H_imag_part_Reshaped, H_real_part_Reshaped], axis=2)\n",
    "# print('c =',c)\n",
    "b_trans = tf.transpose(b, (1, 0, 2))\n",
    "# print('b_trans =',b_trans)\n",
    "c_trans = tf.transpose(c, (1, 0, 2))\n",
    "# print('c_trans =',c_trans)\n",
    "d = tf.concat([b_trans, c_trans], axis=1)\n",
    "# print('d =',d)\n",
    "g = tf.reshape(d,[3,3,2,2]) # [NUM_RX_ANT,NUM_TX_ANT,2,2] = [3,3,2,2]\n",
    "# print('g =',g)\n",
    "# H_Reshaped_real = tf.concat([tf.concat([H_real_part_Reshaped, -H_imag_part_Reshaped], axis=2), tf.concat([H_imag_part_Reshaped, H_real_part_Reshaped], axis=2)],axis=1)\n",
    "result = tf.matmul(g, f)\n",
    "# print('result =',result)\n",
    "sum = tf.reduce_sum(result, axis=1)\n",
    "# print('sum =',sum)\n",
    "sum_real,sum_imag = tf.split(sum, num_or_size_splits=2, axis=1)\n",
    "# print('sum_real =',sum_real)\n",
    "# print('sum_imag =',sum_imag)\n",
    "sum_complex = tf.squeeze(tf.complex(sum_real,sum_imag),axis=-1)\n",
    "print('sum_complex =',sum_complex)\n",
    "if all(Y == sum_complex):\n",
    "    print('Y = sum_complex!!!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[[1.+2.j]\n",
      "  [3.+4.j]\n",
      "  [5.+6.j]]\n",
      "\n",
      " [[1.+2.j]\n",
      "  [3.+4.j]\n",
      "  [5.+6.j]]], shape=(2, 3, 1), dtype=complex128)\n",
      "H = tf.Tensor(\n",
      "[[[ 1. +2.j  3. +4.j  5. +6.j]\n",
      "  [ 7. +8.j  9.+10.j 11.+12.j]\n",
      "  [13.+14.j 15.+16.j 17.+18.j]]\n",
      "\n",
      " [[ 1. +2.j  3. +4.j  5. +6.j]\n",
      "  [ 7. +8.j  9.+10.j 11.+12.j]\n",
      "  [13.+14.j 15.+16.j 17.+18.j]]], shape=(2, 3, 3), dtype=complex128)\n",
      "Y = tf.Tensor(\n",
      "[[[-21. +88.j]\n",
      "  [-39.+214.j]\n",
      "  [-57.+340.j]]\n",
      "\n",
      " [[-21. +88.j]\n",
      "  [-39.+214.j]\n",
      "  [-57.+340.j]]], shape=(2, 3, 1), dtype=complex128)\n",
      "e = tf.Tensor(\n",
      "[[[[1.]\n",
      "   [2.]]\n",
      "\n",
      "  [[3.]\n",
      "   [4.]]\n",
      "\n",
      "  [[5.]\n",
      "   [6.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [2.]]\n",
      "\n",
      "  [[3.]\n",
      "   [4.]]\n",
      "\n",
      "  [[5.]\n",
      "   [6.]]]], shape=(2, 3, 2, 1), dtype=float64)\n",
      "X_real = tf.Tensor(\n",
      "[[[[[1.]\n",
      "    [2.]]\n",
      "\n",
      "   [[3.]\n",
      "    [4.]]\n",
      "\n",
      "   [[5.]\n",
      "    [6.]]]\n",
      "\n",
      "\n",
      "  [[[1.]\n",
      "    [2.]]\n",
      "\n",
      "   [[3.]\n",
      "    [4.]]\n",
      "\n",
      "   [[5.]\n",
      "    [6.]]]\n",
      "\n",
      "\n",
      "  [[[1.]\n",
      "    [2.]]\n",
      "\n",
      "   [[3.]\n",
      "    [4.]]\n",
      "\n",
      "   [[5.]\n",
      "    [6.]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[1.]\n",
      "    [2.]]\n",
      "\n",
      "   [[3.]\n",
      "    [4.]]\n",
      "\n",
      "   [[5.]\n",
      "    [6.]]]\n",
      "\n",
      "\n",
      "  [[[1.]\n",
      "    [2.]]\n",
      "\n",
      "   [[3.]\n",
      "    [4.]]\n",
      "\n",
      "   [[5.]\n",
      "    [6.]]]\n",
      "\n",
      "\n",
      "  [[[1.]\n",
      "    [2.]]\n",
      "\n",
      "   [[3.]\n",
      "    [4.]]\n",
      "\n",
      "   [[5.]\n",
      "    [6.]]]]], shape=(2, 3, 3, 2, 1), dtype=float64)\n",
      "Y_real = tf.Tensor(\n",
      "[[[[-21.]\n",
      "   [ 88.]]\n",
      "\n",
      "  [[-39.]\n",
      "   [214.]]\n",
      "\n",
      "  [[-57.]\n",
      "   [340.]]]\n",
      "\n",
      "\n",
      " [[[-21.]\n",
      "   [ 88.]]\n",
      "\n",
      "  [[-39.]\n",
      "   [214.]]\n",
      "\n",
      "  [[-57.]\n",
      "   [340.]]]], shape=(2, 3, 2, 1), dtype=float64)\n",
      "H_real = tf.Tensor(\n",
      "[[[[[  1.  -2.]\n",
      "    [  2.   1.]]\n",
      "\n",
      "   [[  3.  -4.]\n",
      "    [  4.   3.]]\n",
      "\n",
      "   [[  5.  -6.]\n",
      "    [  6.   5.]]]\n",
      "\n",
      "\n",
      "  [[[  7.  -8.]\n",
      "    [  8.   7.]]\n",
      "\n",
      "   [[  9. -10.]\n",
      "    [ 10.   9.]]\n",
      "\n",
      "   [[ 11. -12.]\n",
      "    [ 12.  11.]]]\n",
      "\n",
      "\n",
      "  [[[ 13. -14.]\n",
      "    [ 14.  13.]]\n",
      "\n",
      "   [[ 15. -16.]\n",
      "    [ 16.  15.]]\n",
      "\n",
      "   [[ 17. -18.]\n",
      "    [ 18.  17.]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[  1.  -2.]\n",
      "    [  2.   1.]]\n",
      "\n",
      "   [[  3.  -4.]\n",
      "    [  4.   3.]]\n",
      "\n",
      "   [[  5.  -6.]\n",
      "    [  6.   5.]]]\n",
      "\n",
      "\n",
      "  [[[  7.  -8.]\n",
      "    [  8.   7.]]\n",
      "\n",
      "   [[  9. -10.]\n",
      "    [ 10.   9.]]\n",
      "\n",
      "   [[ 11. -12.]\n",
      "    [ 12.  11.]]]\n",
      "\n",
      "\n",
      "  [[[ 13. -14.]\n",
      "    [ 14.  13.]]\n",
      "\n",
      "   [[ 15. -16.]\n",
      "    [ 16.  15.]]\n",
      "\n",
      "   [[ 17. -18.]\n",
      "    [ 18.  17.]]]]], shape=(2, 3, 3, 2, 2), dtype=float64)\n",
      "H_bs1_1166 = tf.Tensor(\n",
      "[[[[  1.  -2.   2.   1.   3.  -4.]\n",
      "   [  4.   3.   5.  -6.   6.   5.]\n",
      "   [  7.  -8.   8.   7.   9. -10.]\n",
      "   [ 10.   9.  11. -12.  12.  11.]\n",
      "   [ 13. -14.  14.  13.  15. -16.]\n",
      "   [ 16.  15.  17. -18.  18.  17.]]]], shape=(1, 1, 6, 6), dtype=float64)\n",
      "X_bs1_1161 = tf.Tensor(\n",
      "[[[[1. 2. 3.]\n",
      "   [4. 5. 6.]\n",
      "   [1. 2. 3.]\n",
      "   [4. 5. 6.]\n",
      "   [1. 2. 3.]\n",
      "   [4. 5. 6.]]]], shape=(1, 1, 6, 3), dtype=float64)\n",
      "Y_bs1_1161 = tf.Tensor(\n",
      "[[[[-14. -13. -12.]\n",
      "   [ 23.  40.  57.]\n",
      "   [-20.  -7.   6.]\n",
      "   [ 65. 106. 147.]\n",
      "   [-26.  -1.  24.]\n",
      "   [107. 172. 237.]]]], shape=(1, 1, 6, 3), dtype=float64)\n",
      "result = tf.Tensor(\n",
      "[[[[[ -3.]\n",
      "    [  4.]]\n",
      "\n",
      "   [[ -7.]\n",
      "    [ 24.]]\n",
      "\n",
      "   [[-11.]\n",
      "    [ 60.]]]\n",
      "\n",
      "\n",
      "  [[[ -9.]\n",
      "    [ 22.]]\n",
      "\n",
      "   [[-13.]\n",
      "    [ 66.]]\n",
      "\n",
      "   [[-17.]\n",
      "    [126.]]]\n",
      "\n",
      "\n",
      "  [[[-15.]\n",
      "    [ 40.]]\n",
      "\n",
      "   [[-19.]\n",
      "    [108.]]\n",
      "\n",
      "   [[-23.]\n",
      "    [192.]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ -3.]\n",
      "    [  4.]]\n",
      "\n",
      "   [[ -7.]\n",
      "    [ 24.]]\n",
      "\n",
      "   [[-11.]\n",
      "    [ 60.]]]\n",
      "\n",
      "\n",
      "  [[[ -9.]\n",
      "    [ 22.]]\n",
      "\n",
      "   [[-13.]\n",
      "    [ 66.]]\n",
      "\n",
      "   [[-17.]\n",
      "    [126.]]]\n",
      "\n",
      "\n",
      "  [[[-15.]\n",
      "    [ 40.]]\n",
      "\n",
      "   [[-19.]\n",
      "    [108.]]\n",
      "\n",
      "   [[-23.]\n",
      "    [192.]]]]], shape=(2, 3, 3, 2, 1), dtype=float64)\n",
      "sum = tf.Tensor(\n",
      "[[[[-21.]\n",
      "   [ 88.]]\n",
      "\n",
      "  [[-39.]\n",
      "   [214.]]\n",
      "\n",
      "  [[-57.]\n",
      "   [340.]]]\n",
      "\n",
      "\n",
      " [[[-21.]\n",
      "   [ 88.]]\n",
      "\n",
      "  [[-39.]\n",
      "   [214.]]\n",
      "\n",
      "  [[-57.]\n",
      "   [340.]]]], shape=(2, 3, 2, 1), dtype=float64)\n",
      "Y = sum_complex!!!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_RX_ANT = 3\n",
    "NUM_TX_ANT = 3\n",
    "X = tf.constant([[[1+2j],[3+4j],[5+6j]],[[1+2j],[3+4j],[5+6j]]])\n",
    "print('X =',X)\n",
    "H = tf.constant([[[1+2j,3+4j,5+6j],[7+8j,9+10j,11+12j],[13+14j,15+16j,17+18j]],[[1+2j,3+4j,5+6j],[7+8j,9+10j,11+12j],[13+14j,15+16j,17+18j]]])\n",
    "print('H =',H)\n",
    "H_shape = tf.shape(H)\n",
    "# print('H_shape =',H_shape)\n",
    "# print('BATCH_SIZE =',H.shape[0])\n",
    "Y = tf.matmul(H, X)\n",
    "print('Y =',Y)\n",
    "\n",
    "X_real_part = tf.math.real(X);\n",
    "# print('X_real_part =',X_real_part)\n",
    "X_imag_part = tf.math.imag(X);\n",
    "# print('X_imag_part =',X_imag_part)\n",
    "X_temp_real = tf.concat([X_real_part, X_imag_part], axis=2)\n",
    "# print('X_real =',X_real)\n",
    "e = tf.reshape(X_temp_real,[BATCH_SIZE,NUM_TX_ANT,2,1]) # [BATCH_SIZE,NUM_TX_ANT,2,1] = [1,-1,2,1]\n",
    "print('e =',e)\n",
    "# X_fake_real = tf.repeat(e, repeats=NUM_RX_ANT, axis=0)\n",
    "# print('X_fake_real =',X_fake_real)\n",
    "X_real = tf.reshape(tf.repeat(e, repeats=NUM_RX_ANT, axis=0),[BATCH_SIZE,NUM_RX_ANT,NUM_TX_ANT,2,1])\n",
    "print('X_real =',X_real)\n",
    "\n",
    "Y_real_part = tf.math.real(Y);\n",
    "# print('Y_real_part =',Y_real_part)\n",
    "Y_imag_part = tf.math.imag(Y);\n",
    "# print('Y_imag_part =',Y_imag_part)\n",
    "Y_real_part_reshaped = tf.reshape(Y_real_part,[BATCH_SIZE,NUM_RX_ANT,1,1])\n",
    "# print('Y_real_part_reshaped =',Y_real_part_reshaped)\n",
    "Y_imag_part_reshaped = tf.reshape(Y_imag_part,[BATCH_SIZE,NUM_RX_ANT,1,1])\n",
    "# print('Y_imag_part_reshaped =',Y_imag_part_reshaped)\n",
    "Y_real = tf.concat([Y_real_part_reshaped, Y_imag_part_reshaped], axis=2)\n",
    "print('Y_real =',Y_real)\n",
    "\n",
    "H_Reshaped = tf.reshape(H,[BATCH_SIZE,-1,1])\n",
    "# print('H_Reshaped =',H_Reshaped)\n",
    "H_Reshaped_real_part = tf.math.real(H_Reshaped);\n",
    "# print('H_Reshaped_real_part =',H_Reshaped_real_part)\n",
    "H_Reshaped_imag_part = tf.math.imag(H_Reshaped);\n",
    "# print('H_Reshaped_imag_part =',H_Reshaped_imag_part);\n",
    "\n",
    "H_real_part_Reshaped = tf.reshape(H_Reshaped_real_part,[BATCH_SIZE,-1,1])\n",
    "# print('H_real_part_Reshaped =',H_real_part_Reshaped)\n",
    "H_imag_part_Reshaped = tf.reshape(H_Reshaped_imag_part,[BATCH_SIZE,-1,1])\n",
    "# print('H_imag_part_Reshaped =',H_imag_part_Reshaped)\n",
    "\n",
    "b = tf.concat([H_real_part_Reshaped, -H_imag_part_Reshaped], axis=2)\n",
    "# print('b =',b)\n",
    "c = tf.concat([H_imag_part_Reshaped, H_real_part_Reshaped], axis=2)\n",
    "# print('c =',c)\n",
    "b_trans = tf.reshape(b, [BATCH_SIZE, NUM_RX_ANT*NUM_TX_ANT, -1, 2])\n",
    "# print('b_trans =',b_trans)\n",
    "c_trans = tf.reshape(c, [BATCH_SIZE, NUM_RX_ANT*NUM_TX_ANT, -1, 2])\n",
    "# print('c_trans =',c_trans)\n",
    "d = tf.concat([b_trans, c_trans], axis=2)\n",
    "# print('d =',d)\n",
    "H_real = tf.reshape(d,[BATCH_SIZE,NUM_RX_ANT,NUM_TX_ANT,2,2])\n",
    "print('H_real =',H_real)\n",
    "\n",
    "H_bs1_1166 = tf.reshape(H_real[1],[1,1,2*NUM_RX_ANT,2*NUM_TX_ANT])\n",
    "print('H_bs1_1166 =',H_bs1_1166)\n",
    "X_bs1_1161 = tf.reshape(X_real[1],[1,1,2*NUM_TX_ANT,3])\n",
    "print('X_bs1_1161 =',X_bs1_1161)\n",
    "Y_bs1_1161 = tf.matmul(H_bs1_1166, X_bs1_1161)\n",
    "print('Y_bs1_1161 =',Y_bs1_1161)\n",
    "\n",
    "# H_Reshaped_real = tf.concat([tf.concat([H_real_part_Reshaped, -H_imag_part_Reshaped], axis=2), tf.concat([H_imag_part_Reshaped, H_real_part_Reshaped], axis=2)],axis=1)\n",
    "result = tf.matmul(H_real, X_real)\n",
    "print('result =',result)\n",
    "sum = tf.reduce_sum(result, axis=2)\n",
    "print('sum =',sum)\n",
    "sum_real_part,sum_imag_part = tf.split(sum, num_or_size_splits=2, axis=2)\n",
    "# print('sum_real =',sum_real)\n",
    "# print('sum_imag =',sum_imag)\n",
    "sum_complex = tf.squeeze(tf.complex(sum_real_part,sum_imag_part),axis=-1)\n",
    "# print('sum_complex =',sum_complex)\n",
    "if tf.reduce_all(tf.equal(Y,sum_complex)):\n",
    "    print('Y = sum_complex!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([[[1.+2.j],\n",
      "         [3.+4.j],\n",
      "         [5.+6.j]],\n",
      "\n",
      "        [[1.+2.j],\n",
      "         [3.+4.j],\n",
      "         [5.+6.j]]])\n",
      "e = tensor([[[[1.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [4.]],\n",
      "\n",
      "         [[5.],\n",
      "          [6.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [4.]],\n",
      "\n",
      "         [[5.],\n",
      "          [6.]]]])\n",
      "e shape = torch.Size([2, 3, 2, 1])\n",
      "X_real shape = torch.Size([2, 3, 3, 2, 1])\n",
      "X_real = tensor([[[[[1.],\n",
      "           [2.]],\n",
      "\n",
      "          [[3.],\n",
      "           [4.]],\n",
      "\n",
      "          [[5.],\n",
      "           [6.]]],\n",
      "\n",
      "\n",
      "         [[[1.],\n",
      "           [2.]],\n",
      "\n",
      "          [[3.],\n",
      "           [4.]],\n",
      "\n",
      "          [[5.],\n",
      "           [6.]]],\n",
      "\n",
      "\n",
      "         [[[1.],\n",
      "           [2.]],\n",
      "\n",
      "          [[3.],\n",
      "           [4.]],\n",
      "\n",
      "          [[5.],\n",
      "           [6.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1.],\n",
      "           [2.]],\n",
      "\n",
      "          [[3.],\n",
      "           [4.]],\n",
      "\n",
      "          [[5.],\n",
      "           [6.]]],\n",
      "\n",
      "\n",
      "         [[[1.],\n",
      "           [2.]],\n",
      "\n",
      "          [[3.],\n",
      "           [4.]],\n",
      "\n",
      "          [[5.],\n",
      "           [6.]]],\n",
      "\n",
      "\n",
      "         [[[1.],\n",
      "           [2.]],\n",
      "\n",
      "          [[3.],\n",
      "           [4.]],\n",
      "\n",
      "          [[5.],\n",
      "           [6.]]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_RX_ANT = 3\n",
    "NUM_TX_ANT = 3\n",
    "X = torch.tensor([[[1+2j],[3+4j],[5+6j]],[[1+2j],[3+4j],[5+6j]]])\n",
    "print('X =',X)\n",
    "X_real_part = torch.real(X);\n",
    "# print('X_real_part =',X_real_part)\n",
    "X_imag_part = torch.imag(X);\n",
    "# print('X_imag_part =',X_imag_part)\n",
    "X_temp_real = torch.cat([X_real_part, X_imag_part], dim=2)\n",
    "# print('X_real =',X_real)\n",
    "e = torch.reshape(X_temp_real,[BATCH_SIZE,NUM_TX_ANT,2,1]) # [BATCH_SIZE,NUM_TX_ANT,2,1] = [1,-1,2,1]\n",
    "print('e =',e)\n",
    "print('e shape =',e.shape)\n",
    "X_real = torch.reshape(e.repeat(NUM_RX_ANT,1,1,1),[BATCH_SIZE,NUM_RX_ANT,NUM_TX_ANT,2,1])\n",
    "print('X_real shape =',X_real.shape)\n",
    "print('X_real =',X_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.1937],\n",
      "          [ 0.3977]],\n",
      "\n",
      "         [[ 0.5643],\n",
      "          [-0.4291]],\n",
      "\n",
      "         [[-0.6503],\n",
      "          [-0.1561]]]])\n",
      "tensor([[[[ 1.1937],\n",
      "          [ 0.3977]],\n",
      "\n",
      "         [[ 0.5643],\n",
      "          [-0.4291]],\n",
      "\n",
      "         [[-0.6503],\n",
      "          [-0.1561]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1937],\n",
      "          [ 0.3977]],\n",
      "\n",
      "         [[ 0.5643],\n",
      "          [-0.4291]],\n",
      "\n",
      "         [[-0.6503],\n",
      "          [-0.1561]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1937],\n",
      "          [ 0.3977]],\n",
      "\n",
      "         [[ 0.5643],\n",
      "          [-0.4291]],\n",
      "\n",
      "         [[-0.6503],\n",
      "          [-0.1561]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(1, 3, 2, 1)\n",
    "y = x.repeat(3, 1, 1, 1)\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[10  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]]\n",
      "[7. 5. 6.]\n",
      "[-5.  -2.5  0.   2.5  5.   7.5 10.  12.5 15.  17.5 20. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 生成一个二维空数组\n",
    "arr = np.empty((0, 0))\n",
    "\n",
    "print(arr)\n",
    "\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 对二维数组的某个位置元素赋值\n",
    "row_index = 0  # 要赋值的行索引\n",
    "col_index = 0  # 要赋值的列索引\n",
    "value = 10  # 要赋的值\n",
    "\n",
    "arr[row_index, col_index] = value\n",
    "\n",
    "print(arr)\n",
    "\n",
    "\n",
    "column_means = np.mean(arr, axis=0)\n",
    "print(column_means)\n",
    "\n",
    "print(np.linspace(-5,20,11))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成示例数据\n",
    "x = np.random.rand(50)\n",
    "y = np.random.rand(50)\n",
    "colors = np.random.rand(50)\n",
    "labels = np.arange(50)\n",
    "\n",
    "# 绘制散点图\n",
    "plt.scatter(x, y, c=colors, label=labels)\n",
    "\n",
    "# 设置图例\n",
    "plt.legend()\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 0\n",
      "Data Group 0\n",
      "Processing...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# GPU Configuration and Imports\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "    \n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from xyDIP import DeepImagePrior\n",
    "from complex2real import Complex2Real\n",
    "\n",
    "k = 4 # Block Length:512\n",
    "NUM_TX_ANT = 4 # Transmit Antennas: 4\n",
    "NUM_RX_ANT = 4 # Receive Antennas: 4\n",
    "NUM_BITS_PER_SYMBOL = 4 # Mapping: 16QAM\n",
    "BATCH_SIZE = 1 # Numerbe of Parallelly Processed Batches: 32\n",
    "EBN0_DB_MIN = -5.0 # Minimum Eb/N0 (dB): -5\n",
    "EBN0_DB_MAX = 5.0 # Maximum Eb/N0 (dB): 20\n",
    "NUM_EBN0_POINTS = 2 # EBNO Points: 11\n",
    "NUM_DATA_GROUP = 1\n",
    "\n",
    "snrs = np.linspace(EBN0_DB_MIN,EBN0_DB_MAX,NUM_EBN0_POINTS)\n",
    "bers = []\n",
    "sers_zf = np.empty((NUM_DATA_GROUP, NUM_EBN0_POINTS))\n",
    "sers_lmmse = np.empty((NUM_DATA_GROUP, NUM_EBN0_POINTS))\n",
    "sers_dip = np.empty((NUM_DATA_GROUP, NUM_EBN0_POINTS))\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "\n",
    "# SymbolDemapper\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "\n",
    "# Deep Image Prior\n",
    "dip = DeepImagePrior(num_rx_ant=NUM_RX_ANT,\n",
    "                    num_tx_ant=NUM_TX_ANT,      # Number of transmitted symbol in real domain\n",
    "                    M=16,              # Modulation order, 4 for 4QAM, 16 for 16QAM; 16QAM: 4 bits per symbol\n",
    "                    iteration=100,    # Number of max iterations used for DIP: 100\n",
    "                    LR=0.01,          # Learning rate,  typically set to 0.01\n",
    "                    buffer_size=30,   # Iterations stored,  typically set to 30\n",
    "                    threshold=0.001,  # Threshold of DIP stop,, typically set to 0.001\n",
    "                    stop=True)        # True\n",
    "\n",
    "# Complex2Real\n",
    "c2r = Complex2Real(NUM_RX_ANT,NUM_TX_ANT)\n",
    "\n",
    "for i in range(0, NUM_DATA_GROUP):\n",
    "\n",
    "    print('Data Group {}'.format(i))\n",
    "    print('Processing...')\n",
    "\n",
    "    b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "    # print('b shape =',b.shape)\n",
    "\n",
    "    x = mapper(b)\n",
    "    # print('x shape =',x.shape)\n",
    "    # print('x =',x)\n",
    "\n",
    "    shape = tf.shape(x)\n",
    "    x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "    # print('x reshape =',x_reshape.shape)\n",
    "    # print('x_reshape =',x_reshape)\n",
    "\n",
    "    # Tx_Symbols = bits2symbol(b,NUM_BITS_PER_SYMBOL)\n",
    "    # print('Tx_Symbols =',Tx_Symbols)\n",
    "    \n",
    "    j = 0\n",
    "    \n",
    "    for EBN0_DB in np.linspace(EBN0_DB_MIN,EBN0_DB_MAX,NUM_EBN0_POINTS):\n",
    "        \n",
    "        # print('EBN0_DB =',EBN0_DB)\n",
    "\n",
    "        no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                                num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                                coderate=1.0) # Coderate set to 1 as we do uncoded transmission here\n",
    "        # print('no =',no)\n",
    "\n",
    "        x_ind = symbol_demapper([x, no])\n",
    "        # print('x_ind.shape =',x_ind.shape)\n",
    "        # print('x_ind =',x_ind)\n",
    "\n",
    "        # y and h are the Channel Output and Channel Realizations, respectively.\n",
    "        y, h = flatfading_channel([x_reshape, no])\n",
    "        # print('h.shape =\\n',h.shape)\n",
    "        # print('y.shape =\\n',y.shape)\n",
    "\n",
    "        s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "\n",
    "        x_hat_zf, no_eff_zf = zf_equalizer(y, h, s)\n",
    "        # print('x_hat_zf.shape =',x_hat_zf.shape)\n",
    "        # print('x_hat_zf =',x_hat_zf)\n",
    "        x_hat_lmmse, no_eff_lmmse = lmmse_equalizer(y, h, s)\n",
    "        # print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "\n",
    "        X_inCH_real,H_real,Y_real = c2r.C2R(x_reshape,h,y)\n",
    "        # print('X_inCH_real =',X_inCH_real)\n",
    "        # print('max =',np.max(X_inCH_real))\n",
    "        # print('H_real =',H_real)\n",
    "        # print('Y_real =',Y_real)\n",
    "\n",
    "        x_dip_ay,num_stop_point = dip.DIP(Y_real,H_real)\n",
    "        # print('x_dip_ay.shape =',x_dip_ay.shape)\n",
    "        # print('x_dip =',x_dip_ay)\n",
    "        # print('num_stop_point =',num_stop_point)\n",
    "        x_dip_ay_real_part,x_dip_ay_imag_part = tf.split(x_dip_ay, num_or_size_splits=2, axis=2)\n",
    "        # print('sum_real =',sum_real)\n",
    "        # print('sum_imag =',sum_imag)\n",
    "        x_hat_dip = tf.squeeze(tf.squeeze(tf.complex(x_dip_ay_real_part,x_dip_ay_imag_part),axis=-1),axis=-1)\n",
    "        # print('x_hat_dip =',x_hat_dip)\n",
    "\n",
    "        x_hat_zf = tf.reshape(x_hat_zf, shape)\n",
    "        # print('x_hat_zf.shape =',x_hat_zf.shape)\n",
    "        x_hat_lmmse = tf.reshape(x_hat_lmmse, shape)\n",
    "        # print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "        x_hat_dip = tf.reshape(x_hat_dip, shape)\n",
    "        # print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "\n",
    "        # no_eff_zf = tf.reshape(no_eff_zf, shape)\n",
    "        # no_eff_lmmse = tf.reshape(no_eff_lmmse, shape)\n",
    "\n",
    "        # llr_zf = demapper([x_hat_zf, no_eff_zf])\n",
    "        # b_hat_zf = decoder(llr_zf)\n",
    "\n",
    "        x_ind_hat_zf = symbol_demapper([x_hat_zf, no])\n",
    "        # print('x_ind_hat_zf.shape =',x_ind_hat_zf.shape)\n",
    "        # print('x_ind_hat_zf =',x_ind_hat_zf)\n",
    "        x_ind_hat_lmmse = symbol_demapper([x_hat_lmmse, no])\n",
    "        # print('x_ind_hat_lmmse.shape =',x_ind_hat_lmmse.shape)\n",
    "        x_ind_hat_dip = symbol_demapper([tf.cast(x_hat_dip, dtype=tf.complex64), no])\n",
    "        # print('x_ind_hat_lmmse.shape =',x_ind_hat_lmmse.shape)\n",
    "\n",
    "        ser_zf = compute_ser(x_ind, x_ind_hat_zf)\n",
    "        ser_lmmse = compute_ser(x_ind, x_ind_hat_lmmse)\n",
    "        ser_dip = compute_ser(x_ind, x_ind_hat_dip)\n",
    "        sers_zf[i, j] = ser_zf\n",
    "        sers_lmmse[i, j] = ser_lmmse\n",
    "        sers_dip[i, j] = ser_dip\n",
    "\n",
    "        j = j+1\n",
    "    print('Done')\n",
    "\n",
    "sers_zf_mean = np.mean(sers_zf, axis=0)\n",
    "sers_lmmse_mean = np.mean(sers_lmmse, axis=0)\n",
    "sers_dip_mean = np.mean(sers_dip, axis=0)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.axes().set_aspect(1)\n",
    "plt.grid(True)\n",
    "plt.title('Flat-Fading Channel Constellation', fontsize=12)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlabel('REAL', fontsize=10)\n",
    "plt.ylabel('IMAG', fontsize=10)\n",
    "plt.scatter(tf.math.real(x), tf.math.imag(x), s=16, c='b', label='TX')\n",
    "plt.scatter(tf.math.real(x_hat_zf), tf.math.imag(x_hat_zf), s=16, c='y', label='ZF')\n",
    "plt.scatter(tf.math.real(x_hat_lmmse), tf.math.imag(x_hat_lmmse), s=16, c='g', label='LMMSE')\n",
    "plt.scatter(tf.math.real(x_hat_dip), tf.math.imag(x_hat_dip), s=16, c='r', label='DIP')\n",
    "plt.legend(loc='lower left', fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(2)\n",
    "title = \"SER: Noncoding MIMO Falt-Fading with ZF, MMSE, DIP Equalizer\"\n",
    "xlabel = \"$E_b/N_0$ (dB)\"\n",
    "ylabel = \"SER (log)\"\n",
    "plt.title(title, fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(xlabel, fontsize=10)\n",
    "plt.ylabel(ylabel, fontsize=10)\n",
    "plt.grid(which=\"both\")\n",
    "plt.semilogy(snrs, sers_zf_mean, 'b', label='ZF')\n",
    "plt.semilogy(snrs, sers_lmmse_mean, 'g', label='LMMSE')\n",
    "plt.semilogy(snrs, sers_dip_mean, 'r', label='DIP')\n",
    "plt.legend(loc='lower left', fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
