{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SPDX-FileCopyrightText: Copyright (c) 2021-2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "#\n",
    "\"\"\"Layers for (de)mapping, constellation class, and utility functions\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sionna as sn\n",
    "\n",
    "def pam_gray(b):\n",
    "\n",
    "    if len(b)>1:\n",
    "        return (1-2*b[0])*(2**len(b[1:]) - pam_gray(b[1:]))\n",
    "    return 1-2*b[0]\n",
    "\n",
    "def qam(num_bits_per_symbol, normalize=True):\n",
    "\n",
    "    try:\n",
    "        assert num_bits_per_symbol % 2 == 0 # is even\n",
    "        assert num_bits_per_symbol >0 # is larger than zero\n",
    "    except AssertionError as error:\n",
    "        raise ValueError(\"num_bits_per_symbol must be a multiple of 2\") \\\n",
    "        from error\n",
    "    assert isinstance(normalize, bool), \"normalize must be boolean\"\n",
    "\n",
    "    # Build constellation by iterating through all points\n",
    "    c = np.zeros([2**num_bits_per_symbol], dtype=np.complex64)\n",
    "    for i in range(0, 2**num_bits_per_symbol):\n",
    "        b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n",
    "                     dtype=np.int16)\n",
    "        c[i] = pam_gray(b[0::2]) + 1j*pam_gray(b[1::2]) # PAM in each dimension\n",
    "\n",
    "    if normalize: # Normalize to unit energy\n",
    "        n = int(num_bits_per_symbol/2)\n",
    "        qam_var = 1/(2**(n-2))*np.sum(np.linspace(1,2**n-1, 2**(n-1))**2)\n",
    "        c /= np.sqrt(qam_var)\n",
    "    return c\n",
    "\n",
    "def pam(num_bits_per_symbol, normalize=True):\n",
    "\n",
    "    try:\n",
    "        assert num_bits_per_symbol >0 # is larger than zero\n",
    "    except AssertionError as error:\n",
    "        raise ValueError(\"num_bits_per_symbol must be positive\") \\\n",
    "        from error\n",
    "    assert isinstance(normalize, bool), \"normalize must be boolean\"\n",
    "\n",
    "    # Build constellation by iterating through all points\n",
    "    c = np.zeros([2**num_bits_per_symbol], dtype=np.float32)\n",
    "    for i in range(0, 2**num_bits_per_symbol):\n",
    "        b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n",
    "                     dtype=np.int16)\n",
    "        c[i] = pam_gray(b)\n",
    "\n",
    "    if normalize: # Normalize to unit energy\n",
    "        n = int(num_bits_per_symbol)\n",
    "        pam_var = 1/(2**(n-1))*np.sum(np.linspace(1,2**n-1, 2**(n-1))**2)\n",
    "        c /= np.sqrt(pam_var)\n",
    "    return c\n",
    "\n",
    "class Constellation(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 constellation_type,\n",
    "                 num_bits_per_symbol,\n",
    "                 initial_value=None,\n",
    "                 normalize=True,\n",
    "                 center=False,\n",
    "                 trainable=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        assert dtype in [tf.complex64, tf.complex128],\\\n",
    "            \"dtype must be tf.complex64 or tf.complex128\"\n",
    "        self._dtype = dtype\n",
    "\n",
    "        assert constellation_type in (\"qam\", \"pam\", \"custom\"),\\\n",
    "            \"Wrong constellation type\"\n",
    "        self._constellation_type = constellation_type\n",
    "\n",
    "        assert isinstance(normalize, bool), \"normalize must be boolean\"\n",
    "        self._normalize = normalize\n",
    "\n",
    "        assert isinstance(center, bool), \"center must be boolean\"\n",
    "        self._center = center\n",
    "\n",
    "        assert isinstance(trainable, bool), \"trainable must be boolean\"\n",
    "        self._trainable = trainable\n",
    "\n",
    "        # allow float inputs that represent int\n",
    "        assert isinstance(num_bits_per_symbol, (float,int)),\\\n",
    "            \"num_bits_per_symbol must be integer\"\n",
    "        assert (num_bits_per_symbol%1==0),\\\n",
    "            \"num_bits_per_symbol must be integer\"\n",
    "        num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "\n",
    "        if self._constellation_type==\"qam\":\n",
    "            assert num_bits_per_symbol%2 == 0 and num_bits_per_symbol>0,\\\n",
    "                \"num_bits_per_symbol must be a multiple of 2\"\n",
    "            self._num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "\n",
    "            assert initial_value is None, \"QAM must not have an initial value\"\n",
    "            points = qam(self._num_bits_per_symbol, normalize=self.normalize)\n",
    "            points = tf.cast(points, self._dtype)\n",
    "\n",
    "        if self._constellation_type==\"pam\":\n",
    "            assert num_bits_per_symbol>0,\\\n",
    "                \"num_bits_per_symbol must be integer\"\n",
    "            self._num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "\n",
    "            assert initial_value is None, \"PAM must not have an initial value\"\n",
    "            points = pam(self._num_bits_per_symbol, normalize=self.normalize)\n",
    "            points = tf.cast(points, self._dtype)\n",
    "\n",
    "        if self._constellation_type==\"custom\":\n",
    "            assert num_bits_per_symbol>0,\\\n",
    "                \"num_bits_per_symbol must be integer\"\n",
    "            self._num_bits_per_symbol = int(num_bits_per_symbol)\n",
    "\n",
    "            # Randomly initialize points if no initial_value is provided\n",
    "            if initial_value is None:\n",
    "                points = tf.random.uniform(  # pylint: disable=E1123\n",
    "                                        [2, 2**self._num_bits_per_symbol],\n",
    "                                        minval=-0.05, maxval=0.05,\n",
    "                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n",
    "                points  = tf.complex(points[0], points[1])\n",
    "            else:\n",
    "                assert tf.rank(initial_value).numpy() == 1\n",
    "                assert tf.shape(initial_value)[0] == 2**num_bits_per_symbol,\\\n",
    "                    \"initial_value must have shape [2**num_bits_per_symbol]\"\n",
    "                points = tf.cast(initial_value, self._dtype)\n",
    "        self._points = points\n",
    "\n",
    "    def build(self, input_shape): #pylint: disable=unused-argument\n",
    "        points = self._points\n",
    "        points = tf.stack([tf.math.real(points),\n",
    "                           tf.math.imag(points)], axis=0)\n",
    "        if self._trainable:\n",
    "            self._points = tf.Variable(points,\n",
    "                                       trainable=self._trainable,\n",
    "                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n",
    "        else:\n",
    "            self._points = tf.constant(points,\n",
    "                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n",
    "\n",
    "    # pylint: disable=no-self-argument\n",
    "    def create_or_check_constellation(  constellation_type=None,\n",
    "                                        num_bits_per_symbol=None,\n",
    "                                        constellation=None,\n",
    "                                        dtype=tf.complex64):\n",
    "        constellation_object = None\n",
    "        if constellation is not None:\n",
    "            assert constellation_type in [None, \"custom\"], \\\n",
    "                \"\"\"`constellation_type` must be \"custom\".\"\"\"\n",
    "            assert num_bits_per_symbol in \\\n",
    "                     [None, constellation.num_bits_per_symbol], \\\n",
    "                \"\"\"`Wrong value of `num_bits_per_symbol.`\"\"\"\n",
    "            assert constellation.dtype==dtype, \\\n",
    "                \"Constellation has wrong dtype.\"\n",
    "            constellation_object = constellation\n",
    "        else:\n",
    "            assert constellation_type in [\"qam\", \"pam\"], \\\n",
    "                \"Wrong constellation type.\"\n",
    "            assert num_bits_per_symbol is not None, \\\n",
    "                \"`num_bits_per_symbol` must be provided.\"\n",
    "            constellation_object = Constellation(   constellation_type,\n",
    "                                                    num_bits_per_symbol,\n",
    "                                                    dtype=dtype)\n",
    "        return constellation_object\n",
    "\n",
    "    def call(self, inputs): #pylint: disable=unused-argument\n",
    "        x = self._points\n",
    "        x = tf.complex(x[0], x[1])\n",
    "        if self._center:\n",
    "            x = x - tf.reduce_mean(x)\n",
    "        if self._normalize:\n",
    "            energy = tf.reduce_mean(tf.square(tf.abs(x)))\n",
    "            energy_sqrt = tf.cast(tf.sqrt(energy), self._dtype)\n",
    "            x = x / energy_sqrt\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def normalize(self):\n",
    "        \"\"\"Indicates if the constellation is normalized or not.\"\"\"\n",
    "        return self._normalize\n",
    "\n",
    "    @normalize.setter\n",
    "    def normalize(self, value):\n",
    "        assert isinstance(value, bool), \"`normalize` must be boolean\"\n",
    "        self._normalize = value\n",
    "\n",
    "    @property\n",
    "    def center(self):\n",
    "        \"\"\"Indicates if the constellation is centered.\"\"\"\n",
    "        return self._center\n",
    "\n",
    "    @center.setter\n",
    "    def center(self, value):\n",
    "        assert isinstance(value, bool), \"`center` must be boolean\"\n",
    "        self._center = value\n",
    "\n",
    "    @property\n",
    "    def num_bits_per_symbol(self):\n",
    "        \"\"\"The number of bits per constellation symbol.\"\"\"\n",
    "        return self._num_bits_per_symbol\n",
    "\n",
    "    @property\n",
    "    def points(self):\n",
    "        \"\"\"The (possibly) centered and normalized constellation points.\"\"\"\n",
    "        return self(None)\n",
    "\n",
    "    def show(self, labels=True, figsize=(7,7)):\n",
    "\n",
    "        maxval = np.max(np.abs(self.points))*1.05\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.xlim(-maxval, maxval)\n",
    "        plt.ylim(-maxval, maxval)\n",
    "        plt.scatter(np.real(self.points), np.imag(self.points))\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "        plt.xlabel(\"Real Part\")\n",
    "        plt.ylabel(\"Imaginary Part\")\n",
    "        plt.grid(True, which=\"both\", axis=\"both\")\n",
    "        plt.title(\"Constellation Plot\")\n",
    "        if labels is True:\n",
    "            for j, p in enumerate(self.points.numpy()):\n",
    "                plt.annotate(\n",
    "                    np.binary_repr(j, self.num_bits_per_symbol),\n",
    "                    (np.real(p), np.imag(p))\n",
    "                )\n",
    "        return fig\n",
    "\n",
    "class Mapper(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 return_indices=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert dtype in [tf.complex64, tf.complex128],\\\n",
    "            \"dtype must be tf.complex64 or tf.complex128\"\n",
    "\n",
    "        # Create constellation object\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=dtype)\n",
    "\n",
    "        self._return_indices = return_indices\n",
    "\n",
    "        self._binary_base = 2**tf.constant(\n",
    "                        range(self.constellation.num_bits_per_symbol-1,-1,-1))\n",
    "\n",
    "    @property\n",
    "    def constellation(self):\n",
    "        \"\"\"The Constellation used by the Mapper.\"\"\"\n",
    "        return self._constellation\n",
    "\n",
    "    def call(self, inputs):\n",
    "        tf.debugging.assert_greater_equal(tf.rank(inputs), 2,\n",
    "            message=\"The input must have at least rank 2\")\n",
    "\n",
    "        # Reshape inputs to the desired format\n",
    "        new_shape = [-1] + inputs.shape[1:-1].as_list() + \\\n",
    "           [int(inputs.shape[-1] / self.constellation.num_bits_per_symbol),\n",
    "            self.constellation.num_bits_per_symbol]\n",
    "        inputs_reshaped = tf.cast(tf.reshape(inputs, new_shape), tf.int32)\n",
    "\n",
    "        # Convert the last dimension to an integer\n",
    "        int_rep = tf.reduce_sum(inputs_reshaped * self._binary_base, axis=-1)\n",
    "\n",
    "        # Map integers to constellation symbols\n",
    "        x = tf.gather(self.constellation.points, int_rep, axis=0)\n",
    "\n",
    "        if self._return_indices:\n",
    "            return x, int_rep\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class SymbolLogits2LLRs(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 method,\n",
    "                 num_bits_per_symbol,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert method in (\"app\",\"maxlog\"), \"Unknown demapping method\"\n",
    "        self._method = method\n",
    "        self._hard_out = hard_out\n",
    "        self._num_bits_per_symbol = num_bits_per_symbol\n",
    "        self._with_prior = with_prior\n",
    "        num_points = int(2**num_bits_per_symbol)\n",
    "\n",
    "        # Array composed of binary representations of all symbols indices\n",
    "        a = np.zeros([num_points, num_bits_per_symbol])\n",
    "        for i in range(0, num_points):\n",
    "            a[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n",
    "                              dtype=np.int16)\n",
    "\n",
    "        # Compute symbol indices for which the bits are 0 or 1\n",
    "        c0 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        c1 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        for i in range(num_bits_per_symbol-1,-1,-1):\n",
    "            c0[:,i] = np.where(a[:,i]==0)[0]\n",
    "            c1[:,i] = np.where(a[:,i]==1)[0]\n",
    "        self._c0 = tf.constant(c0, dtype=tf.int32) # Symbols with ith bit=0\n",
    "        self._c1 = tf.constant(c1, dtype=tf.int32) # Symbols with ith bit=1\n",
    "\n",
    "        if with_prior:\n",
    "            # Array of labels from {-1, 1} of all symbols\n",
    "            # [num_points, num_bits_per_symbol]\n",
    "            a = 2*a-1\n",
    "            self._a = tf.constant(a, dtype=dtype)\n",
    "\n",
    "        # Determine the reduce function for LLR computation\n",
    "        if self._method == \"app\":\n",
    "            self._reduce = tf.reduce_logsumexp\n",
    "        else:\n",
    "            self._reduce = tf.reduce_max\n",
    "\n",
    "    @property\n",
    "    def num_bits_per_symbol(self):\n",
    "        return self._num_bits_per_symbol\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            logits, prior = inputs\n",
    "        else:\n",
    "            logits = inputs\n",
    "\n",
    "        # Compute exponents\n",
    "        exponents = logits\n",
    "\n",
    "        # Gather exponents for all bits\n",
    "        # shape [...,n,num_points/2,num_bits_per_symbol]\n",
    "        exp0 = tf.gather(exponents, self._c0, axis=-1, batch_dims=0)\n",
    "        exp1 = tf.gather(exponents, self._c1, axis=-1, batch_dims=0)\n",
    "\n",
    "        # Process the prior information\n",
    "        if self._with_prior:\n",
    "            # Expanding `prior` such that it is broadcastable with\n",
    "            # shape [..., n or 1, 1, num_bits_per_symbol]\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(logits), axis=0)\n",
    "            prior = tf.expand_dims(prior, axis=-2)\n",
    "\n",
    "            # Expand the symbol labeling to be broadcastable with prior\n",
    "            # shape [..., 1, num_points, num_bits_per_symbol]\n",
    "            a = sn.utils.expand_to_rank(self._a, tf.rank(prior), axis=0)\n",
    "\n",
    "            # Compute the prior probabilities on symbols exponents\n",
    "            # shape [..., n or 1, num_points]\n",
    "            exp_ps = tf.reduce_sum(tf.math.log_sigmoid(a*prior), axis=-1)\n",
    "\n",
    "            # Gather prior probability symbol for all bits\n",
    "            # shape [..., n or 1, num_points/2, num_bits_per_symbol]\n",
    "            exp_ps0 = tf.gather(exp_ps, self._c0, axis=-1)\n",
    "            exp_ps1 = tf.gather(exp_ps, self._c1, axis=-1)\n",
    "\n",
    "        # Compute LLRs using the definition log( Pr(b=1)/Pr(b=0) )\n",
    "        # shape [..., n, num_bits_per_symbol]\n",
    "        if self._with_prior:\n",
    "            llr = self._reduce(exp_ps1 + exp1, axis=-2)\\\n",
    "                    - self._reduce(exp_ps0 + exp0, axis=-2)\n",
    "        else:\n",
    "            llr = self._reduce(exp1, axis=-2) - self._reduce(exp0, axis=-2)\n",
    "\n",
    "        if self._hard_out:\n",
    "            return sn.utils.hard_decisions(llr)\n",
    "        else:\n",
    "            return llr\n",
    "\n",
    "class SymbolLogits2LLRsWithPrior(SymbolLogits2LLRs):\n",
    "\n",
    "    def __init__(self,\n",
    "                 method,\n",
    "                 num_bits_per_symbol,\n",
    "                 hard_out=False,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(method=method,\n",
    "                         num_bits_per_symbol=num_bits_per_symbol,\n",
    "                         hard_out=False,\n",
    "                         with_prior=True,\n",
    "                         dtype=tf.float32,\n",
    "                         **kwargs)\n",
    "\n",
    "class Demapper(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 demapping_method,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._with_prior = with_prior\n",
    "\n",
    "\n",
    "        # Create constellation object\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=dtype)\n",
    "        num_bits_per_symbol = self._constellation.num_bits_per_symbol\n",
    "\n",
    "        self._logits2llrs = SymbolLogits2LLRs(demapping_method,\n",
    "                                              num_bits_per_symbol,\n",
    "                                              hard_out,\n",
    "                                              with_prior,\n",
    "                                              dtype.real_dtype,\n",
    "                                              **kwargs)\n",
    "\n",
    "    @property\n",
    "    def constellation(self):\n",
    "        return self._constellation\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            y, prior, no = inputs\n",
    "        else:\n",
    "            y, no = inputs\n",
    "\n",
    "        # Reshape constellation points to [1,...1,num_points]\n",
    "        points_shape = [1]*y.shape.rank + self.constellation.points.shape\n",
    "        points = tf.reshape(self.constellation.points, points_shape)\n",
    "\n",
    "        # Compute squared distances from y to all points\n",
    "        # shape [...,n,num_points]\n",
    "        squared_dist = tf.pow(tf.abs(tf.expand_dims(y, axis=-1) - points), 2)\n",
    "\n",
    "        # Add a dummy dimension for broadcasting. This is not needed when no\n",
    "        # is a scalar, but also does not do any harm.\n",
    "        no = tf.expand_dims(no, axis=-1)\n",
    "\n",
    "        # Compute exponents\n",
    "        exponents = -squared_dist/no\n",
    "\n",
    "        if self._with_prior:\n",
    "            llr = self._logits2llrs([exponents, prior])\n",
    "        else:\n",
    "            llr = self._logits2llrs(exponents)\n",
    "\n",
    "        # Reshape LLRs to [...,n*num_bits_per_symbol]\n",
    "        out_shape = tf.concat([tf.shape(y)[:-1],\n",
    "                               [y.shape[-1] * \\\n",
    "                                self.constellation.num_bits_per_symbol]], 0)\n",
    "        llr_reshaped = tf.reshape(llr, out_shape)\n",
    "\n",
    "        return llr_reshaped\n",
    "\n",
    "class DemapperWithPrior(Demapper):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 demapping_method,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(demapping_method=demapping_method,\n",
    "                         constellation_type=constellation_type,\n",
    "                         num_bits_per_symbol=num_bits_per_symbol,\n",
    "                         constellation=constellation,\n",
    "                         hard_out=hard_out,\n",
    "                         with_prior=True,\n",
    "                         dtype=dtype,\n",
    "                         **kwargs)\n",
    "\n",
    "class SymbolDemapper(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._hard_out = hard_out\n",
    "        self._with_prior = with_prior\n",
    "\n",
    "        # Create constellation object\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=dtype)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            y, prior, no = inputs\n",
    "        else:\n",
    "            y, no = inputs\n",
    "\n",
    "        points = sn.utils.expand_to_rank(self._constellation.points,\n",
    "                                tf.rank(y)+1, axis=0)\n",
    "        y = tf.expand_dims(y, axis=-1)\n",
    "        d = tf.abs(y-points)\n",
    "\n",
    "        no = sn.utils.expand_to_rank(no, tf.rank(d), axis=-1)\n",
    "        exp = -d**2 / no\n",
    "\n",
    "        if self._with_prior:\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(exp), axis=0)\n",
    "            exp = exp + prior\n",
    "\n",
    "        if self._hard_out:\n",
    "            return tf.argmax(exp, axis=-1, output_type=tf.int32)\n",
    "        else:\n",
    "            return tf.nn.log_softmax(exp, axis=-1)\n",
    "\n",
    "class SymbolDemapperWithPrior(SymbolDemapper):\n",
    "   \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(constellation_type=constellation_type,\n",
    "                         num_bits_per_symbol=num_bits_per_symbol,\n",
    "                         constellation=constellation,\n",
    "                         hard_out=hard_out,\n",
    "                         with_prior=True,\n",
    "                         dtype=dtype,\n",
    "                         **kwargs)\n",
    "\n",
    "class LLRs2SymbolLogits(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_bits_per_symbol,\n",
    "                 hard_out=False,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "\n",
    "        self._hard_out = hard_out\n",
    "        self._num_bits_per_symbol = num_bits_per_symbol\n",
    "        num_points = int(2**num_bits_per_symbol)\n",
    "\n",
    "        # Array composed of binary representations of all symbols indices\n",
    "        a = np.zeros([num_points, num_bits_per_symbol])\n",
    "        for i in range(0, num_points):\n",
    "            a[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n",
    "                              dtype=np.int16)\n",
    "\n",
    "        # Array of labels from {-1, 1} of all symbols\n",
    "        # [num_points, num_bits_per_symbol]\n",
    "        a = 2*a-1\n",
    "        self._a = tf.constant(a, dtype=dtype)\n",
    "\n",
    "    @property\n",
    "    def num_bits_per_symbol(self):\n",
    "        return self._num_bits_per_symbol\n",
    "\n",
    "    def call(self, inputs):\n",
    "        llrs = inputs\n",
    "\n",
    "        # Expand the symbol labeling to be broadcastable with prior\n",
    "        # shape [1, ..., 1, num_points, num_bits_per_symbol]\n",
    "        a = sn.utils.expand_to_rank(self._a, tf.rank(llrs), axis=0)\n",
    "\n",
    "        # Compute the prior probabilities on symbols exponents\n",
    "        # shape [..., 1, num_points]\n",
    "        llrs = tf.expand_dims(llrs, axis=-2)\n",
    "        logits = tf.reduce_sum(tf.math.log_sigmoid(a*llrs), axis=-1)\n",
    "\n",
    "        if self._hard_out:\n",
    "            return tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "class SymbolLogits2Moments(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "\n",
    "        # Create constellation object\n",
    "        const_dtype = tf.complex64 if dtype is tf.float32 else tf.complex128\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=const_dtype)\n",
    "\n",
    "    def __call__(self, logits):\n",
    "        p = tf.math.softmax(logits, axis=-1)\n",
    "        p_c = tf.complex(p, tf.cast(0.0, self.dtype))\n",
    "        points = self._constellation.points\n",
    "        points = sn.utils.expand_to_rank(points, tf.rank(p), axis=0)\n",
    "\n",
    "        mean = tf.reduce_sum(p_c*points, axis=-1, keepdims=True)\n",
    "        var = tf.reduce_sum(p*tf.square(tf.abs(points - mean)), axis=-1)\n",
    "        mean = tf.squeeze(mean, axis=-1)\n",
    "\n",
    "        return mean, var\n",
    "\n",
    "class QAM2PAM:\n",
    "    \n",
    "    def __init__(self, num_bits_per_symbol):\n",
    "        base = [2**i for i in range(num_bits_per_symbol//2-1, -1, -1)]\n",
    "        base = np.array(base)\n",
    "        pam1_ind = np.zeros([2**num_bits_per_symbol], dtype=np.int32)\n",
    "        pam2_ind = np.zeros([2**num_bits_per_symbol], dtype=np.int32)\n",
    "        for i in range(0, 2**num_bits_per_symbol):\n",
    "            b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n",
    "                         dtype=np.int32)\n",
    "            pam1_ind[i] = np.sum(b[0::2]*base)\n",
    "            pam2_ind[i] = np.sum(b[1::2]*base)\n",
    "        self._pam1_ind = tf.constant(pam1_ind, dtype=tf.int32)\n",
    "        self._pam2_ind = tf.constant(pam2_ind, dtype=tf.int32)\n",
    "\n",
    "    def __call__(self, ind_qam):\n",
    "\n",
    "        ind_pam1 = tf.gather(self._pam1_ind, ind_qam, axis=0)\n",
    "        ind_pam2 = tf.gather(self._pam2_ind, ind_qam, axis=0)\n",
    "\n",
    "        return ind_pam1, ind_pam2\n",
    "\n",
    "class PAM2QAM:\n",
    "    \n",
    "    def __init__(self, num_bits_per_symbol, hard_in_out=True):\n",
    "        num_pam_symbols = 2**(num_bits_per_symbol//2)\n",
    "        base = np.array([2**i for i in range(num_bits_per_symbol-1, -1, -1)])\n",
    "\n",
    "        # Create an array of QAM symbol indices, index by two PAM indices\n",
    "        ind = np.zeros([num_pam_symbols, num_pam_symbols], np.int32)\n",
    "        for i in range(0, num_pam_symbols):\n",
    "            for j in range(0, num_pam_symbols):\n",
    "                b1 = np.array(list(np.binary_repr(i,num_bits_per_symbol//2)),\n",
    "                              dtype=np.int16)\n",
    "                b2 = np.array(list(np.binary_repr(j,num_bits_per_symbol//2)),\n",
    "                              dtype=np.int16)\n",
    "                b = np.zeros([num_bits_per_symbol], np.int32)\n",
    "                b[0::2] = b1\n",
    "                b[1::2] = b2\n",
    "                ind[i, j] = np.sum(b*base)\n",
    "        self._qam_ind = tf.constant(ind, dtype=tf.int32)\n",
    "        self._hard_in_out = hard_in_out\n",
    "\n",
    "    def __call__(self, pam1, pam2):\n",
    "\n",
    "        # PAM indices to QAM indices\n",
    "        if self._hard_in_out:\n",
    "            shape = tf.shape(pam1)\n",
    "            ind_pam1 = tf.reshape(pam1, [-1, 1])\n",
    "            ind_pam2 = tf.reshape(pam2, [-1, 1])\n",
    "            ind_pam = tf.concat([ind_pam1, ind_pam2], axis=-1)\n",
    "            ind_qam = tf.gather_nd(self._qam_ind, ind_pam)\n",
    "            ind_qam = tf.reshape(ind_qam, shape)\n",
    "            return ind_qam\n",
    "\n",
    "        # PAM logits to QAM logits\n",
    "        else:\n",
    "            # Compute all combination of sums of logits\n",
    "            logits_mat = tf.expand_dims(pam1, -1) + tf.expand_dims(pam2, -2)\n",
    "\n",
    "            # Flatten to a vector\n",
    "            logits = sn.utils.flatten_last_dims(logits_mat)\n",
    "\n",
    "            # Gather symbols in the correct order\n",
    "            gather_ind = tf.reshape(self._qam_ind, [-1])\n",
    "            logits = tf.gather(logits, gather_ind, axis=-1)\n",
    "            return logits\n",
    "\n",
    "class SymbolInds2Bits(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "               num_bits_per_symbol,\n",
    "               dtype=tf.float32,\n",
    "               **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        num_symbols = 2**num_bits_per_symbol\n",
    "        b = np.zeros([num_symbols, num_bits_per_symbol])\n",
    "        for i in range(0, num_symbols):\n",
    "            b[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n",
    "                              dtype=np.int16)\n",
    "        self._bit_labels = tf.constant(b, self.dtype)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        symbol_ind = inputs\n",
    "        return tf.gather(self._bit_labels, symbol_ind)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ebnodb2no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber, compute_ser\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = 8\n",
    "BATCH_SIZE = 2\n",
    "EBN0_DB_MIN = -3.0\n",
    "EBN0_DB_MAX = 3.0\n",
    "\n",
    "for EBN0_DB in np.linspace(EBN0_DB_MIN,EBN0_DB_MAX,20):\n",
    "    print('EBN0_DB =',EBN0_DB)\n",
    "    no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                            num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                            coderate=1.0)\n",
    "    print('no =',no)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWGN (Additive White Gaussian **Noise**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils import expand_to_rank, complex_normal\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = 8\n",
    "BATCH_SIZE = 2\n",
    "EBN0_DB = -10\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "print('bits =\\n',bits)\n",
    "\n",
    "no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                        coderate=1.0)\n",
    "print('no =',no)\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "\n",
    "x = mapper(bits)\n",
    "print('x =\\n',x)\n",
    " \n",
    "# Create tensors of real-valued Gaussian noise for each complex dim.\n",
    "noise = complex_normal(tf.shape(x), dtype=x.dtype)\n",
    "print('noise =\\n',noise)\n",
    "\n",
    "# Add extra dimensions for broadcasting\n",
    "no = expand_to_rank(no, tf.rank(x), axis=-1)\n",
    "print('no =',no)\n",
    "\n",
    "# Apply variance scaling\n",
    "real_dtype = tf.dtypes.as_dtype(tf.complex64).real_dtype\n",
    "no = tf.cast(no, real_dtype)\n",
    "print('no =',no)\n",
    "noise *= tf.cast(tf.sqrt(no), noise.dtype)\n",
    "print('noise =\\n',noise)\n",
    "\n",
    "# Add noise to input\n",
    "y = x + noise\n",
    "#print('y = x + noise =\\n',y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logits2llrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.float32, **kwargs):\n",
    "    # pylint: disable=line-too-long\n",
    "    r\"\"\"\n",
    "    SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.float32, **kwargs)\n",
    "\n",
    "    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n",
    "    from a tensor of logits (i.e., unnormalized log-probabilities) on constellation points.\n",
    "    If the flag ``with_prior`` is set, prior knowledge on the bits is assumed to be available.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : One of [\"app\", \"maxlog\"], str\n",
    "        The method used for computing the LLRs.\n",
    "\n",
    "    num_bits_per_symbol : int\n",
    "        The number of bits per constellation symbol, e.g., 4 for QAM16.\n",
    "\n",
    "    hard_out : bool\n",
    "        If `True`, the layer provides hard-decided bits instead of soft-values.\n",
    "        Defaults to `False`.\n",
    "\n",
    "    with_prior : bool\n",
    "        If `True`, it is assumed that prior knowledge on the bits is available.\n",
    "        This prior information is given as LLRs as an additional input to the layer.\n",
    "        Defaults to `False`.\n",
    "\n",
    "    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n",
    "        The dtype for the input and output.\n",
    "        Defaults to `tf.float32`.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    logits or (logits, prior):\n",
    "        Tuple:\n",
    "\n",
    "    logits : [...,n, num_points], tf.float\n",
    "        Logits on constellation points.\n",
    "\n",
    "    prior : [num_bits_per_symbol] or [...n, num_bits_per_symbol], tf.float\n",
    "        Prior for every bit as LLRs.\n",
    "        It can be provided either as a tensor of shape `[num_bits_per_symbol]`\n",
    "        for the entire input batch, or as a tensor that is \"broadcastable\"\n",
    "        to `[..., n, num_bits_per_symbol]`.\n",
    "        Only required if the ``with_prior`` flag is set.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    : [...,n, num_bits_per_symbol], tf.float\n",
    "        LLRs or hard-decisions for every bit.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    With the \"app\" method, the LLR for the :math:`i\\text{th}` bit\n",
    "    is computed according to\n",
    "\n",
    "    .. math::\n",
    "        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert \\mathbf{z},\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert \\mathbf{z},\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n",
    "                \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                e^{z_c}\n",
    "                }{\n",
    "                \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                e^{z_c}\n",
    "                }\\right)\n",
    "\n",
    "    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n",
    "    sets of :math:`2^K` constellation points for which the :math:`i\\text{th}` bit is\n",
    "    equal to 1 and 0, respectively. :math:`\\mathbf{z} = \\left[z_{c_0},\\dots,z_{c_{2^K-1}}\\right]` is the vector of logits on the constellation points, :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]`\n",
    "    is the vector of LLRs that serves as prior knowledge on the :math:`K` bits that are mapped to\n",
    "    a constellation point and is set to :math:`\\mathbf{0}` if no prior knowledge is assumed to be available,\n",
    "    and :math:`\\Pr(c\\lvert\\mathbf{p})` is the prior probability on the constellation symbol :math:`c`:\n",
    "\n",
    "    .. math::\n",
    "        \\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert\\mathbf{p} \\right)\n",
    "        = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n",
    "\n",
    "    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where 0 is\n",
    "    replaced by -1.\n",
    "    The definition of the LLR has been\n",
    "    chosen such that it is equivalent with that of logits. This is\n",
    "    different from many textbooks in communications, where the LLR is\n",
    "    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n",
    "\n",
    "    With the \"maxlog\" method, LLRs for the :math:`i\\text{th}` bit\n",
    "    are approximated like\n",
    "\n",
    "    .. math::\n",
    "        \\begin{align}\n",
    "            LLR(i) &\\approx\\ln\\left(\\frac{\n",
    "                \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                    e^{z_c}\n",
    "                }{\n",
    "                \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                    e^{z_c}\n",
    "                }\\right)\n",
    "                .\n",
    "        \\end{align}\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 method,\n",
    "                 num_bits_per_symbol,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert method in (\"app\",\"maxlog\"), \"Unknown demapping method\"\n",
    "        self._method = method\n",
    "        self._hard_out = hard_out\n",
    "        self._num_bits_per_symbol = num_bits_per_symbol\n",
    "        self._with_prior = with_prior\n",
    "        num_points = int(2**num_bits_per_symbol)\n",
    "\n",
    "        # Array composed of binary representations of all symbols indices\n",
    "        a = np.zeros([num_points, num_bits_per_symbol])\n",
    "        for i in range(0, num_points):\n",
    "            a[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n",
    "                              dtype=np.int16)\n",
    "\n",
    "        # Compute symbol indices for which the bits are 0 or 1\n",
    "        c0 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        c1 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        for i in range(num_bits_per_symbol-1,-1,-1):\n",
    "            c0[:,i] = np.where(a[:,i]==0)[0]\n",
    "            c1[:,i] = np.where(a[:,i]==1)[0]\n",
    "        self._c0 = tf.constant(c0, dtype=tf.int32) # Symbols with ith bit=0\n",
    "        self._c1 = tf.constant(c1, dtype=tf.int32) # Symbols with ith bit=1\n",
    "\n",
    "        if with_prior:\n",
    "            # Array of labels from {-1, 1} of all symbols\n",
    "            # [num_points, num_bits_per_symbol]\n",
    "            a = 2*a-1\n",
    "            self._a = tf.constant(a, dtype=dtype)\n",
    "\n",
    "        # Determine the reduce function for LLR computation\n",
    "        if self._method == \"app\":\n",
    "            self._reduce = tf.reduce_logsumexp\n",
    "        else:\n",
    "            self._reduce = tf.reduce_max\n",
    "\n",
    "    @property\n",
    "    def num_bits_per_symbol(self):\n",
    "        return self._num_bits_per_symbol\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            logits, prior = inputs\n",
    "        else:\n",
    "            logits = inputs\n",
    "\n",
    "        # Compute exponents\n",
    "        exponents = logits\n",
    "\n",
    "        # Gather exponents for all bits\n",
    "        # shape [...,n,num_points/2,num_bits_per_symbol]\n",
    "        exp0 = tf.gather(exponents, self._c0, axis=-1, batch_dims=0)\n",
    "        exp1 = tf.gather(exponents, self._c1, axis=-1, batch_dims=0)\n",
    "\n",
    "        # Process the prior information\n",
    "        if self._with_prior:\n",
    "            # Expanding `prior` such that it is broadcastable with\n",
    "            # shape [..., n or 1, 1, num_bits_per_symbol]\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(logits), axis=0)\n",
    "            prior = tf.expand_dims(prior, axis=-2)\n",
    "\n",
    "            # Expand the symbol labeling to be broadcastable with prior\n",
    "            # shape [..., 1, num_points, num_bits_per_symbol]\n",
    "            a = sn.utils.expand_to_rank(self._a, tf.rank(prior), axis=0)\n",
    "\n",
    "            # Compute the prior probabilities on symbols exponents\n",
    "            # shape [..., n or 1, num_points]\n",
    "            exp_ps = tf.reduce_sum(tf.math.log_sigmoid(a*prior), axis=-1)\n",
    "\n",
    "            # Gather prior probability symbol for all bits\n",
    "            # shape [..., n or 1, num_points/2, num_bits_per_symbol]\n",
    "            exp_ps0 = tf.gather(exp_ps, self._c0, axis=-1)\n",
    "            exp_ps1 = tf.gather(exp_ps, self._c1, axis=-1)\n",
    "\n",
    "        # Compute LLRs using the definition log( Pr(b=1)/Pr(b=0) )\n",
    "        # shape [..., n, num_bits_per_symbol]\n",
    "        if self._with_prior:\n",
    "            llr = self._reduce(exp_ps1 + exp1, axis=-2)\\\n",
    "                    - self._reduce(exp_ps0 + exp0, axis=-2)\n",
    "        else:\n",
    "            llr = self._reduce(exp1, axis=-2) - self._reduce(exp0, axis=-2)\n",
    "\n",
    "        if self._hard_out:\n",
    "            return sn.utils.hard_decisions(llr)\n",
    "        else:\n",
    "            return llr\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = 8\n",
    "BATCH_SIZE = 2\n",
    "EBN0_DB = -10\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "\n",
    "# AWGN channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "#print('bits =\\n',bits)\n",
    "\n",
    "no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                        coderate=1.0)\n",
    "#print('no =',no)\n",
    "\n",
    "x = mapper(bits)\n",
    "#print('x =\\n',x)\n",
    "\n",
    "y = awgn_channel([x, no])\n",
    "\n",
    "# Reshape constellation points to [1,...1,num_points]\n",
    "points_shape = [1]*y.shape.rank + constellation.points.shape\n",
    "points = tf.reshape(constellation.points, points_shape)\n",
    "\n",
    "# Compute squared distances from y to all points\n",
    "# shape [...,n,num_points]\n",
    "squared_dist = tf.pow(tf.abs(tf.expand_dims(y, axis=-1) - points), 2)\n",
    "\n",
    "# Add a dummy dimension for broadcasting. This is not needed when no\n",
    "# is a scalar, but also does not do any harm.\n",
    "no = tf.expand_dims(no, axis=-1)\n",
    "\n",
    "# Compute exponents\n",
    "exponents = -squared_dist/no\n",
    "#print('exponents =\\n',exponents)\n",
    "\n",
    "logits2llrs = SymbolLogits2LLRs(\"app\",NUM_BITS_PER_SYMBOL)\n",
    "print('logits2llrs =\\n',logits2llrs)\n",
    "\n",
    "# if self._with_prior:\n",
    "#     llr = self._logits2llrs([exponents, prior])\n",
    "# else:\n",
    "llr = logits2llrs(exponents)\n",
    "\n",
    "# Reshape LLRs to [...,n*num_bits_per_symbol]\n",
    "out_shape = tf.concat([tf.shape(y)[:-1],\n",
    "                        [y.shape[-1] * \\\n",
    "                        constellation.num_bits_per_symbol]], 0)\n",
    "llr_reshaped = tf.reshape(llr, out_shape)\n",
    "\n",
    "# return llr_reshaped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bits2symbol"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber, compute_ser\n",
    "\n",
    "CODERATE = 0.5\n",
    "n = 16\n",
    "k = int(n*CODERATE)\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "print('NUM_BITS_PER_SYMBOL =',NUM_BITS_PER_SYMBOL)\n",
    "BLOCK_LENGTH = k\n",
    "BATCH_SIZE = 2 # How many examples are processed by Sionna in parallel\n",
    "EBN0_DB_MIN = -10.0 # Minimum value of Eb/N0 [dB] for simulations\n",
    "EBN0_DB_MAX = 10.0 # Maximum value of Eb/N0 [dB] for simulations\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "\n",
    "bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "print('bits =\\n',bits)\n",
    "\n",
    "new_shape = [-1] + bits.shape[1:-1].as_list() + \\\n",
    "           [int(bits.shape[-1] / NUM_BITS_PER_SYMBOL),\n",
    "            NUM_BITS_PER_SYMBOL]\n",
    "print('new_shape =\\n',new_shape)\n",
    "\n",
    "bits_reshaped = tf.cast(tf.reshape(bits, new_shape), tf.int32)\n",
    "print('symbols =\\n',bits_reshaped)\n",
    "\n",
    "binary_base = 2**tf.constant(\n",
    "                        range(NUM_BITS_PER_SYMBOL-1,-1,-1))\n",
    "print('binary_base =\\n',binary_base)\n",
    "\n",
    "int_rep = tf.reduce_sum(bits_reshaped * binary_base, axis=-1)\n",
    "print('int_rep =\\n',int_rep)\n",
    "\n",
    "x = tf.gather(constellation.points, int_rep, axis=0)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber, compute_ser\n",
    "\n",
    "def bits2symbol(bits,num_bits_per_symbol):\n",
    "    new_shape = [-1] + bits.shape[1:-1].as_list() + \\\n",
    "            [int(bits.shape[-1] / NUM_BITS_PER_SYMBOL),\n",
    "                NUM_BITS_PER_SYMBOL]\n",
    "    #print('new_shape =',new_shape)\n",
    "    #print('bits.shape[1:-1]',bits.shape[1:-1])\n",
    "    # print('bits.shape[-1]=',bits.shape[-1])\n",
    "\n",
    "    symbols = tf.cast(tf.reshape(bits, new_shape), tf.int32)\n",
    "    # print('symbols =',symbols)\n",
    "    return symbols\n",
    "\n",
    "\n",
    "CODERATE = 0.5\n",
    "n = 16\n",
    "k = int(n*CODERATE)\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = k\n",
    "BATCH_SIZE = 2 # How many examples are processed by Sionna in parallel\n",
    "EBN0_DB_MIN = -10.0 # Minimum value of Eb/N0 [dB] for simulations\n",
    "EBN0_DB_MAX = 10.0 # Maximum value of Eb/N0 [dB] for simulations\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "\n",
    "#bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "bits = binary_source([2,3,4,5,6])\n",
    "# print('bits =',bits)\n",
    "# print('bits.ndim =',bits.ndim)\n",
    "\n",
    "symbols = bits2symbol(bits,NUM_BITS_PER_SYMBOL)\n",
    "# print('symbols =',symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "\n",
    "BATCH_SIZE = 1000000\n",
    "NUM_TX_ANT = 4\n",
    "NUM_RX_ANT = 16\n",
    "NUM_BITS_PER_SYMBOL = 4\n",
    "\n",
    "channel = FlatFadingChannel(num_tx_ant=NUM_TX_ANT, num_rx_ant=NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "no = 0.2 # Noise variance of the channel\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "qam_source = QAMSource(num_bits_per_symbol=NUM_BITS_PER_SYMBOL)\n",
    "x = qam_source([BATCH_SIZE, NUM_TX_ANT])\n",
    "# print('x =',x)\n",
    "# Get symbol indices for the transmitted symbols\n",
    "x_ind = symbol_demapper([x, no])\n",
    "# print('x_ind =',x_ind)\n",
    "\n",
    "# Create transmit and receive correlation matrices\n",
    "r_tx = exp_corr_mat(0.4, NUM_TX_ANT)\n",
    "r_rx = exp_corr_mat(0.9, NUM_RX_ANT)\n",
    "\n",
    "print('r_tx =',r_tx)\n",
    "print('r_rx =',r_rx)\n",
    "print('r_tx.shape =',r_tx.shape)\n",
    "print('r_rx.shape =',r_rx.shape)\n",
    "\n",
    "# Add the spatial correlation model to the channel\n",
    "channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "#print('h_corr =',KroneckerModel(r_tx, r_rx))\n",
    "\n",
    "h = channel.generate(BATCH_SIZE)\n",
    "print('h.shape =',h.shape)\n",
    "\n",
    "# Compute empirical covariance matrices\n",
    "r_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/NUM_RX_ANT\n",
    "r_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/NUM_TX_ANT\n",
    "\n",
    "# Test that the empirical results match the theory\n",
    "# assert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\n",
    "# assert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n",
    "\n",
    "y, h = channel([x, no]) # type: ignore\n",
    "s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "x_hat, no_eff = lmmse_equalizer(y, h, s)\n",
    "\n",
    "# Get symbol indices for the received soft-symbols\n",
    "x_ind_hat = symbol_demapper([x_hat, no])\n",
    "compute_ser(x_ind, x_ind_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FlatFadingChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b shape = (32, 4, 512)\n",
      "x shape = (32, 4, 128)\n",
      "x reshape = (4096, 4)\n",
      "batch_size = tf.Tensor(4096, shape=(), dtype=int32)\n",
      "h shape = (4096, 16, 4)\n",
      "h = tf.Tensor(\n",
      "[[[ 1.2106943 -0.57531357j -0.16533719+0.3895905j\n",
      "   -0.1602286 +0.8083027j  -0.9215764 -0.03920262j]\n",
      "  [-1.1231408 -0.76993793j  0.21325897+0.04296628j\n",
      "   -0.5221998 +1.2066145j   1.3783945 -0.31628877j]\n",
      "  [ 0.8965064 -0.12762327j -0.6455877 -0.3811652j\n",
      "   -1.7724121 -0.19522943j  0.7525839 -0.42759407j]\n",
      "  ...\n",
      "  [ 0.6631029 -0.1177212j   0.280737  -0.14437845j\n",
      "    0.84232557+0.22630343j  0.65941656-0.02572032j]\n",
      "  [-0.6040951 -0.37555417j -0.6060022 -0.77499133j\n",
      "   -0.71687335-0.30254802j  0.2920682 +0.11929827j]\n",
      "  [ 1.7277184 +1.6393815j   0.53525054+0.6290777j\n",
      "   -0.0562429 +0.52128416j -0.7860079 -1.0565555j ]]\n",
      "\n",
      " [[-0.7330225 +1.4971594j  -0.28901926+0.07351026j\n",
      "   -0.5539348 +0.20673583j -0.60231996-0.3816234j ]\n",
      "  [ 0.80606776-0.4482717j  -0.26762336+1.9391681j\n",
      "   -0.39329344-0.33786756j -0.5783194 -0.268788j  ]\n",
      "  [-0.32890016+0.16010037j -1.1172493 +0.7748073j\n",
      "   -0.8909023 -0.03574862j  0.16404478-0.17641577j]\n",
      "  ...\n",
      "  [-0.16759732-0.6054775j   0.28272223-0.2474445j\n",
      "   -0.03771289+0.8060286j  -0.35887927+0.4151725j ]\n",
      "  [-1.0647324 +0.13704719j -0.99746686+0.15185735j\n",
      "   -1.0219169 -0.8521126j   0.20527622+0.8631279j ]\n",
      "  [ 0.3769181 -0.4343401j   0.9676978 +1.6530007j\n",
      "   -0.5047888 +1.589793j    0.692099  +0.12364984j]]\n",
      "\n",
      " [[-0.45520058+0.60051656j -0.11613375+0.15086955j\n",
      "   -0.46465027-0.5791605j   0.24424282+2.2634947j ]\n",
      "  [ 0.35086602+0.82284504j -0.6346    -0.60698354j\n",
      "    0.73251295+0.1238371j  -0.4514151 +0.34147403j]\n",
      "  [ 0.18894911-0.33402842j  0.66023153-0.34309003j\n",
      "   -0.15558074+0.90807956j -1.2998484 +1.037905j  ]\n",
      "  ...\n",
      "  [-0.95200634-0.17142355j  1.2890072 -0.45265204j\n",
      "   -0.79009223+0.04623677j -0.04365751-1.2453983j ]\n",
      "  [-0.5805038 +0.47901213j -0.5073962 +0.7223951j\n",
      "   -0.04781335+0.04681444j -0.13489805+0.27507198j]\n",
      "  [ 0.90787286-0.22249177j -0.12776965-1.2736357j\n",
      "    0.51698333-1.0195056j   0.19748226+0.8345062j ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.3504827 +0.65818286j -1.2799274 -1.0783912j\n",
      "   -0.7683469 -0.43462336j -0.45767966+0.58970696j]\n",
      "  [ 0.49896455+0.59569573j -0.4956412 +1.0570983j\n",
      "    0.6449413 -1.0454427j   1.8203    +1.2466846j ]\n",
      "  [ 0.21253116+0.33432755j  0.58483326+0.0823579j\n",
      "   -0.33624232-0.40921655j  0.03520089+1.3362987j ]\n",
      "  ...\n",
      "  [-0.3185644 -0.5393044j   0.18137337+0.21525335j\n",
      "    0.68860453-0.34955198j -0.10203208+0.3580961j ]\n",
      "  [-0.85062665-0.66048855j  0.16599204-0.8269364j\n",
      "    1.4819826 +0.7138624j   1.6073787 +0.80762285j]\n",
      "  [ 0.27966976-2.513037j   -0.24102163-0.02195356j\n",
      "   -0.40625334+0.27918753j  0.44940323-0.5345899j ]]\n",
      "\n",
      " [[ 0.61895174-0.3464509j  -0.804764  -0.72906965j\n",
      "   -1.4334726 +0.05716273j -0.33784154+1.333262j  ]\n",
      "  [-0.06726669+1.1804951j  -0.26846594-1.2130965j\n",
      "    0.16685334+1.4040694j  -0.06098498+0.43661264j]\n",
      "  [-0.16039859-0.26267633j  1.9007653 -0.24288476j\n",
      "    0.7902664 -0.51067406j -0.33670717+0.3242341j ]\n",
      "  ...\n",
      "  [-1.1662343 +0.28266746j  0.56842136+0.69268733j\n",
      "   -0.17432924-0.2639666j   0.14587094-0.27837035j]\n",
      "  [ 0.6722571 -0.49440473j -0.8219144 -0.12374986j\n",
      "   -0.55522776-0.2117025j   0.47759244-0.25176114j]\n",
      "  [ 0.11040144+0.5292954j   0.42072362+0.96741676j\n",
      "    0.05682142+0.6159406j   0.51401   +0.10966955j]]\n",
      "\n",
      " [[-0.7720596 +0.26721787j  0.4385211 -0.3080621j\n",
      "    0.10084855+0.10418357j  0.07847558+0.7735779j ]\n",
      "  [ 0.2003141 +0.624013j    0.08704434-0.3974101j\n",
      "    0.18426546-0.8340741j   1.1858749 +0.03579108j]\n",
      "  [-0.3645557 +0.4108567j   1.046996  -0.6458077j\n",
      "    0.3721212 -0.25138593j  0.16613396+0.88863003j]\n",
      "  ...\n",
      "  [ 0.28296986+1.0880635j  -1.0500168 -0.20304869j\n",
      "   -0.3768386 -1.3519056j  -0.9390552 +0.85090286j]\n",
      "  [ 0.02328013-0.5378241j  -0.4312452 +1.2336087j\n",
      "    0.07969272-1.4260607j   0.6487793 -0.26552296j]\n",
      "  [ 0.45050824-0.26634413j -0.351692  -0.29266766j\n",
      "    0.41096655+0.9900504j  -0.6247422 -1.2059103j ]]], shape=(4096, 16, 4), dtype=complex64)\n",
      "x reshape(app_chn) = (4096, 4, 1)\n",
      "noise shape = (4096, 16)\n"
     ]
    }
   ],
   "source": [
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from sionna.utils import expand_to_rank, complex_normal\n",
    "\n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "\n",
    "# from sionna.channel import AWGN\n",
    "from sionna.utils import complex_normal\n",
    "\n",
    "class AWGN(Layer):\n",
    "    def __init__(self, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._real_dtype = tf.dtypes.as_dtype(self._dtype).real_dtype\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x, no = inputs\n",
    "\n",
    "        # Create tensors of real-valued Gaussian noise for each complex dim.\n",
    "        noise = complex_normal(tf.shape(x), dtype=x.dtype)\n",
    "\n",
    "        # Add extra dimensions for broadcasting\n",
    "        no = expand_to_rank(no, tf.rank(x), axis=-1)\n",
    "\n",
    "        # Apply variance scaling\n",
    "        no = tf.cast(no, self._real_dtype)\n",
    "        noise *= tf.cast(tf.sqrt(no), noise.dtype)\n",
    "        print('noise shape =',noise.shape)\n",
    "        # Add noise to input\n",
    "        y = x + noise\n",
    "\n",
    "        return y\n",
    "\n",
    "class GenerateFlatFadingChannel():\n",
    "    def __init__(self, num_tx_ant, num_rx_ant, spatial_corr=None, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._dtype = dtype\n",
    "        self.spatial_corr = spatial_corr\n",
    " \n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._spatial_corr\n",
    " \n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._spatial_corr = value\n",
    " \n",
    "    def __call__(self, batch_size):\n",
    "        # Generate standard complex Gaussian matrices\n",
    "        shape = [batch_size, self._num_rx_ant, self._num_tx_ant]\n",
    "        h = complex_normal(shape, dtype=self._dtype)\n",
    " \n",
    "        # Apply spatial correlation\n",
    "        if self.spatial_corr is not None:\n",
    "            h = self.spatial_corr(h)\n",
    " \n",
    "        return h\n",
    "\n",
    "class ApplyFlatFadingChannel(tf.keras.layers.Layer):\n",
    "    def __init__(self, add_awgn=True, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "        self._add_awgn = add_awgn\n",
    " \n",
    "    def build(self, input_shape): #pylint: disable=unused-argument\n",
    "        if self._add_awgn:\n",
    "            self._awgn = AWGN(dtype=self.dtype)\n",
    " \n",
    "    def call(self, inputs):\n",
    "        if self._add_awgn:\n",
    "            x, h, no = inputs\n",
    "        else:\n",
    "            x, h = inputs\n",
    " \n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "        print('x reshape(app_chn) =',x.shape)\n",
    "        y = tf.matmul(h, x)\n",
    "        y = tf.squeeze(y, axis=-1)\n",
    " \n",
    "        if self._add_awgn:\n",
    "            y = self._awgn((y, no))\n",
    " \n",
    "        return y\n",
    "\n",
    "class FlatFadingChannel(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_tx_ant,\n",
    "                 num_rx_ant,\n",
    "                 spatial_corr=None,\n",
    "                 add_awgn=True,\n",
    "                 return_channel=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._add_awgn = add_awgn\n",
    "        self._return_channel = return_channel\n",
    "        self._gen_chn = GenerateFlatFadingChannel(self._num_tx_ant,\n",
    "                                                  self._num_rx_ant,\n",
    "                                                  spatial_corr,\n",
    "                                                  dtype=dtype)\n",
    "        self._app_chn = ApplyFlatFadingChannel(add_awgn=add_awgn, dtype=dtype)\n",
    " \n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._gen_chn.spatial_corr\n",
    " \n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._gen_chn.spatial_corr = value\n",
    " \n",
    "    @property\n",
    "    def generate(self):\n",
    "        \"\"\"Calls the internal :class:`GenerateFlatFadingChannel`.\"\"\"\n",
    "        return self._gen_chn\n",
    " \n",
    "    @property\n",
    "    def apply(self):\n",
    "        \"\"\"Calls the internal :class:`ApplyFlatFadingChannel`.\"\"\"\n",
    "        return self._app_chn\n",
    " \n",
    "    def call(self, inputs):\n",
    "        if self._add_awgn:\n",
    "            x, no = inputs\n",
    "        else:\n",
    "            x = inputs\n",
    " \n",
    "        # Generate a batch of channel realizations\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        print('batch_size =', batch_size)\n",
    "        h = self._gen_chn(batch_size)\n",
    "        print('h shape =',h.shape)\n",
    "        print('h =',h)\n",
    " \n",
    "        # Apply the channel to the input\n",
    "        if self._add_awgn:\n",
    "            y = self._app_chn([x, h, no])\n",
    "        else:\n",
    "            y = self._app_chn([x, h])\n",
    " \n",
    "        if self._return_channel:\n",
    "            return y, h\n",
    "        else:\n",
    "            return y\n",
    "\n",
    "no = 0.2\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 32 # Parallel in 32 Batches\n",
    "k = 512 # Message Bits\n",
    "NUM_RX_ANT = 16 # Receiver Antennas\n",
    "NUM_TX_ANT = 4 # Transmitter Antennas\n",
    "\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "\n",
    "y, h = flatfading_channel([x_reshape, no]) # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complex_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Layer\n",
    "def complex_normal(shape, var=1.0, dtype=tf.complex64):\n",
    "    # Half the variance for each dimension\n",
    "    var_dim = tf.cast(var, dtype.real_dtype)/tf.cast(2, dtype.real_dtype) # var_dim = 1/2\n",
    "    print('var_dim =',var_dim)\n",
    "    stddev = tf.sqrt(var_dim) # standard deviation = sqrt(variance) = sqrt(1/2) = 0.7071\n",
    "    print('stddev =',stddev)\n",
    " \n",
    "    # Generate complex Gaussian noise with the right variance\n",
    "    xr = tf.random.normal(shape, stddev=stddev, dtype=dtype.real_dtype)\n",
    "    xi = tf.random.normal(shape, stddev=stddev, dtype=dtype.real_dtype)\n",
    "    x = tf.complex(xr, xi)\n",
    "    print('x =',x)\n",
    " \n",
    "    return x\n",
    "\n",
    "shape = [4,3,2];\n",
    "cn = complex_normal(shape);\n",
    "print('cn shape=', cn.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# equalization\n",
    "# whiten_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# GPU Configuration and Imports\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "    \n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "# from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from sionna.utils import expand_to_rank, matrix_inv, matrix_pinv\n",
    "# from sionna.mimo.utils import whiten_channel\n",
    "from sionna.utils import matrix_sqrt_inv, expand_to_rank\n",
    "\n",
    "def whiten_channel(y, h, s, return_s=True):\n",
    "    # Compute whitening matrix\n",
    "    s_inv_1_2 = matrix_sqrt_inv(s)\n",
    "    s_inv_1_2 = expand_to_rank(s_inv_1_2, tf.rank(h), 0)\n",
    "\n",
    "    # Whiten obervation and channel matrix\n",
    "    yw = tf.expand_dims(y, -1)\n",
    "    yw = tf.matmul(s_inv_1_2, yw)\n",
    "    yw = tf.squeeze(yw, axis=-1)\n",
    "\n",
    "    hw = tf.matmul(s_inv_1_2, h)\n",
    "\n",
    "    if return_s:\n",
    "        # Ideal interference covariance matrix after whitening\n",
    "        sw = tf.eye(tf.shape(s)[-2], dtype=s.dtype)\n",
    "        sw = expand_to_rank(sw, tf.rank(s), 0)\n",
    "        return yw, hw, sw\n",
    "    else:\n",
    "        return yw, hw\n",
    "\n",
    "def lmmse_equalizer(y, h, s, whiten_interference=True):\n",
    "    if not whiten_interference:\n",
    "        # Compute G (G = H^H(HH^H + S}^-1).\n",
    "        print('H^H shape=',(np.linalg.pinv(h)).shape)\n",
    "        g = tf.matmul(h, h, adjoint_b=True) + s\n",
    "        print('H(H^H) shape=',(tf.matmul(h, h, adjoint_b=True)).shape)\n",
    "        print('H(H^H)+S shape=',g.shape)\n",
    "        print('(H(H^H)+S)^-1 shape',(matrix_inv(g)).shape)\n",
    "        g = tf.matmul(h, matrix_inv(g), adjoint_a=True)\n",
    "        print('H^H(H(H^H)+S)^-1 shape',g.shape)\n",
    "\n",
    "    else:\n",
    "        # Whiten channel\n",
    "        y, h  = whiten_channel(y, h, s, return_s=False) # type: ignore\n",
    "\n",
    "        # Compute G (G = ((H^H)H + i)^-1)H^H).\n",
    "        print('h =',h)\n",
    "        print('h^H =',np.linalg.pinv(h))\n",
    "        # print('h^H shape=',(np.linalg.pinv(h)).shape)\n",
    "        i = expand_to_rank(tf.eye(h.shape[-1], dtype=s.dtype), tf.rank(s), 0)\n",
    "        print('i =',i)\n",
    "        g = tf.matmul(h, h, adjoint_a=True) + i\n",
    "        print('(h^H)h =',tf.matmul(h, h, adjoint_a=True))\n",
    "        # print('(h^H)h shape=',(tf.matmul(h, h, adjoint_a=True)).shape)\n",
    "        print('(h^H)h+i =',g)\n",
    "        # print('(h^H)h+i shape=',g.shape)\n",
    "        print('((h^H)h+i)^-1 =',matrix_inv(g))\n",
    "        # print('((h^H)h+i)^-1 shape=',(matrix_inv(g)).shape)\n",
    "        g = tf.matmul(matrix_inv(g), h, adjoint_b=True)\n",
    "        print('(((h^H)h+i)^-1)h^H =',g)\n",
    "        # print('(((h^H)H+i)^-1)h^H shape=',g.shape)\n",
    "\n",
    "    # Compute Gy\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    gy = tf.squeeze(tf.matmul(g, y), axis=-1)\n",
    "\n",
    "    # Compute GH\n",
    "    gh = tf.matmul(g, h)\n",
    "\n",
    "    # Compute diag(GH)\n",
    "    d = tf.linalg.diag_part(gh)\n",
    "\n",
    "    # Compute x_hat (x_hat=(diag(GH)^-1)Gy)\n",
    "    x_hat = gy/d\n",
    "\n",
    "    # Compute residual error variance\n",
    "    one = tf.cast(1, dtype=d.dtype)\n",
    "    no_eff = tf.math.real(one/d - one)\n",
    "\n",
    "    return x_hat, no_eff\n",
    "\n",
    "def zf_equalizer(y, h, s):\n",
    "    # Compute G\n",
    "    g = matrix_pinv(h)\n",
    "\n",
    "    # Compute x_hat\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    x_hat = tf.squeeze(tf.matmul(g, y), axis=-1)\n",
    "\n",
    "    # Compute residual error variance\n",
    "    gsg = tf.matmul(tf.matmul(g, s), g, adjoint_b=True)\n",
    "    no_eff = tf.math.real(tf.linalg.diag_part(gsg))\n",
    "\n",
    "    return x_hat, no_eff\n",
    "\n",
    "def mf_equalizer(y, h, s):\n",
    "    # Compute G\n",
    "    hth = tf.matmul(h, h, adjoint_a=True)\n",
    "    d = tf.linalg.diag(tf.cast(1, h.dtype)/tf.linalg.diag_part(hth))\n",
    "    g = tf.matmul(d, h, adjoint_b=True)\n",
    "\n",
    "    # Compute x_hat\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    x_hat = tf.squeeze(tf.matmul(g, y), axis=-1)\n",
    "\n",
    "    # Compute residual error variance\n",
    "    gsg = tf.matmul(tf.matmul(g, s), g, adjoint_b=True)\n",
    "    gh = tf.matmul(g, h)\n",
    "    i = expand_to_rank(tf.eye(gsg.shape[-2], dtype=gsg.dtype), tf.rank(gsg), 0)\n",
    "\n",
    "    no_eff = tf.abs(tf.linalg.diag_part(tf.matmul(i-gh, i-gh, adjoint_b=True) + gsg))\n",
    "    return x_hat, no_eff\n",
    "\n",
    "# k = 512 # Block Length\n",
    "# no = 0.2 # Noise variance of the channel\n",
    "# NUM_TX_ANT = 4 # Transmit Antennas\n",
    "# NUM_RX_ANT = 16 # Receive Antennas\n",
    "# NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "# BATCH_SIZE = 8 # Parallelly Processed Batches\n",
    "# EBN0_DB_MIN = -30.0 # Minimum Eb/N0 [dB]\n",
    "# EBN0_DB_MAX = 10.0 # Maximum Eb/N0 [dB]\n",
    "# snrs = []\n",
    "# bers = []\n",
    "# sers_zf = []\n",
    "# sers_lmmse = []\n",
    "\n",
    "k = 8 # Block Length\n",
    "no = 0.2 # Noise variance of the channel\n",
    "NUM_TX_ANT = 2 # Transmit Antennas\n",
    "NUM_RX_ANT = 4 # Receive Antennas\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 1 # Parallelly Processed Batches\n",
    "EBN0_DB_MIN = -30.0 # Minimum Eb/N0 [dB]\n",
    "EBN0_DB_MAX = 10.0 # Maximum Eb/N0 [dB]\n",
    "snrs = []\n",
    "bers = []\n",
    "sers_zf = []\n",
    "sers_lmmse = []\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "\n",
    "# SymbolDemapper\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "\n",
    "y, h = flatfading_channel([x_reshape, no])\n",
    "print('y shape =',y.shape)\n",
    "# print('h =',h)\n",
    "print('h shape =',h.shape)\n",
    "\n",
    "s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "print('s =',s)\n",
    "print('tf.rank(s) =',tf.rank(s))\n",
    "\n",
    "x_hat_lmmse, no_eff_lmmse = lmmse_equalizer(y, h, s)\n",
    "print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "print('no_eff_lmmse shape =',no_eff_lmmse.shape)\n",
    "\n",
    "noise_var_eff_lmmse = np.var(x_reshape-x_hat_lmmse)\n",
    "noise_var_est_lmmse = np.mean(no_eff_lmmse)\n",
    "print('noise_var_eff_lmmse =',noise_var_eff_lmmse)\n",
    "print('noise_var_est_lmmse =',noise_var_est_lmmse)\n",
    "\n",
    "plt.axes().set_aspect(1.0)\n",
    "plt.scatter(np.real(x_hat_lmmse), np.imag(x_hat_lmmse))\n",
    "plt.scatter(np.real(x), np.imag(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SymbolDemapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna\n",
    "\n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer\n",
    "# from sionna.mapping import SymbolDemapper\n",
    "from sionna.mapping import Constellation, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "\n",
    "class SymbolDemapper(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._hard_out = hard_out\n",
    "        self._with_prior = with_prior\n",
    " \n",
    "        # Create constellation object\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=dtype)\n",
    " \n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            y, prior, no = inputs\n",
    "        else:\n",
    "            y, no = inputs\n",
    "\n",
    "        # print('y =',y)\n",
    "        # print('y shape=',y.shape)\n",
    "        # print('tf.rank(y) =',tf.rank(y))\n",
    "        # print('tf.rank(y)+1 =',(tf.rank(y)+1))\n",
    "        # print('self._constellation.points =',self._constellation.points)\n",
    "        points = sn.utils.expand_to_rank(self._constellation.points,\n",
    "                                tf.rank(y)+1, axis=0)\n",
    "        # print('points =',points)\n",
    "        # print('points shape=',points.shape)\n",
    "\n",
    "        y = tf.expand_dims(y, axis=-1)\n",
    "        # print('y =',y)\n",
    "        # print('y shape=',y.shape)\n",
    "        d = tf.abs(y-points)\n",
    "        # print('d =',d)\n",
    "        # print('d shape=',d.shape)\n",
    " \n",
    "        no = sn.utils.expand_to_rank(no, tf.rank(d), axis=-1)\n",
    "        # print('no =',no)\n",
    "        # print('no shape=',no.shape)\n",
    "        exp = -d**2 / no\n",
    "        print('exp =',exp)\n",
    "        # print('exp shape=',exp.shape)\n",
    " \n",
    "        if self._with_prior:\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(exp), axis=0)\n",
    "            exp = exp + prior\n",
    " \n",
    "        if self._hard_out:\n",
    "            # tf.argmax: Get the Index of the maximum value in a tensor at the last dimension (axis=-1)\n",
    "            print('tf.argmax(exp, axis=-1, output_type=tf.int32) =',tf.argmax(exp, axis=-1, output_type=tf.int32))\n",
    "            # print('tf.argmax(exp, axis=-1, output_type=tf.int32) shape=',(tf.argmax(exp, axis=-1, output_type=tf.int32)).shape)\n",
    "            return tf.argmax(exp, axis=-1, output_type=tf.int32)\n",
    "        else:\n",
    "            # print('tf.nn.log_softmax(exp, axis=-1) =',tf.nn.log_softmax(exp, axis=-1))\n",
    "            print('tf.nn.log_softmax(exp, axis=-1) shape=',(tf.nn.log_softmax(exp, axis=-1)).shape)\n",
    "            return tf.nn.log_softmax(exp, axis=-1)\n",
    "        \n",
    "num_tx_ant = 2\n",
    "num_rx_ant = 4\n",
    "num_bits_per_symbol = 4\n",
    "batch_size = 3\n",
    "qam_source = QAMSource(num_bits_per_symbol)\n",
    "x = qam_source([batch_size, num_tx_ant])\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "channel = FlatFadingChannel(num_tx_ant, num_rx_ant, add_awgn=True, return_channel=True)\n",
    "no = 0.2 # Noise variance of the channel\n",
    "\n",
    "# y and h are the channel output and channel realizations, respectively.\n",
    "y, h = channel([x, no])\n",
    "print('y shape =',y.shape)\n",
    "print('h shape =',h.shape)\n",
    "\n",
    "s = tf.cast(no*tf.eye(num_rx_ant, num_rx_ant), y.dtype)\n",
    "x_hat, no_eff = lmmse_equalizer(y, h, s)\n",
    "print('x_hat shape =',x_hat.shape)\n",
    "\n",
    "plt.axes().set_aspect(1.0)\n",
    "plt.scatter(np.real(x_hat), np.imag(x_hat));\n",
    "plt.scatter(np.real(x), np.imag(x));\n",
    "\n",
    "print('no_eff shape =',no_eff.shape)\n",
    "\n",
    "noise_var_eff = np.var(x-x_hat)\n",
    "noise_var_est = np.mean(no_eff)\n",
    "print('noise_var_eff =',noise_var_eff)\n",
    "print('noise_var_est =',noise_var_est)\n",
    "\n",
    "symbol_demapper = SymbolDemapper(\"qam\", num_bits_per_symbol, hard_out=True)\n",
    "\n",
    "# Get symbol indices for the transmitted symbols\n",
    "x_ind = symbol_demapper([x, no])\n",
    "\n",
    "# # Get symbol indices for the received soft-symbols\n",
    "# x_ind_hat = symbol_demapper([x_hat, no])\n",
    "\n",
    "# compute_ser(x_ind, x_ind_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp_corr_mat & KroneckerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# GPU Configuration and Imports\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "    \n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "# from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel import FlatFadingChannel, SpatialCorrelation\n",
    "# from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from sionna.utils import expand_to_rank, matrix_sqrt\n",
    "\n",
    "def exp_corr_mat(a, n, dtype=tf.complex64):\n",
    "\n",
    "    # Cast to desired output dtype and expand last dimension for broadcasting\n",
    "    a = tf.cast(a, dtype=dtype)\n",
    "    a = tf.expand_dims(a, -1)\n",
    " \n",
    "    # Check that a is valid\n",
    "    msg = \"The absolute value of the elements of `a` must be smaller than one\"\n",
    "    tf.debugging.assert_less(tf.abs(a), tf.cast(1, a.dtype.real_dtype), msg)\n",
    " \n",
    "    # Vector of exponents, adapt dtype and dimensions for broadcasting\n",
    "    exp = tf.range(0, n)\n",
    "    exp = tf.cast(exp, dtype=dtype)\n",
    "    exp = expand_to_rank(exp, tf.rank(a), 0)\n",
    " \n",
    "    # First column of R\n",
    "    col = tf.math.pow(a, exp)\n",
    " \n",
    "    # For a=0, one needs to remove the resulting nans due to 0**0=nan\n",
    "    cond = tf.math.is_nan(tf.math.real(col))\n",
    "    col = tf.where(cond, tf.ones_like(col), col)\n",
    " \n",
    "    # First row of R (equal to complex-conjugate of the first column)\n",
    "    row = tf.math.conj(col)\n",
    " \n",
    "    # Create Toeplitz operator\n",
    "    operator = tf.linalg.LinearOperatorToeplitz(col, row)\n",
    " \n",
    "    # Generate dense tensor from operator\n",
    "    r = operator.to_dense()\n",
    " \n",
    "    return r\n",
    "\n",
    "class KroneckerModel(SpatialCorrelation):\n",
    "    def __init__(self, r_tx=None, r_rx=None):\n",
    "        super().__init__()\n",
    "        self.r_tx = r_tx\n",
    "        self.r_rx = r_rx\n",
    " \n",
    "    @property\n",
    "    def r_tx(self):\n",
    "        return self._r_tx\n",
    " \n",
    "    @r_tx.setter\n",
    "    def r_tx(self, value):\n",
    "        self._r_tx = value\n",
    "        if self._r_tx is not None:\n",
    "            self._r_tx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_tx_sqrt = None\n",
    " \n",
    "    @property\n",
    "    def r_rx(self):\n",
    "        return self._r_rx\n",
    " \n",
    "    @r_rx.setter\n",
    "    def r_rx(self, value):\n",
    "        self._r_rx = value\n",
    "        if self._r_rx is not None:\n",
    "            self._r_rx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_rx_sqrt = None\n",
    " \n",
    "    def __call__(self, h):\n",
    "        if self._r_tx_sqrt is not None:\n",
    "            r_tx_sqrt = expand_to_rank(self._r_tx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(h, r_tx_sqrt, adjoint_b=True)\n",
    " \n",
    "        if self._r_rx_sqrt is not None:\n",
    "            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(r_rx_sqrt, h)\n",
    "        # print('h =',h)\n",
    "        return h\n",
    "\n",
    "k = 512 # Block Length\n",
    "no = 0.2 # Noise variance of the channel\n",
    "NUM_TX_ANT = 4 # Transmit Antennas\n",
    "NUM_RX_ANT = 4 # Receive Antennas\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 1024 # Parallelly Processed Batches\n",
    "EBN0_DB_MIN = -30.0 # Minimum Eb/N0 [dB]\n",
    "EBN0_DB_MAX = 10.0 # Maximum Eb/N0 [dB]\n",
    "snrs = []\n",
    "bers = []\n",
    "sers_zf = []\n",
    "sers_lmmse = []\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "\n",
    "# SymbolDemapper\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "x_ind = symbol_demapper([x, no])\n",
    "print('x_ind shape',x_ind.shape)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "\n",
    "# Adding Spatial Correlation\n",
    "# Create transmit and receive correlation matrices\n",
    "r_tx = exp_corr_mat(0.1, NUM_TX_ANT)\n",
    "r_rx = exp_corr_mat(0.1, NUM_RX_ANT)\n",
    "print('r_tx =',r_tx)\n",
    "print('r_rx =',r_rx)\n",
    "\n",
    "# Add the spatial correlation model to the channel\n",
    "flatfading_channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "\n",
    "y, h = flatfading_channel([x_reshape, no])\n",
    "print('y shape =',y.shape)\n",
    "# print('h =',h)\n",
    "print('h shape =',h.shape)\n",
    "\n",
    "# Compute empirical covariance matrices\n",
    "r_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/NUM_RX_ANT\n",
    "r_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/NUM_TX_ANT\n",
    "\n",
    "# Test that the empirical results match the theory\n",
    "assert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\n",
    "assert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n",
    "\n",
    "s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "\n",
    "x_hat_lmmse, no_eff_lmmse = lmmse_equalizer(y, h, s)\n",
    "print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "print('no_eff_lmmse shape =',no_eff_lmmse.shape)\n",
    "\n",
    "# Confirm the correctness of estimate x by comparing \n",
    "# the average estimated effective noise variance between \n",
    "# the transmitted and equalized symbols.\n",
    "noise_var_eff_lmmse = np.var(x_reshape-x_hat_lmmse)\n",
    "noise_var_est_lmmse = np.mean(no_eff_lmmse)\n",
    "# print('noise_var_eff_lmmse =',noise_var_eff_lmmse)\n",
    "# print('noise_var_est_lmmse =',noise_var_est_lmmse)\n",
    "\n",
    "x_hat_lmmse = tf.reshape(x_hat_lmmse, shape)\n",
    "\n",
    "x_ind_hat_lmmse = symbol_demapper([x_hat_lmmse, no])\n",
    "print('x_ind_hat_lmmse shape',x_ind_hat_lmmse.shape)\n",
    "\n",
    "print('SER =',compute_ser(x_ind, x_ind_hat_lmmse))\n",
    "\n",
    "plt.axes().set_aspect(1.0)\n",
    "plt.scatter(np.real(x_hat_lmmse), np.imag(x_hat_lmmse))\n",
    "plt.scatter(np.real(x), np.imag(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepImagePrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 19:16:43.474781: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 0\n",
      "b shape = (1, 4, 8)\n",
      "b = tf.Tensor(\n",
      "[[[1. 0. 0. 1. 1. 1. 0. 1.]\n",
      "  [1. 0. 0. 1. 0. 0. 1. 1.]\n",
      "  [1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "  [0. 1. 0. 0. 1. 0. 0. 1.]]], shape=(1, 4, 8), dtype=float32)\n",
      "x shape = (1, 4, 2)\n",
      "x = tf.Tensor(\n",
      "[[[-0.3162278+0.9486833j -0.3162278-0.9486833j]\n",
      "  [-0.3162278+0.9486833j  0.9486833+0.9486833j]\n",
      "  [-0.9486833+0.3162278j -0.9486833-0.9486833j]\n",
      "  [ 0.3162278-0.3162278j -0.3162278+0.9486833j]]], shape=(1, 4, 2), dtype=complex64)\n",
      "x reshape = (2, 4)\n",
      "TX_ANT_CORRELATION_INDEX = 0.1\n",
      "RX_ANT_CORRELATION_INDEX = 0.1\n",
      "h.shape =\n",
      " (2, 16, 4)\n",
      "y.shape =\n",
      " (2, 16)\n",
      "Y shape= (2, 16)\n",
      "Y = tf.Tensor(\n",
      "[[  3.979923   -1.2577324j    8.067277   -3.955019j\n",
      "    4.655363   +6.46085j      3.1919937  -5.1065345j\n",
      "   -2.430389   +7.1592674j   -0.04395366 +3.9714246j\n",
      "  -19.785105  -12.086312j    -8.703782   +4.2686114j\n",
      "   -0.02105239 +6.463314j     2.8954153  -9.718775j\n",
      "    2.9155006  +5.7738156j  -12.098549   -5.8574195j\n",
      "    9.164595   +1.0592384j   10.834409   -8.361681j\n",
      "    2.523401   -1.3651795j   -8.259767  +19.141478j  ]\n",
      " [  5.748241  +16.030458j     1.9299939  -8.878938j\n",
      "    1.6955953 -11.479931j    -3.719088   -2.189886j\n",
      "    0.7724427  -5.819427j     3.6103694  -0.6577479j\n",
      "    9.241739   +0.48185992j  -3.830353   -0.53976893j\n",
      "    6.041432   +0.26964545j -11.782206   +7.738495j\n",
      "    6.3264503  +8.831793j     0.4515128  +4.49879j\n",
      "    1.0969795 -10.600309j    -3.2755938  +0.40453494j\n",
      "    5.66591    -0.91411066j   3.0041075  -2.234287j  ]], shape=(2, 16), dtype=complex64)\n",
      "H shape= (2, 16, 4)\n",
      "H = tf.Tensor(\n",
      "[[[-0.7343505 +0.17998466j -0.4443169 -1.6453273j\n",
      "   -1.6152505 -1.5198717j  -0.66618884+1.9847796j ]\n",
      "  [ 1.4201188 -0.25535408j -1.1380517 -0.8821775j\n",
      "   -1.0003704 -0.46576977j  0.8560566 -0.09793015j]\n",
      "  [-0.41432178-0.2580635j  -1.5771072 -0.10496606j\n",
      "   -0.17241052-0.19568631j  1.1381124 -0.2473832j ]\n",
      "  [-0.50090295-0.07018991j  0.02537499-0.15658395j\n",
      "    0.19652444-0.96873504j -0.04940052-0.16681203j]\n",
      "  [-0.01342029+0.4575927j  -0.648062  +0.45291945j\n",
      "    0.725005  -0.30236426j  0.13097401+0.68602693j]\n",
      "  [ 0.2112347 -0.81555575j -1.1826233 +1.1372958j\n",
      "   -1.0890459 -0.30893415j  0.14211234+0.5234777j ]\n",
      "  [-0.3157057 +0.9633734j   0.37827885-0.28796062j\n",
      "    0.5227672 +0.02677158j  0.65545034+0.6309772j ]\n",
      "  [-0.03771867+0.10668264j  0.19550262+0.39627454j\n",
      "   -0.21010649-0.83806616j  0.19645737+0.7670349j ]\n",
      "  [ 1.3414426 -1.0356622j  -0.15442589-0.26914364j\n",
      "   -0.7762739 -0.11140464j -0.9040986 -0.39853767j]\n",
      "  [ 0.46334597-0.09274535j  0.10105816-0.13001087j\n",
      "   -1.2322748 +0.898309j   -1.0135455 -1.1418891j ]\n",
      "  [ 0.04438362-0.14440353j -0.17961405-0.04960788j\n",
      "    1.0226427 +0.64113903j  0.71694785-0.86396897j]\n",
      "  [ 1.3188994 -0.52989465j -0.12375493-0.03456305j\n",
      "    0.16006951+0.39652765j  0.36778465+1.3121349j ]\n",
      "  [ 0.03413161-0.78403723j -0.13965216+1.0208662j\n",
      "    2.0181935 -0.19205013j  0.76908636-0.5543625j ]\n",
      "  [ 0.12511344+1.4749348j   0.21264382+0.6574627j\n",
      "   -1.0680743 +0.5140386j  -0.29833114-0.52414566j]\n",
      "  [ 0.43274614+1.2634754j   0.67013806-0.14981441j\n",
      "   -0.24748407-0.24386092j -0.37788153-0.24953558j]\n",
      "  [-0.3169691 -0.069906j   -1.342051  +0.6034453j\n",
      "   -0.24698864-0.86562955j -0.35747802+0.52736974j]]\n",
      "\n",
      " [[ 0.48629147-0.31094444j  1.4756799 +1.646348j\n",
      "    0.88403845-0.949008j   -0.12374974+0.08940354j]\n",
      "  [ 0.15515128-0.30548427j -0.8126419 -1.0507283j\n",
      "    0.7847277 +0.6290003j   0.29027325+0.66909385j]\n",
      "  [ 0.8540365 -0.5861757j  -0.18993819+0.82724047j\n",
      "    0.49685723-1.3782796j  -0.8347571 +1.447276j  ]\n",
      "  [ 0.45895597+0.28699255j -0.5664751 -0.18366995j\n",
      "   -0.36034334-1.2398514j   0.53021705+0.12281051j]\n",
      "  [-0.04534743+1.1212554j  -0.1967602 -0.80995935j\n",
      "   -0.7019759 +0.8377493j   0.11048856-0.04192101j]\n",
      "  [-0.63811904+1.0399168j   0.08319441-0.6124954j\n",
      "   -0.91062903-0.6258698j   0.70286465+0.39252928j]\n",
      "  [ 0.03681339-0.2042739j   0.9577442 +0.01797128j\n",
      "   -0.19438699-0.01220778j -0.13298887-0.7791391j ]\n",
      "  [ 0.02765553-0.92958605j  0.60229415-1.1651543j\n",
      "    1.5461931 +0.6111035j   1.5370741 -0.41961005j]\n",
      "  [-0.8208712 -1.7307677j   0.02909848-1.2222726j\n",
      "    1.4328605 -0.5912541j   0.5469095 -1.3942208j ]\n",
      "  [ 0.29313776-1.1686423j   0.00604602+0.1697823j\n",
      "   -0.16465639+0.01479224j  1.0303185 -1.142019j  ]\n",
      "  [ 1.2052776 -0.00373182j  0.06840091+0.591492j\n",
      "   -0.66260326-0.00569433j  0.7325783 +1.1110339j ]\n",
      "  [ 0.837062  +0.22381818j -0.49247706+0.5135241j\n",
      "    0.45565844-1.8872387j   0.76572746-0.06856342j]\n",
      "  [ 0.24456216+0.6687299j   0.9093613 +0.74608016j\n",
      "    0.16835009+0.8713473j   2.191259  +0.18187615j]\n",
      "  [ 1.2861897 -0.09730271j -1.0018628 +0.83059156j\n",
      "    0.5905898 -0.7063204j   0.4611737 +0.53852195j]\n",
      "  [ 0.19814198+0.9196466j   0.25647902-0.35695446j\n",
      "   -0.03093316-0.04484797j  0.8037797 +0.8280128j ]\n",
      "  [ 0.5084815 +0.00777614j  0.8157807 +0.49538037j\n",
      "    0.8187691 +0.01312153j -0.5563833 +0.15482336j]]], shape=(2, 16, 4), dtype=complex64)\n",
      "y_torch = tensor([[[[  3.9799],\n",
      "          [  8.0673],\n",
      "          [  4.6554],\n",
      "          [  3.1920],\n",
      "          [ -2.4304],\n",
      "          [ -0.0440],\n",
      "          [-19.7851],\n",
      "          [ -8.7038],\n",
      "          [ -0.0211],\n",
      "          [  2.8954],\n",
      "          [  2.9155],\n",
      "          [-12.0985],\n",
      "          [  9.1646],\n",
      "          [ 10.8344],\n",
      "          [  2.5234],\n",
      "          [ -8.2598]]]])\n",
      "H_torch = tensor([[[[-0.7344, -0.4443, -1.6153, -0.6662],\n",
      "          [ 1.4201, -1.1381, -1.0004,  0.8561],\n",
      "          [-0.4143, -1.5771, -0.1724,  1.1381],\n",
      "          [-0.5009,  0.0254,  0.1965, -0.0494],\n",
      "          [-0.0134, -0.6481,  0.7250,  0.1310],\n",
      "          [ 0.2112, -1.1826, -1.0890,  0.1421],\n",
      "          [-0.3157,  0.3783,  0.5228,  0.6555],\n",
      "          [-0.0377,  0.1955, -0.2101,  0.1965],\n",
      "          [ 1.3414, -0.1544, -0.7763, -0.9041],\n",
      "          [ 0.4633,  0.1011, -1.2323, -1.0135],\n",
      "          [ 0.0444, -0.1796,  1.0226,  0.7169],\n",
      "          [ 1.3189, -0.1238,  0.1601,  0.3678],\n",
      "          [ 0.0341, -0.1397,  2.0182,  0.7691],\n",
      "          [ 0.1251,  0.2126, -1.0681, -0.2983],\n",
      "          [ 0.4327,  0.6701, -0.2475, -0.3779],\n",
      "          [-0.3170, -1.3421, -0.2470, -0.3575]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/im/Documents/GitHub/sionna/Jupyter Notebooks/xyDIP.py:105: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686209/work/aten/src/ATen/native/Copy.cpp:276.)\n",
      "  y_torch = torch.from_numpy((Y[bs]).numpy()).reshape(1, 1, self.user_num, 1).type(dtype)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [1, 8].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 233\u001b[0m\n\u001b[1;32m    230\u001b[0m x_hat_lmmse, no_eff_lmmse \u001b[39m=\u001b[39m lmmse_equalizer(y, h, s)\n\u001b[1;32m    231\u001b[0m \u001b[39m# print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m x_dip_ay,num_stop_point \u001b[39m=\u001b[39m dip\u001b[39m.\u001b[39;49mDIP(y,h)\n\u001b[1;32m    234\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx_dip_ay.shape =\u001b[39m\u001b[39m'\u001b[39m,x_dip_ay\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    235\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx_dip_ay =\u001b[39m\u001b[39m'\u001b[39m,x_dip_ay)\n",
      "File \u001b[0;32m~/Documents/GitHub/sionna/Jupyter Notebooks/xyDIP.py:133\u001b[0m, in \u001b[0;36mDeepImagePrior.DIP\u001b[0;34m(self, Y, H)\u001b[0m\n\u001b[1;32m    131\u001b[0m out1 \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtype(dtype) \u001b[39m# Tx * Block Length=(4)*(2)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# print('out1 shape =',out1.shape)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m Y_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(H_torch,out1)\u001b[39m.\u001b[39mtype(dtype)\n\u001b[1;32m    134\u001b[0m total_loss \u001b[39m=\u001b[39m mse(Y_hat,y_torch)\n\u001b[1;32m    135\u001b[0m total_loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [1, 4] but got: [1, 8]."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from myDIP import DeepImagePrior, Decoder, EarlyStop\n",
    "\n",
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# GPU Configuration and Imports\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "    \n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from xyDIP import DeepImagePrior\n",
    "\n",
    "k = 8 # Block Length512\n",
    "# no = 0.2 # Noise variance of the channel\n",
    "NUM_TX_ANT = 4 # Transmit Antennas\n",
    "NUM_RX_ANT = 16 # Receive Antennas\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 1 # Parallelly Processed Batches: 32\n",
    "EBN0_DB_MIN = -25.0 # Minimum Eb/N0 [dB]\n",
    "EBN0_DB_MAX = 25.0 # Maximum Eb/N0 [dB]\n",
    "TX_ANT_CORRELATION_INDEX = 0\n",
    "RX_ANT_CORRELATION_INDEX = 0\n",
    "CORRELATION_INDEX_MIN = 0.1\n",
    "CORRELATION_INDEX_MAX = 0.9\n",
    "snrs = np.linspace(EBN0_DB_MIN,EBN0_DB_MAX,51)\n",
    "# print('snrs[25] =',snrs[25])\n",
    "bers = []\n",
    "sers_zf = np.zeros((9, 51))\n",
    "sers_lmmse = np.zeros((9, 51))\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "\n",
    "# SymbolDemapper\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "\n",
    "# Deep Image Prior\n",
    "dip = DeepImagePrior(user_num=NUM_RX_ANT,      # Number of transmitted symbol in real domain\n",
    "                    M=16,              # Modulation order, 4 for 4QAM, 16 for 16QAM; 16QAM: 4 bits per symbol\n",
    "                    iteration=100,    # Number of max iterations used for DIP: 100\n",
    "                    LR=0.01,          # Learning rate,  typically set to 0.01\n",
    "                    buffer_size=30,   # Iterations stored,  typically set to 30\n",
    "                    threshold=0.001,  # Threshold of DIP stop,, typically set to 0.001\n",
    "                    stop=True)        # True\n",
    "\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "print('b =',b)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "print('x =',x)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "# print('x_reshape =',x_reshape)\n",
    "\n",
    "# Tx_Symbols = bits2symbol(b,NUM_BITS_PER_SYMBOL)\n",
    "# print('Tx_Symbols =',Tx_Symbols)\n",
    "\n",
    "# # Adding Spatial Correlation\n",
    "# # Create transmit and receive correlation matrices\n",
    "# r_tx = exp_corr_mat(TX_ANT_CORRELATION_INDEX, NUM_TX_ANT)\n",
    "# r_rx = exp_corr_mat(RX_ANT_CORRELATION_INDEX, NUM_RX_ANT)\n",
    "# # print('r_tx =',r_tx)\n",
    "# # print('r_rx =',r_rx)\n",
    "\n",
    "# # Add the spatial correlation model to the channel\n",
    "# flatfading_channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "\n",
    "for TX_ANT_CORRELATION_INDEX in np.linspace(CORRELATION_INDEX_MIN,CORRELATION_INDEX_MAX,3):\n",
    "    r_tx = exp_corr_mat(TX_ANT_CORRELATION_INDEX, NUM_TX_ANT)\n",
    "    for RX_ANT_CORRELATION_INDEX in np.linspace(CORRELATION_INDEX_MIN,CORRELATION_INDEX_MAX,3):\n",
    "        print('TX_ANT_CORRELATION_INDEX =',TX_ANT_CORRELATION_INDEX)\n",
    "        print('RX_ANT_CORRELATION_INDEX =',RX_ANT_CORRELATION_INDEX)\n",
    "        r_rx = exp_corr_mat(RX_ANT_CORRELATION_INDEX, NUM_RX_ANT)\n",
    "        flatfading_channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "        if i == 0:\n",
    "            LINE_COLOR_ZF = 'red'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'lawngreen'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "        elif i == 1:\n",
    "            LINE_COLOR_ZF = 'orange'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'deepskyblue'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '-.'\n",
    "        elif i == 2:\n",
    "            LINE_COLOR_ZF = 'chocolate'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'dodgerblue'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "        elif i == 3:\n",
    "            LINE_COLOR_ZF = 'goldenrod'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'darkorchid'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '-.'\n",
    "        elif i == 4:\n",
    "            LINE_COLOR_ZF = 'springgreen'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'fuchsia'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "        elif i == 5:\n",
    "            LINE_COLOR_ZF = 'black'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'gold'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '-.'\n",
    "        elif i == 6:\n",
    "            LINE_COLOR_ZF = 'brown'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'darkcyan'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "        elif i == 7:\n",
    "            LINE_COLOR_ZF = 'darkorange'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'crimson'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '-.'\n",
    "        else:\n",
    "            LINE_COLOR_ZF = 'olive'\n",
    "            LINE_MARKER_ZF = 'o'\n",
    "            LINE_STYLE_ZF = '-'\n",
    "            LINE_COLOR_LMMSE = 'lightcoral'\n",
    "            LINE_MARKER_LMMSE = '>'\n",
    "            LINE_STYLE_LMMSE = '--'\n",
    "\n",
    "        for EBN0_DB in np.linspace(EBN0_DB_MIN,EBN0_DB_MAX,1): # 51\n",
    "\n",
    "            # snrs += [EBN0_DB]\n",
    "\n",
    "            no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                                    num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                                    coderate=1.0) # Coderate set to 1 as we do uncoded transmission here\n",
    "            # print('no =',no)\n",
    "\n",
    "            x_ind = symbol_demapper([x, no])\n",
    "            # print('x_ind.shape =',x_ind.shape)\n",
    "            # print('x_ind =',x_ind)\n",
    "\n",
    "            # y and h are the Channel Output and Channel Realizations, respectively.\n",
    "            y, h = flatfading_channel([x_reshape, no])\n",
    "            print('h.shape =\\n',h.shape)\n",
    "            # print('h =',h)\n",
    "            print('y.shape =\\n',y.shape)\n",
    "            # print('y =',y)\n",
    "\n",
    "            # Compute empirical covariance matrices\n",
    "            r_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/NUM_RX_ANT\n",
    "            r_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/NUM_TX_ANT\n",
    "\n",
    "            # # Test that the empirical results match the theory\n",
    "            # assert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\n",
    "            # assert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n",
    "\n",
    "            s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "\n",
    "            x_hat_zf, no_eff_zf = zf_equalizer(y, h, s)\n",
    "            # print('x_hat_zf.shape =',x_hat_zf.shape)\n",
    "            x_hat_lmmse, no_eff_lmmse = lmmse_equalizer(y, h, s)\n",
    "            # print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "\n",
    "            x_dip_ay,num_stop_point = dip.DIP(y,h)\n",
    "            print('x_dip_ay.shape =',x_dip_ay.shape)\n",
    "            print('x_dip_ay =',x_dip_ay)\n",
    "            print('num_stop_point =',num_stop_point)\n",
    "\n",
    "            # Confirm the correctness of estimate x by comparing \n",
    "            # the average estimated effective noise variance between \n",
    "            # the transmitted and equalized symbols.\n",
    "            noise_var_eff_zf = np.var(x_reshape-x_hat_zf)\n",
    "            noise_var_est_zf = np.mean(no_eff_zf)\n",
    "            noise_var_eff_lmmse = np.var(x_reshape-x_hat_lmmse)\n",
    "            noise_var_est_lmmse = np.mean(no_eff_lmmse)\n",
    "            # print('noise_var_eff_lmmse =',noise_var_eff_lmmse)\n",
    "            # print('noise_var_est_lmmse =',noise_var_est_lmmse)\n",
    "\n",
    "            x_hat_zf = tf.reshape(x_hat_zf, shape)\n",
    "            # print('x_hat_zf.shape =',x_hat_zf.shape)\n",
    "            x_hat_lmmse = tf.reshape(x_hat_lmmse, shape)\n",
    "            # print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "\n",
    "            no_eff_zf = tf.reshape(no_eff_zf, shape)\n",
    "            # print('no_eff_zf.shape =',no_eff_zf.shape)\n",
    "            no_eff_lmmse = tf.reshape(no_eff_lmmse, shape)\n",
    "            # print('no_eff_lmmse.shape =',no_eff_lmmse.shape)\n",
    "\n",
    "            # llr_zf = demapper([x_hat_zf, no_eff_zf])\n",
    "            # b_hat_zf = decoder(llr_zf)\n",
    "\n",
    "            x_ind_hat_zf = symbol_demapper([x_hat_zf, no_eff_zf])\n",
    "            # print('x_ind_hat_zf.shape =',x_ind_hat_zf.shape)\n",
    "            # print('x_ind_hat_zf =',x_ind_hat_zf)\n",
    "            x_ind_hat_lmmse = symbol_demapper([x_hat_lmmse, no_eff_lmmse])\n",
    "            # print('x_ind_hat_lmmse.shape =',x_ind_hat_lmmse.shape)\n",
    "\n",
    "            ser_zf = compute_ser(x_ind, x_ind_hat_zf)\n",
    "            ser_lmmse = compute_ser(x_ind, x_ind_hat_lmmse)\n",
    "            # sers_zf += [ser_zf]\n",
    "            # sers_lmmse += [ser_lmmse]\n",
    "            sers_zf[i][j] = ser_zf\n",
    "            sers_lmmse[i][j] = ser_lmmse\n",
    "            j = j + 1\n",
    "        \n",
    "        j = 0 \n",
    "        # print(snrs)\n",
    "        # print(sers_zf[i])\n",
    "        # print(sers_lmmse[i])\n",
    "        # print('snrs shape =',len(snrs))\n",
    "        # print('sers_zf shape=',len(sers_zf))\n",
    "        # print('sers_lmmse shape=',len(sers_lmmse))\n",
    "        plt.rcParams['figure.figsize']=(10,10)\n",
    "        plt.semilogy(snrs, sers_zf[i], color = LINE_COLOR_ZF, linestyle = LINE_STYLE_ZF, \\\n",
    "                     label='ZF ({},{})'.format(TX_ANT_CORRELATION_INDEX,RX_ANT_CORRELATION_INDEX))\n",
    "        plt.semilogy(snrs, sers_lmmse[i], color = LINE_COLOR_LMMSE, linestyle = LINE_STYLE_LMMSE, \\\n",
    "                     label='LMMSE ({},{})'.format(TX_ANT_CORRELATION_INDEX,RX_ANT_CORRELATION_INDEX))\n",
    "        # plt.text(snrs[25], sers_zf[i][25], '({},{}).format(TX_ANT_CORRELATION_INDEX,RX_ANT_CORRELATION_INDEX)', \\\n",
    "        #          fontsize=8, color = \"r\", style = \"italic\", weight = \"light\", verticalalignment='center', \\\n",
    "        #          horizontalalignment='right', rotation=90)\n",
    "        plt.scatter(snrs[25], sers_zf[i][25], marker='o', color='red')\n",
    "        plt.scatter(snrs[25], sers_lmmse[i][25], marker='o', color='green')\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        plt.legend(handles[::-1], labels[::-1], loc='lower left', fontsize=10)\n",
    "        i = i + 1\n",
    "title = \"SER: Uncoded MIMO with ZF,MMSE\"\n",
    "xlabel = \"$E_b/N_0$ (dB)\"\n",
    "ylabel = \"SER\"\n",
    "plt.title(title, fontsize=15)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel(ylabel, fontsize=15)\n",
    "plt.grid(which=\"both\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder Debug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constellation = [-0.70710678  0.70710678]\n",
      "net_input = tensor([[-0.6823,  0.1965, -0.1067,  0.8085]])\n",
      "x = tensor([[-0.6823,  0.1965, -0.1067,  0.8085]])\n",
      "nn1 = tensor([[ 0.1597, -0.3540, -0.2885, -0.7414,  0.2953,  0.1158,  0.2866,  0.5733]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "o1 = tensor([[ 0.1584, -0.3399, -0.2808, -0.6300,  0.2870,  0.1152,  0.2790,  0.5178]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "nn2 = tensor([[ 0.0026, -0.0246,  0.0367,  0.4040,  0.0383,  0.3631, -0.0752, -0.1903,\n",
      "          0.2346,  0.6832, -0.3954,  0.1268, -0.2634,  0.3085, -0.1021,  0.1200]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "o2 = tensor([[ 0.0026, -0.0246,  0.0367,  0.3833,  0.0383,  0.3479, -0.0751, -0.1881,\n",
      "          0.2304,  0.5936, -0.3760,  0.1261, -0.2574,  0.2991, -0.1018,  0.1194]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "nn3 = tensor([[-0.0105, -0.2657,  0.0159, -0.3150,  0.0316,  0.0507, -0.1769,  0.1651,\n",
      "         -0.1346,  0.0509,  0.2669,  0.1090, -0.2130, -0.1471, -0.0518, -0.2691,\n",
      "         -0.0928, -0.0916, -0.2771, -0.2713, -0.0297,  0.0503,  0.3862, -0.0244,\n",
      "          0.1895, -0.1879, -0.2781,  0.1211, -0.0517,  0.3379, -0.1228,  0.0984]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "o3 = tensor([[-0.0105, -0.2596,  0.0159, -0.3050,  0.0316,  0.0507, -0.1751,  0.1636,\n",
      "         -0.1338,  0.0509,  0.2607,  0.1086, -0.2099, -0.1460, -0.0518, -0.2628,\n",
      "         -0.0925, -0.0913, -0.2702, -0.2648, -0.0297,  0.0502,  0.3681, -0.0244,\n",
      "          0.1873, -0.1858, -0.2711,  0.1205, -0.0516,  0.3256, -0.1222,  0.0981]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "nn4 = tensor([[ 0.0810, -0.0409, -0.0118, -0.1327,  0.0320, -0.0612,  0.3484,  0.1243,\n",
      "         -0.1946,  0.0845, -0.2314, -0.0361, -0.3657, -0.0239, -0.1938,  0.0437]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "o4 = tensor([[ 0.0809, -0.0409, -0.0118, -0.1319,  0.0319, -0.0611,  0.3350,  0.1236,\n",
      "         -0.1922,  0.0843, -0.2273, -0.0361, -0.3503, -0.0239, -0.1914,  0.0437]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "net_output shape = torch.Size([1, 16])\n",
      "net_output = tensor([[ 0.0809, -0.0409, -0.0118, -0.1319,  0.0319, -0.0611,  0.3350,  0.1236,\n",
      "         -0.1922,  0.0843, -0.2273, -0.0361, -0.3503, -0.0239, -0.1914,  0.0437]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "max_constellation = 0.7071067811865475\n",
      "out shape = torch.Size([1, 16])\n",
      "out1 shape = torch.Size([1, 1, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,user_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nn1 = nn.Linear(4,8) # Define numbers of input (4) and output (8) of fully connected layer\n",
    "                                  # Weight.shape = (number of output (8),number of input (4))\n",
    "                                  # Bias.shape = number of output (8)\n",
    "        self.nn2 = nn.Linear(8,16)\n",
    "        self.nn3 = nn.Linear(16,32)\n",
    "        self.nn4 = nn.Linear(32,user_num)\n",
    "        self.act = nn.Tanh() # Define Activation Function: Tanh()\n",
    "         \n",
    "    def forward(self,x):\n",
    "        print('x =', x)\n",
    "        nn1 = self.nn1(x)\n",
    "        print('nn1 =', nn1)\n",
    "        o1 = self.act(nn1)\n",
    "        print('o1 =', o1)\n",
    "        nn2 = self.nn2(o1)\n",
    "        print('nn2 =', nn2)\n",
    "        o2 = self.act(nn2)\n",
    "        print('o2 =', o2)\n",
    "        nn3 = self.nn3(o2)\n",
    "        print('nn3 =', nn3)\n",
    "        o3 = self.act(nn3)\n",
    "        print('o3 =', o3)\n",
    "        nn4 = self.nn4(o3)\n",
    "        print('nn4 =', nn4)\n",
    "        o4 = self.act(nn4)\n",
    "        print('o4 =', o4)\n",
    "        return o4\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters() \n",
    "\n",
    "LR = 0.01\n",
    "M = 6\n",
    "constellation = np.linspace(int(-np.sqrt(M) + 1), int(np.sqrt(M) - 1), int(np.sqrt(M)))\n",
    "alpha = np.sqrt((constellation ** 2).mean())\n",
    "constellation /= (alpha * np.sqrt(2))\n",
    "print('constellation =', constellation)\n",
    "\n",
    "user_num = 16\n",
    "dtype = torch.FloatTensor\n",
    "net = Decoder(user_num).type(dtype)\n",
    "# for param in net.parameters():\n",
    "#     print(param)\n",
    "mse = torch.nn.MSELoss().type(dtype)        ###Loss function\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr= LR)     ###Adam optimizer\n",
    "WR = weight_reset\n",
    "# net.apply(WR)\n",
    "# for param in net.parameters():\n",
    "#     print(param)\n",
    "net_input = torch.randn(1,4)\n",
    "print('net_input =', net_input)\n",
    "\n",
    "net_output = net(net_input).type(dtype)\n",
    "print('net_output shape =', net_output.shape)\n",
    "print('net_output =', net_output)\n",
    "max_constellation= np.max(constellation)\n",
    "print('max_constellation =', max_constellation)\n",
    "out = net_output*max_constellation\n",
    "print('out shape =', out.shape)\n",
    "out1 = out.reshape(1,1,user_num,1).type(dtype)\n",
    "print('out1 shape =', out1.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAHBCAYAAACYFepwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHIklEQVR4nO3deXhbZ533/4+8x05sWdnaJE6b42zdWy+lQMsWOW3ZCq3dwAADA9ga5hkGaMEiMAxkHsC1WX/MUHDCVngGSCT2aaGxCi2FFupYTbqniY/TpNkTWbETx7Zs6/eHIzWO7cSLrKPl/bouX63kY+mrbxT5k/vc575t4XA4LAAAgCSTYXUBAAAAU0GIAQAASYkQAwAAkhIhBgAAJCVCDAAASEqEGAAAkJQIMQAAICkRYgAAQFIixADTtHHjRpWXl8tms6m0tFQ1NTUyTTP6/fLycrlcLgsrvHANfr9fNpttwo/ndrtls9nk8/liUZ6k+PQpXn8WTU1NstlsY3653e4Zf/7xJMJ7EYilLKsLAJJZU1OTGhoatGnTJpWVlck0TXk8Hvl8PtXV1UmS1q9fL7vdbmmdsa5h48aNMgxDHo9HTqczJo8Zjz7F68/i+PHjstvt6ujoGPU9K98LifBeBGIqDGDKJIU9Ho/VZUxbW1tbeKIfB21tbWHDMMLNzc1hu90+6edqaWkJG4Yx6Z9LtOc4n/r6+in1Jlasfv1AvHA6CZimdPuXbXNzs5xOp5xOp4LBYExPKQHAZBBigGlwOp1yuVzn/UVeVVU1Yh5EMBhUTU2NiouLVV5eLrfbrdLSUpWXl0uSampq1NTUJJfLpeLiYpWWlsrn88nn86m0tFQ2m001NTWjnifyOMXFxaPmPYxVQ1VVlWw2m8rLyycVRLZs2aKamhoZhiHDMNTc3DzmcU1NTdF6I89RU1OjqqoqmaYZnSMSDAZH1ehyuUa9xrPn7Xi93hHzkLxeb/S4iT7HRPo23p9FLJxby7nzkiby3NPpsdWvH4gFQgwwDR6PR3a7PRoIampq5Pf7z/szbrdbDodDnZ2dcrlc8nq9am9vV1tbm6ThgOF2u1VTU6OOjg6VlZWppqZGzc3NamtrU1tbm7xerzZu3Bh9zMjztrS0qKOjQ4FAQFVVVePWUFNTo0AgoPb2dj300ENqbW2d0Ov1+XwKBoPReTDV1dUjAkSEy+XS5s2b5fF41NnZqcbGRgWDQXk8Hnk8HhmGoXA4rHA4POZIVk1NzajHbW5uVnV1tSQpEAho06ZNCofDam5uHtH3iT5H5HnO17ex/iziNTH2Qs893R5Lif36gQmx8FQWkDLa2trC9fX1YcMwRs2TcTqd4fr6+uhtu90ebmtri96WFG5vbx9xfFlZWfR2S0tLWFK4paUlel9ZWVn0MSPzWTo7O0fUZLfboz9zdg3t7e2jnnOic2Kqq6vDTqdz1M+d/Xo7OztHPf7ZPB7PmPM1xurT2Y977u2zGYYRbmxsnNRzTLRvY/1ZXEh9fX1Y0qivs2s69/We+2dwvueORY9n8vUD8cJIDBADZWVlamxsVHt7u6qrqyd9Ga3D4Rhxu6KiYtT3zr7PMIzoKYJt27bJMIxR/9quqKhQS0vLqOfy+/2y2+0yDGNSNUrDp3HOPs1TVlYmu90+4pSSz+eb8uOf7c4779TmzZujNQeDwehIjDR8hVRNTY3Ky8tHXNI+URPt21h/FhNht9ujIyGRr/b29knVON5zx6LHM/36gXggxAAxtn79epmmGQ0Z53I6nWpoaJA0PKchEgTONtbw/3inBMZ7nliLnN5xu90qLi6OfkUm98a6jsipNknavHnziABTXl4uj8cjl8ultrY2lZWVTfrxJ1qvlRO3Z/K5k+H1AxdCiAGmYawRANM0ZbfbLxg6SktL1dLSooceemhaNTidzjFD07Zt21RZWTnq+MgozmRHLyJzUjo7O0d8RebybNmyRdLw6MxUHv9ckXDn8/nk9XqjczFM04zO45jOGjWT7dtMCwQCEz42Fj1OtNcPTAUhBpgiv9+v0tJSud1u+Xw+maYpr9er2tpaNTY2jvtzpmlq3bp1amlpUXNz87T/pVtWVian06k1a9ZEfylFrh46e/Ti7OMjk4Ujvwhra2vP+xyR0ZaxJnVGHi9ySskwDNXV1UVXLg4Gg/J6vdFTbIZhRO+P9G08dXV1amxslGma0cASOaURmdjs9XpHTaaeyHNMtm+xZhhGtG7TNCd1CjIWPbb69QOxQIgBpqisrEwtLS0yTVM1NTUqLS2Nrt4bWa13LIZhRI8/3yXTkxEZlSgvL9eyZcvkcDiiIyRjeeihh+RwOKKX1bpcrvPOr9iyZYsMwxh35MPlckXnrUivrCVTVVWl4uJiNTc3a926dZJeCT3Lli07b9iTpHXr1o1Y/VgaPr1RX18fvew38trPDoMTfY7J9i2WXC6Xtm3bNuE/g3PFosdWvn4gFmzhcDhsdRFAuoiM1HR0dER/6fr9fq1Zs0aNjY3nDT8AgJEYiQHiqLW1dcxRgzvvvJN/AQPAJBFigDiKnB7xer3RUy9erze6Ci4AYOI4nQTEmc/nU2Njo7Zt2yZpeI7M+vXrmUwJAJNEiAEAAEmJ00kAACApEWIAAEBSIsQAAICklGV1ATNlaGhIBw4c0Jw5c2Sz2awuBwAATEA4HFZ3d7cWLVqkjIzzj7WkbIg5cOCASkpKrC4DAABMwb59+7RkyZLzHpOyIWbOnDmShptQWFhocTXWC4VC2rp1q9auXavs7Gyry0lZ9Dk+6HN80Of4odev6OrqUklJSfT3+PmkbIiJnEIqLCwkxGj4L0h+fr4KCwvT/i/ITKLP8UGf44M+xw+9Hm0iU0GY2AsAAJISIQYAACQlQgwAAEhKhBgAAJCUCDEAACApEWIAAEBSsiTE+P1+lZeXX/A40zTV1NQkr9erpqYmBYPBmS8OAAAkhbivE+P1emUYhvx+/wWPrampUVtbm6ThQFNbWyuPxzPTJQIAgCQQ9xBTXV09oeNM0xxx2zAM+Xy+mSgJAAAkoYSdE+Pz+eRwOEbc53A4JjSCAwAAUl/Cbjsw3vyXQCAw5v19fX3q6+uL3u7q6pI0vJRzKBSKeX3JJtIDejGz6HN80Of4oM/xQ69fMZkeJGyIGc944aahoUEbNmwYdf/WrVuVn58/w1Ulj5aWFqtLSAv0OT7oc3zQ5/ih11JPT8+Ej03YEGO320eNugQCAdnt9jGPX79+ve66667o7cgumGvXrmUDSA0n25aWFlVVVbG52Ayiz/FBn+ODPsdPIvR6aCisU/0DOnF6QCdOh9TVG9KJ0wPq7g3pZN+gTvYO6FT/gE72Dehk76BO9g1o+YICffqWVTGtI3ImZSISNsQ4nU41NzePur+iomLM43Nzc5Wbmzvq/uzsbP7ynYV+xAd9jg/6HB/0OX5i1evQ4JA6T/Xr+Kl+HT/Zr+On+qL/DZwKqet0SCfO+eruDWkoPLnn6QkNxvy9MZnHszTEBIPBESMrfr9fdrtdhmHIMIwRx5qmqYqKinFHYgAASHU9/QM6dKJXh7p6dbirVwdP9OrwiV4d6R4OKcfOhJUTp6c+tyY3K0NFs7KjX4WzsjUnL0sFuVmak5ul2blZmn3m9qKiWTF8dZMX9xDj8/mi5/waGhpUWVkZvew6cru+vl6S5PF45Ha7VVlZqdbWVtaIAQCkrKGwdLirV4e6u7Wvs0d7j5/W/mDPcFA5E1i6ewcm/HgZNslRkCNHQY7mFuRq7uwczS3IUXFBjuyzslWUn63CvOxRgSUvO3MGX2VsxT3EOJ1OOZ1ONTY2jvreuSHFMIzocRNdXwYAgEQ1MDikfZ2n1X7kpDqOndLeQM+ZwNKjvcczNfC3P1/wMQpyMrWwKE8XFebpojP/XViYp3mzc+UoyNG82TmaOztXRbOylZlhi8Orsk7CzokBACBZneob0K4jJ9V+5KTaj56UefSU2o+e1J7jpxQaHG/iiU2ZGTZdXJSnkuJ8LXXka0nxLF1UlKeLi2bpoqJcLSzM05w85idFEGIAAJiicDisAyd69dyBLj1/8JWvlwI9Co+TVfKyM2TMmy1jfoGWOobDysWFOdq94+969223KD9v9EUqGBshBgCACTp0oldP7u3U9n1B7Xg5qOcOdKlrnHkq82bnasWC2SpdUCBj3myVLpit0vkFWlQ0SxnnnOYJhUIK7pSyMxN2If2ERIgBAGAMvaFB7dgX1JP7gtq+N6jt+4I61NU76risDJuWL5ityy4u1GUXzznz30LNm82IykwjxAAAoOHQ4n+pU38zj+tvZkDb9wXVPzg04pgMm7TqokJdW2LXdSV2XbG4UMsXzFZuVvJc0ZNKCDEAgLQ0MDik7fuC+vOLR8cNLQvm5KpsabGuXTocWq5aUqT8HH51Jgr+JAAAaeNIV68efvGoHtl5VI/uOjpqPstFhXm6wXDoBmOuXmXM1aVz82WzpfZlysmMEAMASFnhcFjPH+zWH549JN9zh/XcwZH78tjzs3XTivm6cflc3WDM1VIHoSWZEGIAACklHA5r+76g/vDsIf3hmUN66fjIXZGvXlKkN6ycr9evWqBrS+wpvyBcKiPEAABSwvMHu/SrJ/frdzsO6OCJV64iys3K0OtWztfNV1ykN6yaz1VDKYQQAwBIWodO9Oo32/frV0/u1wuHuqP3F+Rk6k2XLdQtZ4JLQS6/7lIRf6oAgKTSPzCkrc8d0s+f2Ke/th+Lroybk5mhN61eoHeWLdbrV85Pqo0MMTWEGABAUtgX6NFPn9grz7Z9OnayP3p/5aXFeud1S/SWqy5WUT77CqUTQgwAIGENDYX1p51H9OPHX9Kfdx2NjrosmJOrd1WWqLq8REvn5ltbJCxDiAEAJJze0KB+6d+v7/3FlHn0VPT+m1bM03tedYnWXLaAfYZAiAEAJI7jJ/v0k7+9pJ88/pKOnxo+ZTQnL0vvvn6p3vOqpbpkboHFFSKREGIAAJY70tWr7z5i6n/+/pL6BoaX/l9sn6UP3rhM6ypLNJurizAG3hUAAMsc6erVdx5p10//vjcaXq5eUqTamwzdeuVFyuKUEc6DEAMAiLtjJ/v033/crZ8+sVf9Z8JL2VK7Pu5cqZtWzGPpf0wIIQYAEDc9/QP6/qMd+u4j7TrVPyhJqrikWB9zrtCNywkvmBxCDABgxg0MDsnb9rK+3vKijnT3SZKuWlyk+ltWEV4wZYQYAMCMemz3MX3hd8/qxcMnJUkljln61M2r9darLlYGmy9iGggxAIAZcehEr754/3P636cOSpLs+dn66JtW6L03LFVuFlsCYPoIMQCAmOofGNIP/9qh/++hXerpH1SGTXrvDZfo7qpVbAuAmCLEAABipu2lTrl/8ZR2Hxk+dVR+SbH+87YrdMWiIosrQyoixAAApq2nf0BfffBF/fCxDoXD0tyCHH361tW6o2wJ814wYwgxAIBpeaz9mD79i6e1N9AjSaouX6LPveVyTh1hxhFiAABT0tM/oC/d/7z+5+97JUmLivL05duv0htWLbC4MqQLQgwAYNKeejmoj/98u8xjwztMv+dVS/XpW1drTh6jL4gfQgwAYMIGh8La+GdTX9u6UwNDYV1UmKev3XmNXrt8ntWlIQ0RYgAAE3LwxGl9YvN2/c0MSJJuvfIiNdx+lez5ORZXhnRFiAEAXNBfdh3Tv/38SQVO9Ss/J1NfeNsVqqlYwnYBsBQhBgAwrqGwdO/Dpr75x90Kh6XLLy7Ut99TpmXzCqwuDSDEAADGFuwJadMLGXouuFuStK6iRBtuu0J52WwZgMRAiAEAjPLCoS59+EetejmYodysDP3f267UnZUlVpcFjECIAQCM0PLcYX3850/qVP+g5uaG9f0PXq9rL5lrdVnAKIQYAIAkKRwOq/nPphr/8ILCYenVhkNvcxzRFYsKrS4NGFOG1QUAAKzXNzCouz07dM/vhwPMe29Yqu//Y5kKWLsOCYyRGABIcyd6Qqr9yTY90RFQZoZNX3jb5Xrfqy9VKBSyujTgvAgxAJDGDp44rff/4Am9ePik5uRl6TvvKdeNK1h9F8mBEAMAaerFw916/w+e0METvVpYmKv7Pni9Vl/E/BckD0IMAKShJzoC+vB9rerqHdDyBbN13wev12L7LKvLAiaFEAMAaeaPLxzWP/8/v/oHhlR+SbG+//4K9j9CUiLEAEAa+f3TB/VvP39SocGwnJct1H//w3WswIukRYgBgDTxqydf1t1bdmgoLL3tmkX6+p3XKDuTlTaQvAgxAJAGfv7EXq3/1dMKh6Wa8iW6546rlZnBDtRIboQYAEhxP358j/7jN89Kkt53wyXa8PYrlEGAQQogxABACvvp3/dGA0ztTcv0mTdfJpuNAIPUQIgBgBTlbXtZn/3105KkutcZWn/ragIMUgozugAgBf1m+37Ve3coHJY+8JpLCTBISYQYAEgxv3/6oO46cxXSu69fqs+/7XICDFISIQYAUsgjLx7VR3/2pAaHwqouX6IvveNKAgxSFiEGAFLE9n1BfeT/tWlgKKy3Xn2xGu+4mquQkNIIMQCQAtqPntQ//fAJ9fQP6qYV8/T1O69lHRikPEIMACS5Qyd69Y/ff0KdPSFds6RI331vuXKy+HhH6uNdDgBJ7ERPSO//wRPaHzwtY16BfvCBShXksnoG0gMhBgCSVN/AoGp/sk07D3drYWGu7vvg9Zo7O9fqsoC4sSSum6Ypr9crwzBkmqbq6upkt9vHPdbn88nhcMg0TVVXV8swjPgWDAAJJhwOa/0vntYTHQHNyc3SfR+8XiWOfKvLAuLKkhBTU1OjtrY2ScMhpba2Vh6PZ8xjvV6v6uvro7ddLpeam5vjUicAJKr//uNu/fLJ/crMsOne95Zp9UWFVpcExF3cTyeZpjnitmEY8vl84x6/efPmmS4JAJLKb3cc0NdaXpQk/d/brtRNK+ZbXBFgjbiHmMipobM5HA75/f4xj3c4HCovL4+eVqqqqopHmQCQkNpeCuiTnh2Shjd0/IdXLbW4IsA6cT+dFAwGx7w/EAiMeb/H49GaNWtUWlqqurq6cU8l9fX1qa+vL3q7q6tLkhQKhRQKhaZXdAqI9IBezCz6HB/p2ueXO0+r9sfb1D8wpKrLFuhu5/IZ7UG69tkK9PoVk+lBwlyHN1648fl8amxslGmacrlckjRmkGloaNCGDRtG3b9161bl5zPZLaKlpcXqEtICfY6PdOpz/6D0zWcyFeixaUlBWFVzDujBPxyIy3OnU5+tRq+lnp6eCR8b9xBjt9tHjboEAoExr04yTVOtra1qbGyUJDmdTpWXl8vtdo+6Qmn9+vW66667ore7urpUUlKitWvXqrCQCW+hUEgtLS2qqqpSdna21eWkLPocH+nW53A4rLu9T2t/zyHNLcjRTz9ygy4uypvx5023PluJXr8iciZlIuIeYpxO55gjKRUVFaPu8/v9qqysjN42DEPr168fc9QmNzdXubmj10fIzs5O+zfE2ehHfNDn+EiXPm/6s6nfPXVIWRk23fueMi2dNyeuz58ufU4E9FqTev1xn9h77giKaZqqqKiIjsT4/f7oFUxlZWVqbW0dcfzx48dVVlYWl1oBwGp/2XVMDb9/XpL0ubderlcZcy2uCEgclsyJ8Xg8crvdqqysVGtr64g1YhoaGlRZWan6+noZhqGqqio1NTVFQ05kXgwApLp9gR7968/8GgpL1eVL9I+vvsTqkoCEYkmIMQwjOs+lurp6xPfOXfTO6XTK6XTGrTYASASn+wdV95M2Bc9s6vjFd1wpm41dqYGzsXcSACSgz//2GT1/sEvzZufoO+8tV152ptUlAQmHEAMACeYXbS9ry7aXlWGTvvXu67TIPsvqkoCERIgBgASy63C3/v3Xz0iSPrZmpV5TOs/iioDERYgBgATR0z+gf/kfv06HBnXj8nn61zctt7okIKERYgAgQXzu189q15GTWjAnV99817XKzGAiL3A+hBgASABbtu3TL/yvzIOZN3v04p0ARiLEAIDFdh3u1n/8ZngezF1VK3UDC9oBE0KIAQAL9Q0M6t9+vl29oSHdtGKe/uUNzIMBJooQAwAW+uqDO/X8wS45CnL0tZprlME8GGDCCDEAYJG/7DqmTY92SJIa77haCwpnfmdqIJUQYgDAAp2n+nW3Z7sk6T2vWqqqyxdaWxCQhAgxABBn4XBYn/7lUzrc1SdjfoH+/S2XW10SkJQIMQAQZ1u27dODzx5WdqZN33rXdZqVw75IwFQQYgAgjvYcO6Uv/PY5SdLda1fpysVFFlcEJC9CDADEyeBQWJ/y7tDp0KBetcyh2psMq0sCkhohBgDi5Id/7VDrnk4V5GTqqzXXsK0AME2EGACIg/ajJ/WVB3dKkj7zlstU4si3uCIg+RFiAGCGDQ6FdfeWHeobGF6V9x+uX2p1SUBKIMQAwAzb+GdT2/cFNSc3S413XC2bjdNIQCwQYgBgBr14uFvfaHlRkvS5t12uRfZZFlcEpA5CDADMkIHBId29ZYf6B4f0ptULVFO+xOqSgJRCiAGAGfL9v3To6f0nVJiXpYbbr+I0EhBjhBgAmAF7jp3S1yOnkd56uRayuSMQc4QYAIixcDisz/zqafUNDOm1y+eqmtNIwIwgxABAjHnaXtZj7ceVl52hL7+T00jATCHEAEAMHenu1Zfuf16SdFfVSl0yt8DiioDURYgBgBja8LvndOJ0SFcuLtQHX7vM6nKAlEaIAYAY8T13WPc/dVCZGTbdc/vVysrkIxaYSfwNA4AY6O4N6XO/eUaSVHuToSsXF1lcEZD6CDEAEANf2/qiDp7o1SVz8/Vx5wqrywHSAiEGAKbpmf0n9OPH90iSvvzOq5SXnWltQUCaIMQAwDQMDYX12V8/o6Gw9PZrFum1y+dZXRKQNggxADANP2vdqx37gpqdm6V/f8tlVpcDpBVCDABM0bGTfWr6w05J0t1rV2oBWwsAcUWIAYApuuf3L+jE6ZAuv7hQ77vhEqvLAdIOIQYApuCJjoC8bS/LZpO+9M4rWRMGsAB/6wBgkkKDQ/rcr4fXhHlX5VJdt7TY4oqA9ESIAYBJ+uFfO7TzcLccBTmqv3mV1eUAaYsQAwCTcCB4Wt/07ZIkffrW1SouyLG4IiB9EWIAYBK+/MDz6ukfVMUlxaouW2J1OUBaI8QAwAT93Tyu/33qoDJs0obbrlBGhs3qkoC0RogBgAkYHArrC797TpL0ruuX6opFbPAIWI0QAwAT8LMn9ur5g10qzMvSJ9cymRdIBIQYALiAYE+/vrp1eGXeu6pWysFkXiAhEGIA4AK+0fKigj0hrVw4W+9lZV4gYRBiAOA8XjjUpf/3972SpC+87QpW5gUSCH8bAWAc4XBYG377nAaHwrr1yov0muXzrC4JwFkIMQAwjj88c0iPm8eVm5Whz7z5MqvLAXAOQgwAjKE3NKgv3v+8JMn1+lKVOPItrgjAuQgxADCGjX82tT94WouK8vSR15daXQ6AMRBiAOAch7t69Z2H2yVJ6998mWblZFpcEYCxEGIA4BxffXCnTocGVX5Jsd569cVWlwNgHIQYADjLswdOyOt/WZL02bdcJpuN/ZGAREWIAYAzwuGwvnT/8wqHpbdds0hlS4utLgnAeRBiAOCMP75wRI+1H1dOVobqb2Z/JCDREWIAQFJocEhfemD4kuoPvnYZl1QDSYAQAwAa3qXaPHpKjoIc/csbuaQaSAZZVjypaZryer0yDEOmaaqurk52u33c430+n0zTlGEYkiSn0xmnSgGkgxOnQ/pGy4uSpE9UrVRhXrbFFQGYCEtCTE1Njdra2iQNB5ra2lp5PJ4xj/X5fPJ4PGpubpZpmqqqqlJ7e3s8ywWQ4u7902519oS0fMFsvbuyxOpyAExQ3EOMaZojbhuGIZ/PN+7xLpcrGngMw1BLS8uM1gcgvewL9OiHf90jSfrsmy9jl2ogicT9b6vP55PD4Rhxn8PhkN/vH3WsaZoKBAKy2+3y+/0KBoPRU0oAEAv3/OEF9Q8O6cbl8/SGVfOtLgfAJMR9JCYYDI55fyAQGHWf3++Xw+GQ1+uV0+nUxo0bZRiGqqurRx3b19envr6+6O2uri5JUigUUigUik3xSSzSA3oxs+hzfMSqz0/uDer+pw7KZpPq167QwMBALMpLGbyf44dev2IyPbBkTsxYxgo3gUBApmnK6XTKbrerrq5OxcXFCofDo45taGjQhg0bRt2/detW5edzqWQEp+Pigz7Hx3T6HA5L33wmU5JNr5o/pI4nH1XHk7GrLZXwfo4fei319PRM+Ni4hxi73T5q1CVyyuhchmHIbrdHvxf5r9/vV1lZ2Yhj169fr7vuuit6u6urSyUlJVq7dq0KCwtj+hqSUSgUUktLi6qqqpSdzZUXM4U+x0cs+vzgs4e15287NCs7Q1/7wOu1YE5ujKtMfryf44devyJyJmUi4h5inE6nmpubR91fUVEx6r7JzH/Jzc1Vbu7oD6Hs7Oy0f0OcjX7EB32Oj6n2eWBwSN94aLck6cM3GVrsmB3r0lIK7+f4odea1OuP+8Tec4OJaZqqqKgYMcoSuYLJMAxVVFRETzVF1oo5dxQGACbjF/6X1X70lIrzs1X7Oi4WAJKVJXNiPB6P3G63Kisr1draOmKNmIaGBlVWVqq+vn7EseXl5Wpra+N8IYBp6Q0N6hstuyRJ/+eNy1nYDkhiloQYwzDU2NgoSaOuNDp30Tu73T7m6ScAmIr7HtujQ129WlSUp/fecInV5QCYBlZ1ApA2TpwO6d6Hh1f8/kTVSuVlZ1pcEYDpIMQASBvffaRdJ06HtHLhbN1etsTqcgBMEyEGQFo43NWrH/61Q5L0qZtXKzPDZnFFAKaLEAMgLXzTt0u9oSFVXFIs52ULrC4HQAwQYgCkvPajJ7Vl2z5JkvvW1bLZGIUBUgEhBsAIGzdulNvttrqMmPra1p0aHAprzeoFqrzUceEfAJAUEmbvJADWMU0zuuzBli1bVFdXZ3FFsbNjX1APPH1INpv0qVtWWV0OgBgixACQYRjR9Zi2bdtmcTWx1fTgC5Kkd163WKsvYh81IJVwOglJJxgMRremmCq/3x+japDIHt11VH/dfVw5mRn6hHOl1eUAiDFCDJKKaZpyu92T2hx0LIZhyOVyxagqJKKhobAa/zA8CvOeG5aqxJFvcUUAYo0Qg6Tidrtjsg2F3W6Xy+UiyKSw+58+qGf2d2l2bpb+9Y3LrS4HwAwgxCBp1NTUaP369TF7vLKyMtntdnm93pg9JhJDaHBIX9u6U5JUe5OhubNzLa4IwEwgxCApROawlJWVxfRxGxsb1dDQENPHhPV+3rpPe473aN7sHH34pmVWlwNghhBikBTcbndMR2HO5nQ6tXHjxhl5bMRfT/+AvvXQLknSR9+0QgW5XIQJpCpCDBKeaZoyTTPmozARLpcrukYKkt8P/tKho919WurI17uvX2p1OQBmECEGCa+5uVnV1dUz9viRK5247Dr5dZ7qV/Mjw5ff3712pXKy+IgDUhl/w5HwfD6fqqqqZvQ5nE6nfD7fjD5HsggGgwoGg1aXMSXf/tNudfcN6PKLC/W2qxdZXQ6AGUaISVB+v18ul0s1NTXjXgbs9XpVXFycFL9wIkGkuLhYNptt3K+xFrHz+/2qqKiY8HO53W4VFxerqqpqRG9M01RTU9OYP1NeXq6WlpZJv65UEQwG5Xa75XK5ZJqmtmzZIpfLNW6/EtH+4Gn9+PGXJEn1t6xSRgabPAKpjhlvCcg0TW3evFnNzc0KBoPRX8jnnlJpaGhQMBiU3W63ptAJcrvdampqktPpVF1dnUzTjF7WXF9fr7lz50oaXrvl3EXs/H6/7Hb7hF+jy+XSxo0bZRiGfD6f1qxZo7a2tuj3PB7PmD9XUVGRcpseTobdbo/OC4rFOjxW+GbLi+ofHNINhkOvXznf6nIAxAEhJgE1NjaO2scmEAiMOs7v98vpdE74ce+77z694x3vmHJddrtdHo9nUs9ZVVUln8+ntra2ERNzIyMzpaWl591sMBAITHh1Xr/fL9M01dnZKbvdLr/fL7fbraqqKgUCATU2No4bhgzDmNKIViSgTdVUeorRdh3u1i/8L0uS3Lesls3GKAyQDjidlGDOHVmJhJk777xzxHGR+RuTmSvy/ve/X/39/QqHw1P66uzsnNQv240bN8rn88nj8Yy6ssjpdEZ/gZ/PZPdI8ng80f6VlZWppaVFLpdL69evn1Dtk32+xsbGET3q7+/Xr3/96wn3ebI9Pd+puGT8ipWmB3dqKCzdcsVFum5pccweF0BiI8QkGLvdPmI9FK/XG11Z9myR+RuJ+i/4yByL6urqca8scjgcFwwNwWBQDodjQs85Vp8ioyQXurop8nPJML8II7W9FFDLc4eVYZM+eTObPALphNNJCSjyCzUyb2Ssib2RkZiZWjtluiLzdc63N5FpmhcMYcePH5/SnJ9gMKiGhga5XK5pbxaZSMLhsNUlJJRwOKzG3w9vL1BTXqLlC+ZYXBGAeCLEJLDxTiVJk58PE28+n092u33cGie6jcDcuXMnvX6L3++Xz+eb0gJ2qRR40sHDLx7TE3sCys3K0MerVlhdDoA443RSAvP5fDIMY9RIxFTmw0jDE3tzcnKmNYdhomupmKZ53suiI/sVXWgXabvdPuak5vFs3LhRpmmqvr5+1PfOF4Yip5EmO+rjdrtH9CcnJ0fveMc7JtVn1qeZmqGw9LWW4e0FPvCaS3Vx0SyLKwIQb4SYBBX5pTrWSEVkMuxkR2KmO7E3HA5P+DkdDse4gSAYDMrr9aqxsfGCIx+TuWqoqalJhmGMOf/F6/WeNywEAoEpnbaa7sTeyfR0LBs3bkzbS8Pbjtm08/BJFeZl6SNvKLW6HAAWmHSIcTgc+shHPqLt27fPQDmIiPxCHWtSa6LPh5GGA9Z4k3Zra2tVVlY25mjJuQzDmNAVQxs3boyurRO5rPvs77nd7vM+n9/vn/AEYquZpimXyyWXy5W2AaZvYEgP7Bv++PrnN5TKnp9jcUUArDDpENPR0aGysjJ9+MMf1ooVK7R+/Xrt2bNnBkqD0+mMrhMTUVNTM6EJsVZrbGyUaZqjRj8ip48iC9BdSOR02vmCjGmaamlpUVtbmzwejwzDiK5BU1xcfN5F7s5+jETvaYRhGGpublZzc/Ok5/Bc6PTdTNm4caOKi4vl9/sVDAanvU/Vz1r3KdBn08I5ufqn1yyLUZUAks2kQ0xRUZFqa2u1bds2bdu2TYZhqKamRpWVlfrqV7+qrq6umagzLUV+IdfU1ESXhI/Mg5npvYSmy263q6OjQ83NzdHaa2pqVFVVdcFAca4L7WvU3NysTZs2jbgdWRnYMIxRC+2NpaWlJeF7GguTmV8UK5HTgQ899JDcbre2bds2rVHE7t6Q7n14ONT+6xtLNSsnMxZlAkhCU746afv27WpublZLS4vKysrkcrkUDAZVXV2tm2++WXfffXcs60xLYy0GFzl9cL5VbhPFRBazmwiXy6XGxsZxX/NYVyFFRiomatu2bWm9d9JY/H6/Nm/erMrKSgUCAVVUVETDx8aNG9Xe3j7uz1ZVVUVHtux2u+rq6hQMBtXY2Djt06Dfe7RDnT0hLcgLq7qMTR6BdDbpEPOVr3xFzc3Nstlscrlcuueee1RUVBT9/h133KGKigpCzDSNtyeS1+uNrnabLpxOZzQkz8Tr9nq9Y17Gns6amprU2to6IoTW1NREb082REf2wCorK5Pf759ykDl2sk/fe3R4FOYtS4eUlcm1CUA6m/QnQHt7uzwej3bt2qVPfvKTIwJMhFXn3VNFZHfqcydter1emaaZlpM5Ixs7zoTIKS8M8/l8crvdI07R+f1+VVZWTunxmpqa1NzcLJ/PFx3dmar//uNuneof1FWLC3WNg4X/gHQ36ZGY7373uxc8pra2dkrFYNjmzZtlt9u1bt266H2RZfzr6+uTZgJqLNXX16u8vHxCVzRNRmQtHha5e4Xb7VZZWZl8Pt+IOTRT6b3f71d1dbUcDofWrFkjj8cz5dN2e4/36H/+/pIk6ZNVKxTc+fcpPQ6A1MGKvQmoqqpKLpcrOuQeDAa1Zs0aVVdXT2kV2lTR2Ngot9sd0x40NjbGZN5OonG5XGNe0bVt27YxJzC7XK7o+jp+v18ej+eC+01NxNmnjSZ6Rdp4vt6yU6HBsG5aMU+vKZ2rB3ZOtzoAyY4Qk4Dq6urkdrujOzJHJkSm4wjM2ZxOZ3RLgVj0IhKIUnF+0XiTms+e1zKW8y2yaKXnDnTpNzsOSJLct6y2uBoAiYIQk6DSecTlfOrr66NbC0znFJDX69W6desS7pe11c4X6GIVHqei6cEXFA5Lb736Yl25uEihUMiSOgAkFkIMkk4sLi+PxamSRBAMBie8LcNE1dXVye/3jwiJXq/XshGrv5nH9fDOo8rKsOmTa1dZUgOAxESIAZJMMBhUQ0ODgsGgTNPUli1bJEmlpaUxmfgcuVorEAjI4XAoEAjI6XRaMvk5HA7rnt+/IEl61/UlunReQdxrAJC4CDFAkrHb7dHTjZNZ0G8yEuV05oPPHtb2fUHNys7Uv61ZYXU5ABIMK0UBaWT9+vVWlzBhA4ND+sqDw6MwH7pxmRbMybO4IgCJhhADpJFkmsj8S/9+tR89peL8bNW9nnV8AIxGiAGQcHpDg/p6y4uSpP/zxuUqzMu2uCIAiYgQAyDh/OixPTrU1avF9ll67w2XWF0OgARFiAGQUE70hHTvn3ZLku6qWqm87EyLKwKQqAgxABLKvY/sVlfvgFYtnKN3XLfY6nIAJDBCDICEcSB4Wj/86x5JkvvWVcrMsFlbEICERogBkDC+6XtR/QNDun6ZQ29ctcDqcgAkOEIMgISw63C3vG0vS5I+fetq2WyMwgA4P0IMgITQ9OBODYWlm69YqLKlxVaXAyAJEGIAWG7bnoBanjusDJv0qZtXW10OgCRBiAFgqbM3eVxXWaLlC2ZbXBGAZEGIAWAp3/NHtO2lTuVlZ+hja1ZaXQ6AJEKIAWCZwaGwmv4wPArzT69dpouK2OQRwMQRYgBY5hf+l7XryEkVzcrWP7++1OpyACQZQgwAS/SGBvWNM5s8/usbl6toFps8ApgcQgwAS9z32B4dPNGrRUV5et+r2eQRwOQRYgDE3YmekO59uF2S9Ak2eQQwRYQYAHF378O7deJ0SCsXztbtZUusLgdAkrIkxJimqaamJnm9XjU1NSkYDE7o59xu94SPBZCY9gV6ops8rr/1MjZ5BDBlloSYmpoa1dfXq7q6WtXV1aqtrb3gz/j9fjU1NcWhOgAz6SsP7lT/4JBeu3yu3rBqvtXlAEhicQ8xpmmOuG0Yhnw+34R+zjCMmSoLQBxs3xfUb3cckM0mfebNl7HJI4BpyYr3E/p8PjkcjhH3ORwO+f1+lZWVjfkzXq9X1dXVcrvd4z5uX1+f+vr6ore7urokSaFQSKFQKAaVJ7dID+jFzKLP4wuHw/ri/z4rSXrHtYu0cn7+lPtEn+ODPscPvX7FZHoQ9xAz3pyWQCAw7vF2u/2Cj9vQ0KANGzaMun/r1q3Kz8+fTIkpraWlxeoS0gJ9Hu2pgE3bXspUti2sa2179cADe6f9mPQ5Puhz/NBrqaenZ8LHxj3EjGe8cLNlyxbV1dVd8OfXr1+vu+66K3q7q6tLJSUlWrt2rQoLC2NVZtIKhUJqaWlRVVWVsrNZVGym0OexhQaH9I3/ekxSjz78OkP/4Fwxvcejz3FBn+OHXr8iciZlIuIeYux2+6hRl0AgMOZoi8/n05133jmhx83NzVVubu6o+7Ozs9P+DXE2+hEf9Hmkn23boz3HezRvdo7+z5tWKjs7Nh899Dk+6HP80GtN6vXHPcQ4nU41NzePur+iomLM47ds2RL9f9M01dDQoHXr1o07fwZAYunqDembvl2SpI87V2p2bsIMAANIcnH/NDn3CiPTNFVRUREdifH7/bLb7TIMQ06nc8SxLpdLLpeLq5SAJPKdh9sVONWv0vkFeldlidXlAEghlqwT4/F45Ha75fV61dzcLI/HE/1eQ0ODvF7viOODwWB0jZjGxkb5/f641gtgavYHT+v7f+mQNHxJdVYmi4QDiB1LxnUNw1BjY6Mkqbq6esT3zg40EXa7XfX19aqvr49LfQBi46sP7lT/wJBuMBx60+oFVpcDIMXwzyIAM+Lpl0/oV0/ulyR99s2Xs7AdgJgjxACIuXA4rP/7v89JGl7Y7qolRRZXBCAVEWIAxNwDTx/SE3sCysvOUP0tq60uB0CKIsQAiKne0KC+/MDzkqR/fn2pFtlnWVwRgFRFiAEQU9971NT+4GktKsqT63WlVpcDIIURYgDEzKETvfr2n9olSe5bV2tWTqbFFQFIZYQYADHT9IcXdDo0qPJLivX2axZZXQ6AFEeIARATT+7t1C/PXFL9H2/lkmoAM48QA2DahobC2vC74Uuqq8uX6JoSu7UFAUgLhBgA0/abHfu1fV9QBTmZqr95ldXlAEgThBgA09LTP6DG3++UJP3LG5drQWGexRUBSBeEGADT8t2H23Woq1cljln60I3LrC4HQBohxACYsr3He/TdP5uSpM/cepnysrmkGkD8EGIATNl//u+z6h8Y0muXz9UtV15kdTkA0gwhBsCUPPT8YfmeP6KsDJs2vP0KLqkGEHeEGACT1hsajF5S/aGblmn5gjkWVwQgHRFiAExa8yOm9gZ6dFFhnv7tTSusLgdAmiLEAJiUfYEe3fvwbknSv7/1MhXkZllcEYB0RYgBMCkbfvec+gaG9JrSuXrLVRdbXQ6ANEaIATBhf3zhsHzPH1ZWhk3/eRuTeQFYixADYEJ6Q4P6wm/PTOa9kcm8AKxHiAEwIWdP5v3oGibzArAeIQbABZlHT+rbZybzfvYtl2k2k3kBJABCDIDzCofD+uyvnlH/wJBet3K+3no1k3kBJAZCDIDz+qV/vx43jysvO0NfvO1KJvMCSBiEGADjCpzq1xfvH57M+7E1K7V0br7FFQHAKwgxAMb1pfufV2dPSKsvmqMP37TM6nIAYARCDIAxPbb7mH7hf1k2m/Tl269SdiYfFwASC59KAEbpDQ3qs79+RpL03lddorKlxRZXBACjEWIAjHLvn3ar49gpLZiTq0/dssrqcgBgTIQYACO8eLhb33mkXZL0hbdfocK8bIsrAoCxEWIARA0MDulTnh0KDYblvGyBbr3yIqtLAoBxEWIARH3vLx3a8fIJzcnL0hffcRVrwgBIaIQYAJKk9qMn9fWWFyVJn3vr5bqoKM/iigDg/AgxADQ4FFa996no1gI15UusLgkALogQA0A/emyP2l7q1OzcLDXczmkkAMmBEAOkuZeOn9JXHnxBkrT+zau12D7L4ooAYGIIMUAaGxoKy/2Lp9QbGtJrSufqH65fanVJADBhhBggjf3osT36mxnQrOxM3XP71ZxGApBUCDFAmtp1uFv3/GH4NNJn33IZO1QDSDqEGCAN9Q8M6RNbtqt/YEhvWDVf73kVp5EAJB9CDJCGvvXQLj2zv0v2/Gw13cFpJADJiRADpJm2lzp178O7JUlffudVWlDIonYAkhMhBkgjp/oGdPeW7RoKS++8brHefNXFVpcEAFNGiAHSyJceeF57jvfo4qI8feHtV1hdDgBMCyEGSBMPPntIP/37XknS12quUdGsbIsrAoDpIcQAaeBA8LTqvU9JkmpvWqbXLJ9ncUUAMH2EGCDFDQwO6WM/f1InTod09ZIiferm1VaXBAAxQYgBUty3Htql1j3Dmzv+17uvU04Wf+0BpAY+zYAU9lj7Mf3Xn85cTn37VbpkboHFFQFA7BBigBR1/GSfPrF5u8Jh6c6KJXr7NYusLgkAYooQA6SgoaGwPuV9Soe7+lQ6v4DLqQGkJEIMkIK+80i7/vjCEeVkZei//6FM+TlZVpcEADFHiAFSzF93H9PXtu6UJP3n26/QZRcXWlwRAMwMQgyQQg6eOK2P/uxJDZ2ZB/Ou69mdGkDqIsQAKaJ/YEj/8j9+BU7164pFhfrP2660uiQAmFGEGCBFfOn+5/Tk3qAK87L0nfeUKy870+qSAGBGWTLbzzRNeb1eGYYh0zRVV1cnu90+5rF+v18+n0+S1Nraqk2bNo17LJCufvXky7rv8ZckSd9817VaOjff4ooAYOZZEmJqamrU1tYmaTjQ1NbWyuPxjHmsz+dTfX29JKmpqUlr1qyJ/iwAace+oNy/eFqS9NE3LdebVi+0uCIAiI+4n04yTXPEbcMwoiMt5/L7/WpoaIjerq6ult/vH/UYQLo63NWr2h9vU//AkJyXLdAnnCutLgkA4ibuIzE+n08Oh2PEfQ6HQ36/X2VlZSPuLysr06ZNm6K3g8Fg9Phz9fX1qa+vL3q7q6tLkhQKhRQKhWJVftKK9IBezKx49rk3NKja+1p1pLtPKxYUqOn2KzU4OKDBwRl/asvxfo4P+hw/9PoVk+lB3ENMJIicKxAIjHl/dXV19P83b94sp9M55pyYhoYGbdiwYdT9W7duVX4+8wMiWlparC4hLcx0n8Nh6Se7M/TUsQzlZ4X1rsUn9Ogft87ocyYi3s/xQZ/jh15LPT09Ez42YZbxHC/cnP19r9c77nyY9evX66677ore7urqUklJidauXavCQhb7CoVCamlpUVVVlbKzs60uJ2XFq8/Nf+5Q27Fdysqwqfl9FbrBGD06mcp4P8cHfY4fev2KyJmUiYh7iLHb7aNGXQKBwAWvOHK73WppaRn3uNzcXOXm5o66Pzs7O+3fEGejH/Exk31+4OmD+ppvlyTp82+/QjetSt+JvLyf44M+xw+91qRef9wn9jqdzjHvr6ioGPdnmpqa5Ha7ZRiGgsHgBUdtgFTV9lJAHz+zM/U/vvoSve+GS6wuCQAsE/cQYxjGiNumaaqioiI6wnLu1Uder1dlZWXRALNlyxbWiUFa6jh2Sh++75UrkT7/NnamBpDeLJkT4/F45Ha7VVlZqdbW1hFrxDQ0NKiyslL19fUyTVM1NTUjftZut6uuri7eJQOWOn6yTx/44RPq7Anp6iVF+ta7r1Nmhs3qsgDAUpaEGMMw1NjYKGnk1UeSRgQawzAUDofjWhuQaE73D+pD923TS8d7tKR4lr7//krl5yTMnHwAsAx7JwEJLDQ4pI/+zK/t+4IqmpWtH/3T9Zo/Z/QEdgBIR4QYIEENDYVV731KvuePKDcrQ5v+sULLF8y2uiwASBiEGCABhcNhfeF3z+pXT+5XVoZN976nTNcvS6+1YADgQggxQAL6esuL+vHjL8lmk7525zVac1n6rgUDAOMhxAAJ5nuPmvqvP+6WJP3nbVfqtmsXW1wRACQmQgyQQH78+B598f7nJUmfunkVi9kBwHkQYoAE8ePH9+g/fvOsJOmfX1+qf3lDqcUVAUBiI8QACeAnZwUY1+sMuW9ZJZuNxewA4HwIMYDFfvL4Hn3urADz6VtXE2AAYAIIMYCF7nvslQBTR4ABgElh7XLAAuFwWN/+0259deuLkqTam5ZpPQEGACaFEAPEWTgc1pcfeF6bHu2QJP3bmhX6hHMFAQYAJokQA8TR4FBYn/nl09q8bZ8k6XNvvVwfunGZxVUBQHIixABx0jcwqLs279D9Tx9Uhk26546rdWdFidVlAUDSIsQAcRDs6Vfdj9v0xJ6AsjNt+q93X6dbrrzY6rIAIKkRYoAZtvd4jz7woydkHj2lOblZ+u77yvXa5fOsLgsAkh4hBphBT+7t1Ifv26bjp/q12D5LP/ynSq1cOMfqsgAgJRBigBny+6cP6hNbtqs3NKQrFxfqB++v1ILCPKvLAoCUQYgBYmwoLH3Dt1v3PmJKkt60eoH+693XqSCXv24AEEt8qgIx1N07oO/vzNAzncMB5sM3LtOnb12trEwWxwaAWCPEADHSfvSkau/bJrMzQzlZGbrn9qt0e9kSq8sCgJRFiAFi4IGnD8rtfUrdfQOy54T1gw9WquxSrkACgJlEiAGmoTc0qC8/8Lx+/PhLkqSKS+y6bd4xXbW4yOLKACD1caIemKI9x07pju88Fg0wH3lDqX78TxUqzLG4MABIE4zEAJMUDof12x0H9NlfPaOTfQMqzs/W19ddqzeuWqBQKGR1eQCQNggxwCR0nurXv//mGd3/1EFJUuWlxfrWu6/TxUWzLK4MANIPIQaYoId3HlG99ykd6e5TZoZNH33Tcv3rG5dz+TQAWIQQA1xAd29I9/z+Bf3P3/dKkkrnF+gb667V1Uvs1hYGAGmOEAOcR8tzh/W5Xz+jQ129kqQPvOZSffrW1crLzrS4MgAAIQYYw5GuXn3+t8/q988ckiQtdeSr4far2H0aABIIIQY4y+BQWD9v3at7fv+CunsHlJlhU+1Nhj62ZoVm5TD6AgCJhBADnNG6J6ANv3tWz+zvkiRds6RIDbdfrcsXFVpcGQBgLIQYpL0DwdNq+P0L+t2OA5KkOXlZ+oRzpd7/mkuVmWGzuDoAwHgIMUhbp/oGtOlRU999pF29oSHZbNK7Kkt099pVmjc71+ryAAAXQIhB2ukbGNRP/75X3/7Tbh072S9peNG6z7/tCl3JnkcAkDQIMUgbg0Nh/erJ/fpGy4vaHzwtSbpkbr4+uXaV3nr1xbLZOHUEAMmEEIOUNzA4pN89dUDf/lO7dh85KUlaMCdXH3Ou0J0VJcpmxV0ASEqEGKSsvoFB/aJtv777SLv2BnokSUWzsvWRN5Tq/a++lEumASDJEWKQcrp7Q9rcuk/fe7QjutKuoyBHH7pxmd736ktUmJdtcYUAgFggxCBl7Dl2Sj96bI882/bpVP+gJGlhYa7qXleqd19fovwc3u4AkEr4VEdSC4fDeqz9uH741w499MIRhcPD9y9fMFsfunGZbi9brNwsThsBQCoixCApHenu1S/a9mvLtn3qOHYqev8bV83XB29cphuXz+NqIwBIcYQYJI3BobD+/OJR/bx1rx56/ogGhoaHXQpyMnVH+RK9/zWXqnT+bIurBADECyEGCS0cDmvHyyf0m+37df9TB3Wkuy/6vbKldr2rcqnecvXFKsjlrQwA6YZPfiSkXYe79dsdB/TbHQf00vGe6P3F+dm6vWyJ1lWWaOXCORZWCACwGiEGCWFoKKyn9p/Q1mcPqeW5w9p1ZlE6SZqVnamqyxfqtmsX6aYV85WTxeJ0AABCDCzUNzCox9uPa+tzh+V77vCIU0VZGTa9fuV8vf3aRaq6fCGXRwMARuE3A+ImHA6r/ehJ/fnFY3p011H9zQzodGgw+v2CnEy9YdUCVV2+UG9ctUBF+SxKBwAYHyEGM+rQiV79veO4/rLrmB7ddSy6gm7EwsJcOS9bqKrLF+rVpXNZ0wUAMGGEGMRMOByWeeyUWjsCemJPQK17AtoXOD3imJysDL1qmUM3rZinm1bM1+qL5rCeCwBgSggxmLJgT7+eevmEnt5/Qjv2BdX2UqeOn+ofcUyGTbrs4kK9dvk83bRiniovdSgvm9EWAMD0EWIwIcGefj1/sFvP7D+hHS8H9fT+EyMufY7IycrQtSV2XX+pQ5XLHCpbatccNlwEAMwAQgxG6A0NaveRk9p5qFs7D3frhUPd2nmoS4e7+sY8/pK5+bp6iV1XLy7SdUvtumpJEfNaAABxQYhJQ+FwWIe7+mQeO6k9x3rUceykOo71nLl9SmdW8x9lsX2WrlxcOBxalhTpqsVFsufnxLd4AADOIMSkqFN9A9ofPK39naf1cvC09h0/qSd2Zug7HY/rpeM9Iy5tPpc9P1urFs7R6ovmaNVFhVp10RytXDib00IAgIRCiElCp/oGdKS7T0e6enWku0+Hu3qjgWV/cPgr2BMa4yczJHVLkjIzbCopnqVl8wp06bwCGWf+u2rhHM2fk8sVQwCAhEeISQBDQ2F19w6os6dfgZ5+BXv6FTgV0rGTfTrS1acj3cNh5eiZ4HKqf/xRlLPNycvSYvssLSmepYsLc9V9aI/efFOFli8sVIkjX9mZLN8PAEheloQY0zTl9XplGIZM01RdXZ3sdvu0j7XS0FBYJ/sH1N07oO7e0Dn/Hf7q6g2p81S/Onv61XkqFA0snT0hDY43EWUc+TmZWjAnVwvm5Gl+Ya6W2GdpcfEsLbbP0qIz/1941umfUCikBx7o0BtXzVd2NqeFAADJz5IQU1NTo7a2NknDIaW2tlYej2fax8bDswdO6KsP7jwrnAwHlZP9AwpPLoeMUpCTqeKCHBXn56i4IEdzC3K0YE6u5s/J1YLCvDOhZfj/Z+cyiAYASG9x/01omuaI24ZhyOfzTfvYeOnpH9Sfdh4d9/s5mRmak5d15itbs3Nf+f/CWVly5OfIXpAjR36OiguyVZyfI0dBjuz52VyaDADAJMQ9xPh8PjkcjhH3ORwO+f1+lZWVTfnYeDHmFajpjqujweTswDInL4vVaAEAiJO4h5hgMDjm/YFAYFrH9vX1qa/vlQXZurq6JA3PBQmFxrpSZ2oKczP0zmsvGue7QwqFhmL2XLEU6UEse4HR6HN80Of4oM/xQ69fMZkeJMzEivECy0SPbWho0IYNG0bdv3XrVuXn50+jstTS0tJidQlpgT7HB32OD/ocP/Ra6ukZvaXNeOIeYux2+6iRlEAgMOYVR5M5dv369brrrruit7u6ulRSUqK1a9eqsLAwJrUns1AopJaWFlVVVXF10gyiz/FBn+ODPscPvX5F5EzKRMQ9xDidTjU3N4+6v6KiYlrH5ubmKjc3d9T92dnZaf+GOBv9iA/6HB/0OT7oc/zQa03q9cd9tTPDMEbcNk1TFRUV0dEVv98fvSrpQscCAID0ZcmcGI/HI7fbrcrKSrW2to5Y96WhoUGVlZWqr6+/4LEAACB9WRJiDMNQY2OjJKm6unrE984NKec7FgAApC82zwEAAEmJEAMAAJISIQYAACQlQgwAAEhKhBgAAJCUCDEAACApEWIAAEBSSpgNIGMtHA5LmtweDKksFAqpp6dHXV1dab+k9Uyiz/FBn+ODPscPvX5F5Pd25Pf4+aRsiOnu7pYklZSUWFwJAACYrO7ubhUVFZ33GFt4IlEnCQ0NDenAgQOaM2eObDab1eVYLrKr9759+9jVewbR5/igz/FBn+OHXr8iHA6ru7tbixYtUkbG+We9pOxITEZGhpYsWWJ1GQmnsLAw7f+CxAN9jg/6HB/0OX7o9bALjcBEMLEXAAAkJUIMAABISoSYNJGbm6vPf/7zys3NtbqUlEaf44M+xwd9jh96PTUpO7EXAACkNkZiAABAUiLEAACApESIAQAASSll14nBxLjdbq1fv152u93qUlKO3++Xz+eTJLW2tmrTpk30OQZM05TX65VhGDJNU3V1dfR1BvD+jT8+jyePib1pzO/3q7y8XJ2dnfylmQFNTU2qr6+P/v/mzZvV1tZmcVXJr7y8PNpH0zTldrvl8Xgsrir18P6NLz6Pp4bTSWnMNE0ZhmF1GSnJ7/eroaEheru6ulp+v1+maVpYVfI7t3+GYURHCxA7vH/jj8/jqSHEpCmv16vq6mqry0hZZWVl2rRpU/R2MBiUJDkcDosqSg0+n29UDx0Oh/x+v0UVpSbev/HF5/HUEWLSUDAYZLgyDs7+UNq8ebOcTid9n6bIL9NzBQKB+BaSBnj/xgefx9NDiElDW7ZskdPptLqMtBEMBuX1epm3MYPGCzeYPt6/M4vP4+nh6qQUsXHjRrW3t4/7/aqqKjmdTvl8Pt15551xrCy1TLTPZ3O73WppaeFfWzFgt9tHjboEAgF6O4N4/84cPo+nj6uT0ozP5xsxOc/lcqm+vl7r1q1TWVmZhZWlpqamJlVXV8swjOhoAb8Mps40TdXU1Iy4Sqa4uFgdHR30dQbw/p1ZfB5PHyEmzdlsNrW3tzMrfgZ4vV7Z7XY5nU4Fg0Ft2bJFdXV1VpeV9M69xNrlcqmlpcXiqlIP79/44/N48ggxaSoYDGrjxo1yu92qq6uTy+Ui+ceQaZoqLS0dcZ/dbldnZ6dFFaUO0zTV3NysyspKtba2sjjYDOD9G198Hk8dIQYAACQlrk4CAABJiRADAACSEiEGAAAkJUIMAABISoQYAACQlAgxAAAgKRFiAABAUiLEAACApESIAQAASYkQAwAAkhIhBkDS8Hq9Ki0tjX7ZbDY1NTVZXRYAi7B3EoCktHHjRjU2Nqq9vd3qUgBYhBADIOkEg0EtW7ZMDz30ELv9AmmMEAMg6VRVVckwDDU3N1tdCgALEWIAJBWv16va2lp1dnZaXQoAizGxF0DSCAaDqq2tlcfjsboUAAmAEAMgabjdbgWDQblcrugVSlydBKQvTicBAICkxEgMAABISoQYAACQlAgxAAAgKRFiAABAUiLEAACApESIAQAASYkQAwAAkhIhBgAAJCVCDAAASEqEGAAAkJQIMQAAICn9/w899iwfNMlGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = sigmoid(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"Sigmoid Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\frac{1}{1 + e^{-z}}$\"\n",
    "ax.text(-4.5, 0.5, formula, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanh Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(x)\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = tanh(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"Tanh Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}$\"\n",
    "ax.text(-4.5, 0.5, formula, fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = relu(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"Relu Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\max(0,z)$\"\n",
    "ax.text(-4.5, 2.2, formula, fontsize=22)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeakyReLU Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def leaky_relu(z, alpha=0.1):\n",
    "    return np.where(z > 0, z, alpha * z)\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = leaky_relu(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"LeakyReLU Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\begin{cases} x, & \\text{if } x > 0 \\\\ \\alpha x, & \\text{if } x \\leq 0 \\end{cases}$\"\n",
    "ax.text(-4.5, 1, formula, fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELU Activation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "\n",
    "def elu(z, alpha=1.0):\n",
    "    return np.where(z > 0, z, alpha * (np.exp(z) - 1))\n",
    "\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "y = elu(z)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(z, y)\n",
    "ax.set_title(\"ELU Activation Function\")\n",
    "ax.set_xlabel(\"z\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.grid()\n",
    "\n",
    "# Add LaTeX formula to the plot\n",
    "formula = r\"$y = \\sigma (z) = \\begin{cases} z, & \\text{if } z > 0 \\\\ \\alpha(e^z-1), & \\text{if } z \\leq 0 \\end{cases}$\"\n",
    "ax.text(-4.5, 2, formula, fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math\n",
    "\n",
    "# display(Math(r\"\"))\n",
    "display(Math(r\"\\mathcal{L}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\"))\n",
    "display(Math(r\"m \\leftarrow \\beta_1 \\cdot m + (1-\\beta_1) \\cdot \\frac{\\partial \\mathcal{L}}{\\partial w^2_{1,1}}\"))\n",
    "display(Math(r\"v \\leftarrow \\beta_2 \\cdot v + (1-\\beta_2) \\cdot (\\frac{\\partial \\mathcal{L}}{\\partial w^2_{1,1}})^2\"))\n",
    "display(Math(r\"w^2_{1,1} \\leftarrow w^2_{1,1} - \\eta \\cdot \\frac{m}{\\sqrt{v}}\"))\n",
    "display(Math(r\"w^2_{1,1} \\leftarrow w^2_{1,1} - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial w^2_{1,1}}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constellation = [-1.  1.]\n",
      "alpha = 1.0\n",
      "constellation = [-0.70710678  0.70710678]\n"
     ]
    }
   ],
   "source": [
    "M = 4                  ####modulation order, 4 for 4qam, 16 for 16qam\n",
    "\n",
    "constellation = np.linspace(int(-np.sqrt(M) + 1), int(np.sqrt(M) - 1), int(np.sqrt(M)))\n",
    "print('constellation =', constellation)\n",
    "alpha = np.sqrt((constellation ** 2).mean())\n",
    "print('alpha =', alpha)\n",
    "constellation /= (alpha * np.sqrt(2))\n",
    "print('constellation =', constellation)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[39mreturn\u001b[39;00m(a, b)\n\u001b[1;32m     50\u001b[0m \u001b[39m# Deep Image Prior\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m dip \u001b[39m=\u001b[39m DeepImagePrior(user_num\u001b[39m=\u001b[39;49mNUM_RX_ANT,      \u001b[39m# Number of transmitted symbol in real domain\u001b[39;49;00m\n\u001b[1;32m     52\u001b[0m                     M\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,              \u001b[39m# Modulation order, 4 for 4qam, 16 for 16qam\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m                     iteration\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,    \u001b[39m# Number of max iterations used for DIP: 100\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m                     LR\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,          \u001b[39m# Learning rate,  typically set to 0.01\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m                     buffer_size\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,   \u001b[39m# Iterations stored,  typically set to 30\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m                     threshold\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m,  \u001b[39m# Threshold of DIP stop,, typically set to 0.001\u001b[39;49;00m\n\u001b[1;32m     57\u001b[0m                     stop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)        \u001b[39m# True\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# print(dip.QAM_const())\u001b[39;00m\n\u001b[1;32m     60\u001b[0m dip\u001b[39m.\u001b[39mQAM_const()\n",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36mDeepImagePrior.__init__\u001b[0;34m(self, user_num, M, iteration, LR, buffer_size, threshold, stop)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold \u001b[39m=\u001b[39m threshold        \u001b[39m###Threshold of DIP stop,, typically set to 0.001\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop \u001b[39m=\u001b[39m stop                  \u001b[39m###True\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m constellation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39mint\u001b[39m(\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msqrt(M) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39msqrt(M) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39msqrt(M)))\n\u001b[1;32m     16\u001b[0m alpha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt((constellation \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean())\n\u001b[1;32m     18\u001b[0m constellation \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m (alpha \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "class DeepImagePrior(object):\n",
    "\n",
    "    def __init__(self,user_num,M, iteration,LR,buffer_size,threshold,stop):\n",
    "        \n",
    "        self.user_num = user_num    ####number of transmitted symbol in real domain\n",
    "        self.M = M                  ####modulation order, 4 for 4qam, 16 for 16qam\n",
    "        self.iteration = iteration  ####number of max iterations used for DIP\n",
    "        self.LR = LR                ####Learning rate,  typically set to 0.01; \n",
    "                                    ####Control step size of updating the model parameters at each iteration\n",
    "        self.buffer_size = buffer_size    ###iterations stored,  typically set to 30\n",
    "        self.threshold = threshold        ###Threshold of DIP stop,, typically set to 0.001\n",
    "        self.stop = stop                  ###True\n",
    "        \n",
    "        constellation = np.linspace(int(-np.sqrt(M) + 1), int(np.sqrt(M) - 1), int(np.sqrt(M)))\n",
    "\n",
    "        alpha = np.sqrt((constellation ** 2).mean())\n",
    "\n",
    "        constellation /= (alpha * np.sqrt(2))\n",
    "        print('constellation =', constellation)\n",
    "        self.constellation = constellation\n",
    "\n",
    "        constellation_expanded = np.expand_dims(self.constellation, axis=1)\n",
    "\n",
    "        constellation_expanded= np.repeat(constellation_expanded[None,...],1,axis=0)\n",
    "\n",
    "        constellation_expanded_transpose = np.repeat(constellation_expanded.transpose(0,2,1), self.user_num, axis=1)\n",
    "\n",
    "        self.constellation_expanded =torch.from_numpy(constellation_expanded)\n",
    "\n",
    "        self.constellation_expanded_transpose = torch.from_numpy(constellation_expanded_transpose)\n",
    "\n",
    "    def QAM_const(self):\n",
    "        mod_n = self.M\n",
    "        sqrt_mod_n = np.int(np.sqrt(mod_n))\n",
    "        real_qam_consts = np.empty((mod_n), dtype=np.int64)\n",
    "        # print('real_qam_consts =', real_qam_consts)\n",
    "        imag_qam_consts = np.empty((mod_n), dtype=np.int64)\n",
    "        # print('imag_qam_consts =', imag_qam_consts)\n",
    "        for i in range(sqrt_mod_n):\n",
    "            for j in range(sqrt_mod_n):\n",
    "                    index = sqrt_mod_n*i + j\n",
    "                    real_qam_consts[index] = i\n",
    "                    imag_qam_consts[index] = j\n",
    "        print('real_qam_consts =', real_qam_consts)\n",
    "        print('imag_qam_consts =', imag_qam_consts)\n",
    "        a = self.constellation[real_qam_consts]\n",
    "        b = self.constellation[imag_qam_consts]\n",
    "        return(a, b)\n",
    "\n",
    "# Deep Image Prior\n",
    "dip = DeepImagePrior(user_num=NUM_RX_ANT,      # Number of transmitted symbol in real domain\n",
    "                    M=16,              # Modulation order, 4 for 4qam, 16 for 16qam\n",
    "                    iteration=100,    # Number of max iterations used for DIP: 100\n",
    "                    LR=0.01,          # Learning rate,  typically set to 0.01\n",
    "                    buffer_size=30,   # Iterations stored,  typically set to 30\n",
    "                    threshold=0.001,  # Threshold of DIP stop,, typically set to 0.001\n",
    "                    stop=True)        # True\n",
    "\n",
    "# print(dip.QAM_const())\n",
    "dip.QAM_const()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tf.Tensor(\n",
      "[[1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j\n",
      "  1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j]\n",
      " [1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j\n",
      "  1.+1.j 1.-1.j 1.+1.j 1.-1.j 1.+1.j 1.-1.j]], shape=(2, 16), dtype=complex128)\n",
      "y_reshape_1col_real = tf.Tensor(\n",
      "[[ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1. -1.]], shape=(32, 2), dtype=float64)\n",
      "X = tf.Tensor(\n",
      "[[1.+1.j]\n",
      " [2.+2.j]\n",
      " [3.+3.j]], shape=(3, 1), dtype=complex128)\n",
      "H = tf.Tensor(\n",
      "[[ 1. +2.j  3. +4.j  5. +6.j]\n",
      " [ 7. +8.j  9.+10.j 11.+12.j]\n",
      " [13.+14.j 15.+16.j 17.+18.j]], shape=(3, 3), dtype=complex128)\n",
      "Y = tf.Tensor(\n",
      "[[-6. +50.j]\n",
      " [-6.+122.j]\n",
      " [-6.+194.j]], shape=(3, 1), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "\n",
    "NUM_TX_ANT = 4\n",
    "y = tf.constant([[1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j],[1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j,1+1j,1-1j]]);\n",
    "print('y =',y)\n",
    "# y_reshape_1row = tf.reshape(y,shape=[1,-1])\n",
    "# print('x_reshape_1row =',x_reshape_1row)\n",
    "# y_reshape_2col4row = tf.reshape(y,shape=[-1,NUM_TX_ANT])\n",
    "# print('y_reshape_2col4row =',y_reshape_2col4row)\n",
    "# y_reshape_1col = tf.transpose(y)\n",
    "# print('y_reshape_1col =',y_reshape_1col)\n",
    "shape_y = tf.shape(y)\n",
    "# print('shape_y =',shape_y)\n",
    "y_reshape_1col = tf.reshape(y,shape=[-1,1])\n",
    "# print('y_reshape_1col =',y_reshape_1col)\n",
    "\n",
    "# y_channel = tf.expand_dims(y_reshape_2col4row, axis=-1)\n",
    "# print('y_channel =',y_channel)\n",
    "\n",
    "# hdd = [];\n",
    "\n",
    "y_reshape_1col_real_part = tf.math.real(y_reshape_1col);\n",
    "# print('y_reshape_1col_real_part =',y_reshape_1col_real_part)\n",
    "y_reshape_1col_imag_part = tf.math.imag(y_reshape_1col);\n",
    "# print('y_reshape_1col_imag_part =',y_reshape_1col_imag_part)\n",
    "y_reshape_1col_real = tf.concat([y_reshape_1col_real_part, y_reshape_1col_imag_part], axis=1) #(batch,168)\n",
    "print('y_reshape_1col_real =',y_reshape_1col_real)\n",
    "\n",
    "# y_reshape_2col4row_real_part = tf.math.real(y_reshape_2col4row);\n",
    "# print('y_real_part =',y_reshape_2col4row_real_part)\n",
    "# y_reshape_2col4row_imag_part = tf.math.imag(y_reshape_2col4row);\n",
    "# print('y_imag_part =',y_reshape_2col4row_imag_part)\n",
    "\n",
    "# y_reshape_2col4row_real = tf.concat([y_reshape_2col4row_real_part, y_reshape_2col4row_imag_part], axis=1) # (batch,158), axis=1(Second Diomension)\n",
    "# print('y_reshape_real =',y_reshape_2col4row_real)\n",
    "\n",
    "# y_reshape_1col_real_part = tf.math.real(y_reshape_1col);\n",
    "# print('y_reshape_1col_real_part =',y_reshape_1col_real_part)\n",
    "# y_reshape_1col_imag_part = tf.math.imag(y_reshape_1col);\n",
    "# print('y_reshape_1col_imag_part =',y_reshape_1col_imag_part)\n",
    "\n",
    "# y_reshape_real = tf.concat([y_reshape_1col_real_part, y_reshape_1col_imag_part], axis=1) # (batch,158), axis=1(Second Diomension)\n",
    "# print('y_reshape_real =',y_reshape_real)\n",
    "\n",
    "\n",
    "# y_real_part = np.real(y);\n",
    "# y_imag_part = np.imag(y);\n",
    "# y_real = np.concatenate([y_real_part, y_imag_part], axis=1) #(batch,168)\n",
    "# Hr = np.real(hdd);\n",
    "# Hi = np. imag(hdd);\n",
    "# hdd_real = np.concatenate([np.concatenate([Hr, -Hi], axis=2), np.concatenate([Hi, Hr], axis=2)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[1.+2.j]\n",
      " [3.+4.j]\n",
      " [5.+6.j]], shape=(3, 1), dtype=complex128)\n",
      "H = tf.Tensor(\n",
      "[[ 1. +2.j  3. +4.j  5. +6.j]\n",
      " [ 7. +8.j  9.+10.j 11.+12.j]\n",
      " [13.+14.j 15.+16.j 17.+18.j]], shape=(3, 3), dtype=complex128)\n",
      "Y = tf.Tensor(\n",
      "[[-21. +88.j]\n",
      " [-39.+214.j]\n",
      " [-57.+340.j]], shape=(3, 1), dtype=complex128)\n",
      "sum_complex = tf.Tensor(\n",
      "[[-21. +88.j]\n",
      " [-39.+214.j]\n",
      " [-57.+340.j]], shape=(3, 1), dtype=complex128)\n",
      "Y = sum_complex!!!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "NUM_RX_ANT = 3\n",
    "NUM_TX_ANT = 3\n",
    "X = tf.constant([[1+2j],[3+4j],[5+6j]])\n",
    "print('X =',X)\n",
    "H = tf.constant([[1+2j,3+4j,5+6j],[7+8j,9+10j,11+12j],[13+14j,15+16j,17+18j]])\n",
    "print('H =',H)\n",
    "H_shape = tf.shape(H)\n",
    "# print('H_shape =',H_shape)\n",
    "Y = tf.matmul(H, X)\n",
    "print('Y =',Y)\n",
    "\n",
    "X_real_part = tf.math.real(X);\n",
    "# print('X_real_part =',X_real_part)\n",
    "X_imag_part = tf.math.imag(X);\n",
    "# print('X_imag_part =',X_imag_part)\n",
    "X_real = tf.concat([X_real_part, X_imag_part], axis=1)\n",
    "# print('X_real =',X_real)\n",
    "e = tf.reshape(X_real,[BATCH_SIZE,NUM_TX_ANT,2,1]) # [BATCH_SIZE,NUM_TX_ANT,2,1] = [1,-1,2,1]\n",
    "# print('e =',e)\n",
    "repeat_times = NUM_RX_ANT\n",
    "f = tf.repeat(e, repeat_times, axis=0)\n",
    "# print('f =',f)\n",
    "\n",
    "Y_real_part = tf.math.real(Y);\n",
    "# print('Y_real_part =',Y_real_part)\n",
    "Y_imag_part = tf.math.imag(Y);\n",
    "# print('Y_imag_part =',Y_imag_part)\n",
    "Y_real = tf.concat([Y_real_part, Y_imag_part], axis=1)\n",
    "# print('Y_real =',Y_real)\n",
    "\n",
    "H_Reshaped = tf.reshape(H,[-1,1])\n",
    "# print('H_Reshaped =',H_Reshaped)\n",
    "H_Reshaped_real_part = tf.math.real(H_Reshaped);\n",
    "# print('H_Reshaped_real_part =',H_Reshaped_real_part)\n",
    "H_Reshaped_imag_part = tf.math.imag(H_Reshaped);\n",
    "# print('H_Reshaped_imag_part =',H_Reshaped_imag_part);\n",
    "\n",
    "H_real_part_Reshaped = tf.reshape(H_Reshaped_real_part,[1,-1,1])\n",
    "# print('H_real_part_Reshaped =',H_real_part_Reshaped)\n",
    "H_imag_part_Reshaped = tf.reshape(H_Reshaped_imag_part,[1,-1,1])\n",
    "# print('H_imag_part_Reshaped =',H_imag_part_Reshaped)\n",
    "\n",
    "b = tf.concat([H_real_part_Reshaped, -H_imag_part_Reshaped], axis=2)\n",
    "# print('b =',b)\n",
    "c = tf.concat([H_imag_part_Reshaped, H_real_part_Reshaped], axis=2)\n",
    "# print('c =',c)\n",
    "b_trans = tf.transpose(b, (1, 0, 2))\n",
    "# print('b_trans =',b_trans)\n",
    "c_trans = tf.transpose(c, (1, 0, 2))\n",
    "# print('c_trans =',c_trans)\n",
    "d = tf.concat([b_trans, c_trans], axis=1)\n",
    "# print('d =',d)\n",
    "g = tf.reshape(d,[3,3,2,2]) # [NUM_RX_ANT,NUM_TX_ANT,2,2] = [3,3,2,2]\n",
    "# print('g =',g)\n",
    "# H_Reshaped_real = tf.concat([tf.concat([H_real_part_Reshaped, -H_imag_part_Reshaped], axis=2), tf.concat([H_imag_part_Reshaped, H_real_part_Reshaped], axis=2)],axis=1)\n",
    "result = tf.matmul(g, f)\n",
    "# print('result =',result)\n",
    "sum = tf.reduce_sum(result, axis=1)\n",
    "# print('sum =',sum)\n",
    "sum_real,sum_imag = tf.split(sum, num_or_size_splits=2, axis=1)\n",
    "# print('sum_real =',sum_real)\n",
    "# print('sum_imag =',sum_imag)\n",
    "sum_complex = tf.squeeze(tf.complex(sum_real,sum_imag),axis=-1)\n",
    "print('sum_complex =',sum_complex)\n",
    "if all(Y == sum_complex):\n",
    "    print('Y = sum_complex!!!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[[1.+2.j]\n",
      "  [3.+4.j]\n",
      "  [5.+6.j]]\n",
      "\n",
      " [[1.+2.j]\n",
      "  [3.+4.j]\n",
      "  [5.+6.j]]], shape=(2, 3, 1), dtype=complex128)\n",
      "H = tf.Tensor(\n",
      "[[[ 1. +2.j  3. +4.j  5. +6.j]\n",
      "  [ 7. +8.j  9.+10.j 11.+12.j]\n",
      "  [13.+14.j 15.+16.j 17.+18.j]]\n",
      "\n",
      " [[ 1. +2.j  3. +4.j  5. +6.j]\n",
      "  [ 7. +8.j  9.+10.j 11.+12.j]\n",
      "  [13.+14.j 15.+16.j 17.+18.j]]], shape=(2, 3, 3), dtype=complex128)\n",
      "Y = tf.Tensor(\n",
      "[[[-21. +88.j]\n",
      "  [-39.+214.j]\n",
      "  [-57.+340.j]]\n",
      "\n",
      " [[-21. +88.j]\n",
      "  [-39.+214.j]\n",
      "  [-57.+340.j]]], shape=(2, 3, 1), dtype=complex128)\n",
      "Y_real = tf.Tensor(\n",
      "[[[[-21.]\n",
      "   [ 88.]]\n",
      "\n",
      "  [[-39.]\n",
      "   [214.]]\n",
      "\n",
      "  [[-57.]\n",
      "   [340.]]]\n",
      "\n",
      "\n",
      " [[[-21.]\n",
      "   [ 88.]]\n",
      "\n",
      "  [[-39.]\n",
      "   [214.]]\n",
      "\n",
      "  [[-57.]\n",
      "   [340.]]]], shape=(2, 3, 2, 1), dtype=float64)\n",
      "H_real = tf.Tensor(\n",
      "[[[[[  1.  -2.]\n",
      "    [  2.   1.]]\n",
      "\n",
      "   [[  3.  -4.]\n",
      "    [  4.   3.]]\n",
      "\n",
      "   [[  5.  -6.]\n",
      "    [  6.   5.]]]\n",
      "\n",
      "\n",
      "  [[[  7.  -8.]\n",
      "    [  8.   7.]]\n",
      "\n",
      "   [[  9. -10.]\n",
      "    [ 10.   9.]]\n",
      "\n",
      "   [[ 11. -12.]\n",
      "    [ 12.  11.]]]\n",
      "\n",
      "\n",
      "  [[[ 13. -14.]\n",
      "    [ 14.  13.]]\n",
      "\n",
      "   [[ 15. -16.]\n",
      "    [ 16.  15.]]\n",
      "\n",
      "   [[ 17. -18.]\n",
      "    [ 18.  17.]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[  1.  -2.]\n",
      "    [  2.   1.]]\n",
      "\n",
      "   [[  3.  -4.]\n",
      "    [  4.   3.]]\n",
      "\n",
      "   [[  5.  -6.]\n",
      "    [  6.   5.]]]\n",
      "\n",
      "\n",
      "  [[[  7.  -8.]\n",
      "    [  8.   7.]]\n",
      "\n",
      "   [[  9. -10.]\n",
      "    [ 10.   9.]]\n",
      "\n",
      "   [[ 11. -12.]\n",
      "    [ 12.  11.]]]\n",
      "\n",
      "\n",
      "  [[[ 13. -14.]\n",
      "    [ 14.  13.]]\n",
      "\n",
      "   [[ 15. -16.]\n",
      "    [ 16.  15.]]\n",
      "\n",
      "   [[ 17. -18.]\n",
      "    [ 18.  17.]]]]], shape=(2, 3, 3, 2, 2), dtype=float64)\n",
      "sum = tf.Tensor(\n",
      "[[[[-21.]\n",
      "   [ 88.]]\n",
      "\n",
      "  [[-39.]\n",
      "   [214.]]\n",
      "\n",
      "  [[-57.]\n",
      "   [340.]]]\n",
      "\n",
      "\n",
      " [[[-21.]\n",
      "   [ 88.]]\n",
      "\n",
      "  [[-39.]\n",
      "   [214.]]\n",
      "\n",
      "  [[-57.]\n",
      "   [340.]]]], shape=(2, 3, 2, 1), dtype=float64)\n",
      "sum_complex = tf.Tensor(\n",
      "[[[-21. +88.j]\n",
      "  [-39.+214.j]\n",
      "  [-57.+340.j]]\n",
      "\n",
      " [[-21. +88.j]\n",
      "  [-39.+214.j]\n",
      "  [-57.+340.j]]], shape=(2, 3, 1), dtype=complex128)\n",
      "Y = sum_complex!!!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_RX_ANT = 3\n",
    "NUM_TX_ANT = 3\n",
    "X = tf.constant([[[1+2j],[3+4j],[5+6j]],[[1+2j],[3+4j],[5+6j]]])\n",
    "print('X =',X)\n",
    "H = tf.constant([[[1+2j,3+4j,5+6j],[7+8j,9+10j,11+12j],[13+14j,15+16j,17+18j]],[[1+2j,3+4j,5+6j],[7+8j,9+10j,11+12j],[13+14j,15+16j,17+18j]]])\n",
    "print('H =',H)\n",
    "H_shape = tf.shape(H)\n",
    "# print('H_shape =',H_shape)\n",
    "# print('BATCH_SIZE =',H.shape[0])\n",
    "Y = tf.matmul(H, X)\n",
    "print('Y =',Y)\n",
    "\n",
    "X_real_part = tf.math.real(X);\n",
    "# print('X_real_part =',X_real_part)\n",
    "X_imag_part = tf.math.imag(X);\n",
    "# print('X_imag_part =',X_imag_part)\n",
    "X_temp_real = tf.concat([X_real_part, X_imag_part], axis=2)\n",
    "# print('X_real =',X_real)\n",
    "e = tf.reshape(X_temp_real,[BATCH_SIZE,NUM_TX_ANT,2,1]) # [BATCH_SIZE,NUM_TX_ANT,2,1] = [1,-1,2,1]\n",
    "# print('e =',e)\n",
    "X_real = tf.reshape(tf.repeat(e, repeats=NUM_RX_ANT, axis=0),[BATCH_SIZE,NUM_RX_ANT,NUM_TX_ANT,2,1])\n",
    "# print('X_real =',X_real)\n",
    "\n",
    "Y_real_part = tf.math.real(Y);\n",
    "# print('Y_real_part =',Y_real_part)\n",
    "Y_imag_part = tf.math.imag(Y);\n",
    "# print('Y_imag_part =',Y_imag_part)\n",
    "Y_real_part_reshaped = tf.reshape(Y_real_part,[BATCH_SIZE,NUM_RX_ANT,1,1])\n",
    "# print('Y_real_part_reshaped =',Y_real_part_reshaped)\n",
    "Y_imag_part_reshaped = tf.reshape(Y_imag_part,[BATCH_SIZE,NUM_RX_ANT,1,1])\n",
    "# print('Y_imag_part_reshaped =',Y_imag_part_reshaped)\n",
    "Y_real = tf.concat([Y_real_part_reshaped, Y_imag_part_reshaped], axis=2)\n",
    "print('Y_real =',Y_real)\n",
    "\n",
    "H_Reshaped = tf.reshape(H,[BATCH_SIZE,-1,1])\n",
    "# print('H_Reshaped =',H_Reshaped)\n",
    "H_Reshaped_real_part = tf.math.real(H_Reshaped);\n",
    "# print('H_Reshaped_real_part =',H_Reshaped_real_part)\n",
    "H_Reshaped_imag_part = tf.math.imag(H_Reshaped);\n",
    "# print('H_Reshaped_imag_part =',H_Reshaped_imag_part);\n",
    "\n",
    "H_real_part_Reshaped = tf.reshape(H_Reshaped_real_part,[BATCH_SIZE,-1,1])\n",
    "# print('H_real_part_Reshaped =',H_real_part_Reshaped)\n",
    "H_imag_part_Reshaped = tf.reshape(H_Reshaped_imag_part,[BATCH_SIZE,-1,1])\n",
    "# print('H_imag_part_Reshaped =',H_imag_part_Reshaped)\n",
    "\n",
    "b = tf.concat([H_real_part_Reshaped, -H_imag_part_Reshaped], axis=2)\n",
    "# print('b =',b)\n",
    "c = tf.concat([H_imag_part_Reshaped, H_real_part_Reshaped], axis=2)\n",
    "# print('c =',c)\n",
    "b_trans = tf.reshape(b, [BATCH_SIZE, NUM_RX_ANT*NUM_TX_ANT, -1, 2])\n",
    "# print('b_trans =',b_trans)\n",
    "c_trans = tf.reshape(c, [BATCH_SIZE, NUM_RX_ANT*NUM_TX_ANT, -1, 2])\n",
    "# print('c_trans =',c_trans)\n",
    "d = tf.concat([b_trans, c_trans], axis=2)\n",
    "# print('d =',d)\n",
    "H_real = tf.reshape(d,[BATCH_SIZE,NUM_RX_ANT,NUM_TX_ANT,2,2])\n",
    "print('H_real =',H_real)\n",
    "# H_Reshaped_real = tf.concat([tf.concat([H_real_part_Reshaped, -H_imag_part_Reshaped], axis=2), tf.concat([H_imag_part_Reshaped, H_real_part_Reshaped], axis=2)],axis=1)\n",
    "result = tf.matmul(H_real, X_real)\n",
    "# print('result =',result)\n",
    "sum = tf.reduce_sum(result, axis=2)\n",
    "print('sum =',sum)\n",
    "sum_real_part,sum_imag_part = tf.split(sum, num_or_size_splits=2, axis=2)\n",
    "# print('sum_real =',sum_real)\n",
    "# print('sum_imag =',sum_imag)\n",
    "sum_complex = tf.squeeze(tf.complex(sum_real_part,sum_imag_part),axis=-1)\n",
    "print('sum_complex =',sum_complex)\n",
    "if tf.reduce_all(tf.equal(Y,sum_complex)):\n",
    "    print('Y = sum_complex!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 1.3890,  1.1318, -0.2127],\n",
      "        [ 0.4226, -0.1349,  0.2362],\n",
      "        [ 0.2446, -0.2047, -0.5718],\n",
      "        [-0.3580, -0.0345,  1.4740]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# \n",
    "linear_layer = nn.Linear(in_features=4, out_features=3)\n",
    "\n",
    "# \n",
    "input_tensor = torch.randn(4, 4)\n",
    "\n",
    "# \n",
    "output_tensor = linear_layer(input_tensor)\n",
    "\n",
    "print(output_tensor.shape)  #  torch.Size([3, 5])\n",
    "print(output_tensor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
