{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ebnodb2no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBN0_DB = -3.0\n",
      "no = tf.Tensor(0.4988156, shape=(), dtype=float32)\n",
      "EBN0_DB = -2.6842105263157894\n",
      "no = tf.Tensor(0.46383238, shape=(), dtype=float32)\n",
      "EBN0_DB = -2.3684210526315788\n",
      "no = tf.Tensor(0.43130267, shape=(), dtype=float32)\n",
      "EBN0_DB = -2.0526315789473686\n",
      "no = tf.Tensor(0.4010543, shape=(), dtype=float32)\n",
      "EBN0_DB = -1.736842105263158\n",
      "no = tf.Tensor(0.37292734, shape=(), dtype=float32)\n",
      "EBN0_DB = -1.4210526315789473\n",
      "no = tf.Tensor(0.346773, shape=(), dtype=float32)\n",
      "EBN0_DB = -1.105263157894737\n",
      "no = tf.Tensor(0.32245293, shape=(), dtype=float32)\n",
      "EBN0_DB = -0.7894736842105265\n",
      "no = tf.Tensor(0.29983848, shape=(), dtype=float32)\n",
      "EBN0_DB = -0.47368421052631593\n",
      "no = tf.Tensor(0.27881005, shape=(), dtype=float32)\n",
      "EBN0_DB = -0.1578947368421053\n",
      "no = tf.Tensor(0.2592564, shape=(), dtype=float32)\n",
      "EBN0_DB = 0.1578947368421053\n",
      "no = tf.Tensor(0.2410741, shape=(), dtype=float32)\n",
      "EBN0_DB = 0.4736842105263155\n",
      "no = tf.Tensor(0.22416694, shape=(), dtype=float32)\n",
      "EBN0_DB = 0.7894736842105261\n",
      "no = tf.Tensor(0.20844556, shape=(), dtype=float32)\n",
      "EBN0_DB = 1.1052631578947363\n",
      "no = tf.Tensor(0.19382674, shape=(), dtype=float32)\n",
      "EBN0_DB = 1.421052631578947\n",
      "no = tf.Tensor(0.18023318, shape=(), dtype=float32)\n",
      "EBN0_DB = 1.7368421052631575\n",
      "no = tf.Tensor(0.16759297, shape=(), dtype=float32)\n",
      "EBN0_DB = 2.052631578947368\n",
      "no = tf.Tensor(0.15583925, shape=(), dtype=float32)\n",
      "EBN0_DB = 2.3684210526315788\n",
      "no = tf.Tensor(0.14490984, shape=(), dtype=float32)\n",
      "EBN0_DB = 2.6842105263157894\n",
      "no = tf.Tensor(0.13474695, shape=(), dtype=float32)\n",
      "EBN0_DB = 3.0\n",
      "no = tf.Tensor(0.1252968, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber, compute_ser\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = 8\n",
    "BATCH_SIZE = 2\n",
    "EBN0_DB_MIN = -3.0\n",
    "EBN0_DB_MAX = 3.0\n",
    "\n",
    "for EBN0_DB in np.linspace(EBN0_DB_MIN,EBN0_DB_MAX,20):\n",
    "    print('EBN0_DB =',EBN0_DB)\n",
    "    no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                            num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                            coderate=1.0)\n",
    "    print('no =',no)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWGN (Additive White Gaussian **Noise**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bits =\n",
      " tf.Tensor(\n",
      "[[1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 1. 1. 1.]], shape=(2, 8), dtype=float32)\n",
      "no = tf.Tensor(2.5, shape=(), dtype=float32)\n",
      "x =\n",
      " tf.Tensor(\n",
      "[[-0.9486833-0.9486833j -0.3162278+0.3162278j]\n",
      " [ 0.9486833-0.9486833j  0.9486833-0.9486833j]], shape=(2, 2), dtype=complex64)\n",
      "noise =\n",
      " tf.Tensor(\n",
      "[[-0.2457148 -0.4940561j  -0.2502328 +0.0766773j ]\n",
      " [ 0.6659922 -0.00514933j  0.40934482-0.22090244j]], shape=(2, 2), dtype=complex64)\n",
      "no = tf.Tensor([[2.5]], shape=(1, 1), dtype=float32)\n",
      "no = tf.Tensor([[2.5]], shape=(1, 1), dtype=float32)\n",
      "noise =\n",
      " tf.Tensor(\n",
      "[[-0.3885092 -0.7811713j  -0.39565277+0.12123746j]\n",
      " [ 1.0530262 -0.00814181j  0.647231  -0.34927744j]], shape=(2, 2), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils import expand_to_rank, complex_normal\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = 8\n",
    "BATCH_SIZE = 2\n",
    "EBN0_DB = -10\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "print('bits =\\n',bits)\n",
    "\n",
    "no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                        coderate=1.0)\n",
    "print('no =',no)\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "\n",
    "x = mapper(bits)\n",
    "print('x =\\n',x)\n",
    " \n",
    "# Create tensors of real-valued Gaussian noise for each complex dim.\n",
    "noise = complex_normal(tf.shape(x), dtype=x.dtype)\n",
    "print('noise =\\n',noise)\n",
    "\n",
    "# Add extra dimensions for broadcasting\n",
    "no = expand_to_rank(no, tf.rank(x), axis=-1)\n",
    "print('no =',no)\n",
    "\n",
    "# Apply variance scaling\n",
    "real_dtype = tf.dtypes.as_dtype(tf.complex64).real_dtype\n",
    "no = tf.cast(no, real_dtype)\n",
    "print('no =',no)\n",
    "noise *= tf.cast(tf.sqrt(no), noise.dtype)\n",
    "print('noise =\\n',noise)\n",
    "\n",
    "# Add noise to input\n",
    "y = x + noise\n",
    "#print('y = x + noise =\\n',y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logits2llrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits2llrs =\n",
      " None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/im/Documents/GitHub/sionna/Jupyter Notebooks/Test.ipynb 单元格 4\u001b[0m in \u001b[0;36m<cell line: 271>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/im/Documents/GitHub/sionna/Jupyter%20Notebooks/Test.ipynb#W4sZmlsZQ%3D%3D?line=265'>266</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlogits2llrs =\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m,logits2llrs)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/im/Documents/GitHub/sionna/Jupyter%20Notebooks/Test.ipynb#W4sZmlsZQ%3D%3D?line=267'>268</a>\u001b[0m \u001b[39m# if self._with_prior:\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/im/Documents/GitHub/sionna/Jupyter%20Notebooks/Test.ipynb#W4sZmlsZQ%3D%3D?line=268'>269</a>\u001b[0m \u001b[39m#     llr = self._logits2llrs([exponents, prior])\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/im/Documents/GitHub/sionna/Jupyter%20Notebooks/Test.ipynb#W4sZmlsZQ%3D%3D?line=269'>270</a>\u001b[0m \u001b[39m# else:\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/im/Documents/GitHub/sionna/Jupyter%20Notebooks/Test.ipynb#W4sZmlsZQ%3D%3D?line=270'>271</a>\u001b[0m llr \u001b[39m=\u001b[39m logits2llrs(exponents)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/im/Documents/GitHub/sionna/Jupyter%20Notebooks/Test.ipynb#W4sZmlsZQ%3D%3D?line=272'>273</a>\u001b[0m \u001b[39m# Reshape LLRs to [...,n*num_bits_per_symbol]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/im/Documents/GitHub/sionna/Jupyter%20Notebooks/Test.ipynb#W4sZmlsZQ%3D%3D?line=273'>274</a>\u001b[0m out_shape \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconcat([tf\u001b[39m.\u001b[39mshape(y)[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/im/Documents/GitHub/sionna/Jupyter%20Notebooks/Test.ipynb#W4sZmlsZQ%3D%3D?line=274'>275</a>\u001b[0m                         [y\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \\\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/im/Documents/GitHub/sionna/Jupyter%20Notebooks/Test.ipynb#W4sZmlsZQ%3D%3D?line=275'>276</a>\u001b[0m                         constellation\u001b[39m.\u001b[39mnum_bits_per_symbol]], \u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.float32, **kwargs):\n",
    "    # pylint: disable=line-too-long\n",
    "    r\"\"\"\n",
    "    SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.float32, **kwargs)\n",
    "\n",
    "    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n",
    "    from a tensor of logits (i.e., unnormalized log-probabilities) on constellation points.\n",
    "    If the flag ``with_prior`` is set, prior knowledge on the bits is assumed to be available.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : One of [\"app\", \"maxlog\"], str\n",
    "        The method used for computing the LLRs.\n",
    "\n",
    "    num_bits_per_symbol : int\n",
    "        The number of bits per constellation symbol, e.g., 4 for QAM16.\n",
    "\n",
    "    hard_out : bool\n",
    "        If `True`, the layer provides hard-decided bits instead of soft-values.\n",
    "        Defaults to `False`.\n",
    "\n",
    "    with_prior : bool\n",
    "        If `True`, it is assumed that prior knowledge on the bits is available.\n",
    "        This prior information is given as LLRs as an additional input to the layer.\n",
    "        Defaults to `False`.\n",
    "\n",
    "    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n",
    "        The dtype for the input and output.\n",
    "        Defaults to `tf.float32`.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    logits or (logits, prior):\n",
    "        Tuple:\n",
    "\n",
    "    logits : [...,n, num_points], tf.float\n",
    "        Logits on constellation points.\n",
    "\n",
    "    prior : [num_bits_per_symbol] or [...n, num_bits_per_symbol], tf.float\n",
    "        Prior for every bit as LLRs.\n",
    "        It can be provided either as a tensor of shape `[num_bits_per_symbol]`\n",
    "        for the entire input batch, or as a tensor that is \"broadcastable\"\n",
    "        to `[..., n, num_bits_per_symbol]`.\n",
    "        Only required if the ``with_prior`` flag is set.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    : [...,n, num_bits_per_symbol], tf.float\n",
    "        LLRs or hard-decisions for every bit.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    With the \"app\" method, the LLR for the :math:`i\\text{th}` bit\n",
    "    is computed according to\n",
    "\n",
    "    .. math::\n",
    "        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert \\mathbf{z},\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert \\mathbf{z},\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n",
    "                \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                e^{z_c}\n",
    "                }{\n",
    "                \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                e^{z_c}\n",
    "                }\\right)\n",
    "\n",
    "    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n",
    "    sets of :math:`2^K` constellation points for which the :math:`i\\text{th}` bit is\n",
    "    equal to 1 and 0, respectively. :math:`\\mathbf{z} = \\left[z_{c_0},\\dots,z_{c_{2^K-1}}\\right]` is the vector of logits on the constellation points, :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]`\n",
    "    is the vector of LLRs that serves as prior knowledge on the :math:`K` bits that are mapped to\n",
    "    a constellation point and is set to :math:`\\mathbf{0}` if no prior knowledge is assumed to be available,\n",
    "    and :math:`\\Pr(c\\lvert\\mathbf{p})` is the prior probability on the constellation symbol :math:`c`:\n",
    "\n",
    "    .. math::\n",
    "        \\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert\\mathbf{p} \\right)\n",
    "        = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n",
    "\n",
    "    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where 0 is\n",
    "    replaced by -1.\n",
    "    The definition of the LLR has been\n",
    "    chosen such that it is equivalent with that of logits. This is\n",
    "    different from many textbooks in communications, where the LLR is\n",
    "    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n",
    "\n",
    "    With the \"maxlog\" method, LLRs for the :math:`i\\text{th}` bit\n",
    "    are approximated like\n",
    "\n",
    "    .. math::\n",
    "        \\begin{align}\n",
    "            LLR(i) &\\approx\\ln\\left(\\frac{\n",
    "                \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                    e^{z_c}\n",
    "                }{\n",
    "                \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n",
    "                    e^{z_c}\n",
    "                }\\right)\n",
    "                .\n",
    "        \\end{align}\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 method,\n",
    "                 num_bits_per_symbol,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.float32,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert method in (\"app\",\"maxlog\"), \"Unknown demapping method\"\n",
    "        self._method = method\n",
    "        self._hard_out = hard_out\n",
    "        self._num_bits_per_symbol = num_bits_per_symbol\n",
    "        self._with_prior = with_prior\n",
    "        num_points = int(2**num_bits_per_symbol)\n",
    "\n",
    "        # Array composed of binary representations of all symbols indices\n",
    "        a = np.zeros([num_points, num_bits_per_symbol])\n",
    "        for i in range(0, num_points):\n",
    "            a[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n",
    "                              dtype=np.int16)\n",
    "\n",
    "        # Compute symbol indices for which the bits are 0 or 1\n",
    "        c0 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        c1 = np.zeros([int(num_points/2), num_bits_per_symbol])\n",
    "        for i in range(num_bits_per_symbol-1,-1,-1):\n",
    "            c0[:,i] = np.where(a[:,i]==0)[0]\n",
    "            c1[:,i] = np.where(a[:,i]==1)[0]\n",
    "        self._c0 = tf.constant(c0, dtype=tf.int32) # Symbols with ith bit=0\n",
    "        self._c1 = tf.constant(c1, dtype=tf.int32) # Symbols with ith bit=1\n",
    "\n",
    "        if with_prior:\n",
    "            # Array of labels from {-1, 1} of all symbols\n",
    "            # [num_points, num_bits_per_symbol]\n",
    "            a = 2*a-1\n",
    "            self._a = tf.constant(a, dtype=dtype)\n",
    "\n",
    "        # Determine the reduce function for LLR computation\n",
    "        if self._method == \"app\":\n",
    "            self._reduce = tf.reduce_logsumexp\n",
    "        else:\n",
    "            self._reduce = tf.reduce_max\n",
    "\n",
    "    @property\n",
    "    def num_bits_per_symbol(self):\n",
    "        return self._num_bits_per_symbol\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            logits, prior = inputs\n",
    "        else:\n",
    "            logits = inputs\n",
    "\n",
    "        # Compute exponents\n",
    "        exponents = logits\n",
    "\n",
    "        # Gather exponents for all bits\n",
    "        # shape [...,n,num_points/2,num_bits_per_symbol]\n",
    "        exp0 = tf.gather(exponents, self._c0, axis=-1, batch_dims=0)\n",
    "        exp1 = tf.gather(exponents, self._c1, axis=-1, batch_dims=0)\n",
    "\n",
    "        # Process the prior information\n",
    "        if self._with_prior:\n",
    "            # Expanding `prior` such that it is broadcastable with\n",
    "            # shape [..., n or 1, 1, num_bits_per_symbol]\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(logits), axis=0)\n",
    "            prior = tf.expand_dims(prior, axis=-2)\n",
    "\n",
    "            # Expand the symbol labeling to be broadcastable with prior\n",
    "            # shape [..., 1, num_points, num_bits_per_symbol]\n",
    "            a = sn.utils.expand_to_rank(self._a, tf.rank(prior), axis=0)\n",
    "\n",
    "            # Compute the prior probabilities on symbols exponents\n",
    "            # shape [..., n or 1, num_points]\n",
    "            exp_ps = tf.reduce_sum(tf.math.log_sigmoid(a*prior), axis=-1)\n",
    "\n",
    "            # Gather prior probability symbol for all bits\n",
    "            # shape [..., n or 1, num_points/2, num_bits_per_symbol]\n",
    "            exp_ps0 = tf.gather(exp_ps, self._c0, axis=-1)\n",
    "            exp_ps1 = tf.gather(exp_ps, self._c1, axis=-1)\n",
    "\n",
    "        # Compute LLRs using the definition log( Pr(b=1)/Pr(b=0) )\n",
    "        # shape [..., n, num_bits_per_symbol]\n",
    "        if self._with_prior:\n",
    "            llr = self._reduce(exp_ps1 + exp1, axis=-2)\\\n",
    "                    - self._reduce(exp_ps0 + exp0, axis=-2)\n",
    "        else:\n",
    "            llr = self._reduce(exp1, axis=-2) - self._reduce(exp0, axis=-2)\n",
    "\n",
    "        if self._hard_out:\n",
    "            return sn.utils.hard_decisions(llr)\n",
    "        else:\n",
    "            return llr\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = 8\n",
    "BATCH_SIZE = 2\n",
    "EBN0_DB = -10\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "\n",
    "# AWGN channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "#print('bits =\\n',bits)\n",
    "\n",
    "no = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n",
    "                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n",
    "                        coderate=1.0)\n",
    "#print('no =',no)\n",
    "\n",
    "x = mapper(bits)\n",
    "#print('x =\\n',x)\n",
    "\n",
    "y = awgn_channel([x, no])\n",
    "\n",
    "# Reshape constellation points to [1,...1,num_points]\n",
    "points_shape = [1]*y.shape.rank + constellation.points.shape\n",
    "points = tf.reshape(constellation.points, points_shape)\n",
    "\n",
    "# Compute squared distances from y to all points\n",
    "# shape [...,n,num_points]\n",
    "squared_dist = tf.pow(tf.abs(tf.expand_dims(y, axis=-1) - points), 2)\n",
    "\n",
    "# Add a dummy dimension for broadcasting. This is not needed when no\n",
    "# is a scalar, but also does not do any harm.\n",
    "no = tf.expand_dims(no, axis=-1)\n",
    "\n",
    "# Compute exponents\n",
    "exponents = -squared_dist/no\n",
    "#print('exponents =\\n',exponents)\n",
    "\n",
    "logits2llrs = SymbolLogits2LLRs(\"app\",NUM_BITS_PER_SYMBOL)\n",
    "print('logits2llrs =\\n',logits2llrs)\n",
    "\n",
    "# if self._with_prior:\n",
    "#     llr = self._logits2llrs([exponents, prior])\n",
    "# else:\n",
    "llr = logits2llrs(exponents)\n",
    "\n",
    "# Reshape LLRs to [...,n*num_bits_per_symbol]\n",
    "out_shape = tf.concat([tf.shape(y)[:-1],\n",
    "                        [y.shape[-1] * \\\n",
    "                        constellation.num_bits_per_symbol]], 0)\n",
    "llr_reshaped = tf.reshape(llr, out_shape)\n",
    "\n",
    "# return llr_reshaped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bits2symbol"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber, compute_ser\n",
    "\n",
    "CODERATE = 0.5\n",
    "n = 16\n",
    "k = int(n*CODERATE)\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "print('NUM_BITS_PER_SYMBOL =',NUM_BITS_PER_SYMBOL)\n",
    "BLOCK_LENGTH = k\n",
    "BATCH_SIZE = 2 # How many examples are processed by Sionna in parallel\n",
    "EBN0_DB_MIN = -10.0 # Minimum value of Eb/N0 [dB] for simulations\n",
    "EBN0_DB_MAX = 10.0 # Maximum value of Eb/N0 [dB] for simulations\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "\n",
    "bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "print('bits =\\n',bits)\n",
    "\n",
    "new_shape = [-1] + bits.shape[1:-1].as_list() + \\\n",
    "           [int(bits.shape[-1] / NUM_BITS_PER_SYMBOL),\n",
    "            NUM_BITS_PER_SYMBOL]\n",
    "print('new_shape =\\n',new_shape)\n",
    "\n",
    "bits_reshaped = tf.cast(tf.reshape(bits, new_shape), tf.int32)\n",
    "print('symbols =\\n',bits_reshaped)\n",
    "\n",
    "binary_base = 2**tf.constant(\n",
    "                        range(NUM_BITS_PER_SYMBOL-1,-1,-1))\n",
    "print('binary_base =\\n',binary_base)\n",
    "\n",
    "int_rep = tf.reduce_sum(bits_reshaped * binary_base, axis=-1)\n",
    "print('int_rep =\\n',int_rep)\n",
    "\n",
    "x = tf.gather(constellation.points, int_rep, axis=0)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Basics\n",
    "\n",
    "# Import TensorFlow and NumPy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "# also try %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber, compute_ser\n",
    "\n",
    "def bits2symbol(bits,num_bits_per_symbol):\n",
    "    new_shape = [-1] + bits.shape[1:-1].as_list() + \\\n",
    "            [int(bits.shape[-1] / NUM_BITS_PER_SYMBOL),\n",
    "                NUM_BITS_PER_SYMBOL]\n",
    "    #print('new_shape =',new_shape)\n",
    "    #print('bits.shape[1:-1]',bits.shape[1:-1])\n",
    "    # print('bits.shape[-1]=',bits.shape[-1])\n",
    "\n",
    "    symbols = tf.cast(tf.reshape(bits, new_shape), tf.int32)\n",
    "    # print('symbols =',symbols)\n",
    "    return symbols\n",
    "\n",
    "\n",
    "CODERATE = 0.5\n",
    "n = 16\n",
    "k = int(n*CODERATE)\n",
    "\n",
    "NUM_BITS_PER_SYMBOL = 4 # QPSK\n",
    "BLOCK_LENGTH = k\n",
    "BATCH_SIZE = 2 # How many examples are processed by Sionna in parallel\n",
    "EBN0_DB_MIN = -10.0 # Minimum value of Eb/N0 [dB] for simulations\n",
    "EBN0_DB_MAX = 10.0 # Maximum value of Eb/N0 [dB] for simulations\n",
    "\n",
    "# Binary source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "\n",
    "#bits = binary_source([BATCH_SIZE,BLOCK_LENGTH])\n",
    "bits = binary_source([2,3,4,5,6])\n",
    "# print('bits =',bits)\n",
    "# print('bits.ndim =',bits.ndim)\n",
    "\n",
    "symbols = bits2symbol(bits,NUM_BITS_PER_SYMBOL)\n",
    "# print('symbols =',symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_tx = tf.Tensor(\n",
      "[[1.        +0.j 0.4       -0.j 0.16000001-0.j 0.06400001-0.j]\n",
      " [0.4       +0.j 1.        +0.j 0.4       -0.j 0.16000001-0.j]\n",
      " [0.16000001+0.j 0.4       +0.j 1.        +0.j 0.4       -0.j]\n",
      " [0.06400001+0.j 0.16000001+0.j 0.4       +0.j 1.        +0.j]], shape=(4, 4), dtype=complex64)\n",
      "r_rx = tf.Tensor(\n",
      "[[1.        +0.j 0.9       -0.j 0.80999994-0.j 0.7289999 -0.j\n",
      "  0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j\n",
      "  0.4304671 -0.j 0.3874204 -0.j 0.34867835-0.j 0.3138105 -0.j\n",
      "  0.28242943-0.j 0.25418648-0.j 0.22876784-0.j 0.20589103-0.j]\n",
      " [0.9       +0.j 1.        +0.j 0.9       -0.j 0.80999994-0.j\n",
      "  0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j\n",
      "  0.47829682-0.j 0.4304671 -0.j 0.3874204 -0.j 0.34867835-0.j\n",
      "  0.3138105 -0.j 0.28242943-0.j 0.25418648-0.j 0.22876784-0.j]\n",
      " [0.80999994+0.j 0.9       +0.j 1.        +0.j 0.9       -0.j\n",
      "  0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j\n",
      "  0.5314409 -0.j 0.47829682-0.j 0.4304671 -0.j 0.3874204 -0.j\n",
      "  0.34867835-0.j 0.3138105 -0.j 0.28242943-0.j 0.25418648-0.j]\n",
      " [0.7289999 +0.j 0.80999994+0.j 0.9       +0.j 1.        +0.j\n",
      "  0.9       -0.j 0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j\n",
      "  0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j 0.4304671 -0.j\n",
      "  0.3874204 -0.j 0.34867835-0.j 0.3138105 -0.j 0.28242943-0.j]\n",
      " [0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j 0.9       +0.j\n",
      "  1.        +0.j 0.9       -0.j 0.80999994-0.j 0.7289999 -0.j\n",
      "  0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j\n",
      "  0.4304671 -0.j 0.3874204 -0.j 0.34867835-0.j 0.3138105 -0.j]\n",
      " [0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j\n",
      "  0.9       +0.j 1.        +0.j 0.9       -0.j 0.80999994-0.j\n",
      "  0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j\n",
      "  0.47829682-0.j 0.4304671 -0.j 0.3874204 -0.j 0.34867835-0.j]\n",
      " [0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j\n",
      "  0.80999994+0.j 0.9       +0.j 1.        +0.j 0.9       -0.j\n",
      "  0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j\n",
      "  0.5314409 -0.j 0.47829682-0.j 0.4304671 -0.j 0.3874204 -0.j]\n",
      " [0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j\n",
      "  0.7289999 +0.j 0.80999994+0.j 0.9       +0.j 1.        +0.j\n",
      "  0.9       -0.j 0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j\n",
      "  0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j 0.4304671 -0.j]\n",
      " [0.4304671 +0.j 0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j\n",
      "  0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j 0.9       +0.j\n",
      "  1.        +0.j 0.9       -0.j 0.80999994-0.j 0.7289999 -0.j\n",
      "  0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j]\n",
      " [0.3874204 +0.j 0.4304671 +0.j 0.47829682+0.j 0.5314409 +0.j\n",
      "  0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j\n",
      "  0.9       +0.j 1.        +0.j 0.9       -0.j 0.80999994-0.j\n",
      "  0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j]\n",
      " [0.34867835+0.j 0.3874204 +0.j 0.4304671 +0.j 0.47829682+0.j\n",
      "  0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j\n",
      "  0.80999994+0.j 0.9       +0.j 1.        +0.j 0.9       -0.j\n",
      "  0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j]\n",
      " [0.3138105 +0.j 0.34867835+0.j 0.3874204 +0.j 0.4304671 +0.j\n",
      "  0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j\n",
      "  0.7289999 +0.j 0.80999994+0.j 0.9       +0.j 1.        +0.j\n",
      "  0.9       -0.j 0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j]\n",
      " [0.28242943+0.j 0.3138105 +0.j 0.34867835+0.j 0.3874204 +0.j\n",
      "  0.4304671 +0.j 0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j\n",
      "  0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j 0.9       +0.j\n",
      "  1.        +0.j 0.9       -0.j 0.80999994-0.j 0.7289999 -0.j]\n",
      " [0.25418648+0.j 0.28242943+0.j 0.3138105 +0.j 0.34867835+0.j\n",
      "  0.3874204 +0.j 0.4304671 +0.j 0.47829682+0.j 0.5314409 +0.j\n",
      "  0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j\n",
      "  0.9       +0.j 1.        +0.j 0.9       -0.j 0.80999994-0.j]\n",
      " [0.22876784+0.j 0.25418648+0.j 0.28242943+0.j 0.3138105 +0.j\n",
      "  0.34867835+0.j 0.3874204 +0.j 0.4304671 +0.j 0.47829682+0.j\n",
      "  0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j\n",
      "  0.80999994+0.j 0.9       +0.j 1.        +0.j 0.9       -0.j]\n",
      " [0.20589103+0.j 0.22876784+0.j 0.25418648+0.j 0.28242943+0.j\n",
      "  0.3138105 +0.j 0.34867835+0.j 0.3874204 +0.j 0.4304671 +0.j\n",
      "  0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j\n",
      "  0.7289999 +0.j 0.80999994+0.j 0.9       +0.j 1.        +0.j]], shape=(16, 16), dtype=complex64)\n",
      "r_tx.shape = (4, 4)\n",
      "r_rx.shape = (16, 16)\n",
      "h.shape = (1000000, 16, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.12131725>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "\n",
    "BATCH_SIZE = 1000000\n",
    "NUM_TX_ANT = 4\n",
    "NUM_RX_ANT = 16\n",
    "NUM_BITS_PER_SYMBOL = 4\n",
    "\n",
    "channel = FlatFadingChannel(num_tx_ant=NUM_TX_ANT, num_rx_ant=NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "no = 0.2 # Noise variance of the channel\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "qam_source = QAMSource(num_bits_per_symbol=NUM_BITS_PER_SYMBOL)\n",
    "x = qam_source([BATCH_SIZE, NUM_TX_ANT])\n",
    "# print('x =',x)\n",
    "# Get symbol indices for the transmitted symbols\n",
    "x_ind = symbol_demapper([x, no])\n",
    "# print('x_ind =',x_ind)\n",
    "\n",
    "# Create transmit and receive correlation matrices\n",
    "r_tx = exp_corr_mat(0.4, NUM_TX_ANT)\n",
    "r_rx = exp_corr_mat(0.9, NUM_RX_ANT)\n",
    "\n",
    "print('r_tx =',r_tx)\n",
    "print('r_rx =',r_rx)\n",
    "print('r_tx.shape =',r_tx.shape)\n",
    "print('r_rx.shape =',r_rx.shape)\n",
    "\n",
    "# Add the spatial correlation model to the channel\n",
    "channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "#print('h_corr =',KroneckerModel(r_tx, r_rx))\n",
    "\n",
    "h = channel.generate(BATCH_SIZE)\n",
    "print('h.shape =',h.shape)\n",
    "\n",
    "# Compute empirical covariance matrices\n",
    "r_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/NUM_RX_ANT\n",
    "r_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/NUM_TX_ANT\n",
    "\n",
    "# Test that the empirical results match the theory\n",
    "# assert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\n",
    "# assert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n",
    "\n",
    "y, h = channel([x, no]) # type: ignore\n",
    "s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "x_hat, no_eff = lmmse_equalizer(y, h, s)\n",
    "\n",
    "# Get symbol indices for the received soft-symbols\n",
    "x_ind_hat = symbol_demapper([x_hat, no])\n",
    "compute_ser(x_ind, x_ind_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FlatFadingChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b shape = (32, 4, 512)\n",
      "x shape = (32, 4, 128)\n",
      "x reshape = (4096, 4)\n",
      "h shape = (4096, 16, 4)\n",
      "x reshape app_chn (4096, 4, 1)\n",
      "noise shape (4096, 16)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from sionna.utils import expand_to_rank, complex_normal\n",
    "\n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "\n",
    "# from sionna.channel import AWGN\n",
    "from sionna.utils import complex_normal\n",
    "\n",
    "class AWGN(Layer):\n",
    "    def __init__(self, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._real_dtype = tf.dtypes.as_dtype(self._dtype).real_dtype\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x, no = inputs\n",
    "\n",
    "        # Create tensors of real-valued Gaussian noise for each complex dim.\n",
    "        noise = complex_normal(tf.shape(x), dtype=x.dtype)\n",
    "\n",
    "        # Add extra dimensions for broadcasting\n",
    "        no = expand_to_rank(no, tf.rank(x), axis=-1)\n",
    "\n",
    "        # Apply variance scaling\n",
    "        no = tf.cast(no, self._real_dtype)\n",
    "        noise *= tf.cast(tf.sqrt(no), noise.dtype)\n",
    "        print('noise shape',noise.shape)\n",
    "        # Add noise to input\n",
    "        y = x + noise\n",
    "\n",
    "        return y\n",
    "\n",
    "class GenerateFlatFadingChannel():\n",
    "    def __init__(self, num_tx_ant, num_rx_ant, spatial_corr=None, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._dtype = dtype\n",
    "        self.spatial_corr = spatial_corr\n",
    " \n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._spatial_corr\n",
    " \n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._spatial_corr = value\n",
    " \n",
    "    def __call__(self, batch_size):\n",
    "        # Generate standard complex Gaussian matrices\n",
    "        shape = [batch_size, self._num_rx_ant, self._num_tx_ant]\n",
    "        h = complex_normal(shape, dtype=self._dtype)\n",
    " \n",
    "        # Apply spatial correlation\n",
    "        if self.spatial_corr is not None:\n",
    "            h = self.spatial_corr(h)\n",
    " \n",
    "        return h\n",
    "\n",
    "class ApplyFlatFadingChannel(tf.keras.layers.Layer):\n",
    "    def __init__(self, add_awgn=True, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "        self._add_awgn = add_awgn\n",
    " \n",
    "    def build(self, input_shape): #pylint: disable=unused-argument\n",
    "        if self._add_awgn:\n",
    "            self._awgn = AWGN(dtype=self.dtype)\n",
    " \n",
    "    def call(self, inputs):\n",
    "        if self._add_awgn:\n",
    "            x, h, no = inputs\n",
    "        else:\n",
    "            x, h = inputs\n",
    " \n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "        print('x reshape app_chn',x.shape)\n",
    "        y = tf.matmul(h, x)\n",
    "        y = tf.squeeze(y, axis=-1)\n",
    " \n",
    "        if self._add_awgn:\n",
    "            y = self._awgn((y, no))\n",
    " \n",
    "        return y\n",
    "\n",
    "class FlatFadingChannel(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_tx_ant,\n",
    "                 num_rx_ant,\n",
    "                 spatial_corr=None,\n",
    "                 add_awgn=True,\n",
    "                 return_channel=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._add_awgn = add_awgn\n",
    "        self._return_channel = return_channel\n",
    "        self._gen_chn = GenerateFlatFadingChannel(self._num_tx_ant,\n",
    "                                                  self._num_rx_ant,\n",
    "                                                  spatial_corr,\n",
    "                                                  dtype=dtype)\n",
    "        self._app_chn = ApplyFlatFadingChannel(add_awgn=add_awgn, dtype=dtype)\n",
    " \n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._gen_chn.spatial_corr\n",
    " \n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._gen_chn.spatial_corr = value\n",
    " \n",
    "    @property\n",
    "    def generate(self):\n",
    "        \"\"\"Calls the internal :class:`GenerateFlatFadingChannel`.\"\"\"\n",
    "        return self._gen_chn\n",
    " \n",
    "    @property\n",
    "    def apply(self):\n",
    "        \"\"\"Calls the internal :class:`ApplyFlatFadingChannel`.\"\"\"\n",
    "        return self._app_chn\n",
    " \n",
    "    def call(self, inputs):\n",
    "        if self._add_awgn:\n",
    "            x, no = inputs\n",
    "        else:\n",
    "            x = inputs\n",
    " \n",
    "        # Generate a batch of channel realizations\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        h = self._gen_chn(batch_size)\n",
    "        print('h shape =',h.shape)\n",
    " \n",
    "        # Apply the channel to the input\n",
    "        if self._add_awgn:\n",
    "            y = self._app_chn([x, h, no])\n",
    "        else:\n",
    "            y = self._app_chn([x, h])\n",
    " \n",
    "        if self._return_channel:\n",
    "            return y, h\n",
    "        else:\n",
    "            return y\n",
    "\n",
    "no = 0.2\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 32 # Parallel in 32 Batches\n",
    "k = 512 # Message Bits\n",
    "NUM_RX_ANT = 16 # Receiver Antennas\n",
    "NUM_TX_ANT = 4 # Transmitter Antennas\n",
    "\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "\n",
    "y, h = flatfading_channel([x_reshape, no]) # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complex_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_dim = tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "stddev = tf.Tensor(0.70710677, shape=(), dtype=float32)\n",
      "x = tf.Tensor(\n",
      "[[[-1.2177651 +0.09163907j -0.0687925 +0.63868874j]\n",
      "  [ 0.12732428-0.741966j    0.70574963+0.3686277j ]\n",
      "  [ 0.8471744 +0.89642155j -0.61999476+0.5020816j ]]\n",
      "\n",
      " [[ 0.3094684 +0.8396757j  -0.17501539-0.47946107j]\n",
      "  [ 0.73089117-0.8029014j   0.10686365-0.96113425j]\n",
      "  [ 1.6795001 +0.4054319j  -0.9734228 -0.9575875j ]]\n",
      "\n",
      " [[-1.085868  +0.27700955j  1.0796782 -0.18337949j]\n",
      "  [-0.9778669 +0.21080385j  0.24215956+2.03898j   ]\n",
      "  [ 0.23300657+0.16278j     1.1952568 +0.32316047j]]\n",
      "\n",
      " [[-0.6072106 +0.32206395j -0.7255045 +0.20543936j]\n",
      "  [ 0.76360106-0.10037783j  0.32929915-1.532512j  ]\n",
      "  [ 0.10845231+0.46006835j  1.1205252 -0.05848385j]]], shape=(4, 3, 2), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Layer\n",
    "def complex_normal(shape, var=1.0, dtype=tf.complex64):\n",
    "    # Half the variance for each dimension\n",
    "    var_dim = tf.cast(var, dtype.real_dtype)/tf.cast(2, dtype.real_dtype) # var_dim = 1/2\n",
    "    print('var_dim =',var_dim)\n",
    "    stddev = tf.sqrt(var_dim) # standard deviation = sqrt(variance) = sqrt(1/2) = 0.7071\n",
    "    print('stddev =',stddev)\n",
    " \n",
    "    # Generate complex Gaussian noise with the right variance\n",
    "    xr = tf.random.normal(shape, stddev=stddev, dtype=dtype.real_dtype)\n",
    "    xi = tf.random.normal(shape, stddev=stddev, dtype=dtype.real_dtype)\n",
    "    x = tf.complex(xr, xi)\n",
    "    print('x =',x)\n",
    " \n",
    "    return x\n",
    "\n",
    "shape = [4,3,2];\n",
    "complex_normal(shape);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# equalization\n",
    "# whiten_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 0\n",
      "b shape = (1, 2, 8)\n",
      "x shape = (1, 2, 2)\n",
      "x reshape = (2, 2)\n",
      "y shape = (2, 4)\n",
      "h shape = (2, 4, 2)\n",
      "s = tf.Tensor(\n",
      "[[0.2+0.j 0. +0.j 0. +0.j 0. +0.j]\n",
      " [0. +0.j 0.2+0.j 0. +0.j 0. +0.j]\n",
      " [0. +0.j 0. +0.j 0.2+0.j 0. +0.j]\n",
      " [0. +0.j 0. +0.j 0. +0.j 0.2+0.j]], shape=(4, 4), dtype=complex64)\n",
      "tf.rank(s) = tf.Tensor(2, shape=(), dtype=int32)\n",
      "h = tf.Tensor(\n",
      "[[[-0.28165317+0.12280053j  2.3477244 +1.8990581j ]\n",
      "  [-0.29761904-1.1903015j  -0.8393968 -0.683898j  ]\n",
      "  [ 1.1311303 +1.1169087j   0.7194977 +0.8282846j ]\n",
      "  [ 1.8959545 -2.5116053j   0.12424983+1.3606714j ]]\n",
      "\n",
      " [[-0.05617288-1.5529664j  -0.3347871 +1.2865958j ]\n",
      "  [ 1.772026  -1.4055105j   0.0477695 -0.69425297j]\n",
      "  [ 0.3951614 +1.3942993j  -1.4122099 +1.3113167j ]\n",
      "  [-1.0189399 +0.63120556j -1.102038  -1.5496628j ]]], shape=(2, 4, 2), dtype=complex64)\n",
      "h^H = [[[-0.02455929-0.03503502j -0.01997718+0.09542315j\n",
      "    0.07861121-0.08983561j  0.12725149+0.17468184j]\n",
      "  [ 0.17791711-0.14683442j -0.07407448+0.05484712j\n",
      "    0.06805454-0.05914444j -0.00140022-0.07789192j]]\n",
      "\n",
      " [[-0.04382511+0.17078948j  0.19680847+0.13413976j\n",
      "    0.00562767-0.08746606j -0.04709714-0.03621078j]\n",
      "  [-0.08626291-0.15687674j -0.0472995 +0.12726623j\n",
      "   -0.12023465-0.13056295j -0.10121524+0.14883165j]]]\n",
      "i = tf.Tensor(\n",
      "[[1.+0.j 0.+0.j]\n",
      " [0.+0.j 1.+0.j]], shape=(2, 2), dtype=complex64)\n",
      "(h^H)h = tf.Tensor(\n",
      "[[[14.029549 +0.j        -0.807107 +1.4063505j]\n",
      "  [-0.807107 -1.4063505j 13.361132 +0.j       ]]\n",
      "\n",
      " [[11.067278 +0.j         0.4962663+3.006572j ]\n",
      "  [ 0.4962663-3.006572j   9.5815115+0.j       ]]], shape=(2, 2, 2), dtype=complex64)\n",
      "(h^H)h+i = tf.Tensor(\n",
      "[[[15.029549 +0.j        -0.807107 +1.4063505j]\n",
      "  [-0.807107 -1.4063505j 14.361132 +0.j       ]]\n",
      "\n",
      " [[12.067278 +0.j         0.4962663+3.006572j ]\n",
      "  [ 0.4962663-3.006572j  10.5815115+0.j       ]]], shape=(2, 2, 2), dtype=complex64)\n",
      "((h^H)h+i)^-1 = tf.Tensor(\n",
      "[[[ 0.06735609+0.j          0.00378547-0.00659602j]\n",
      "  [ 0.00378547+0.00659602j  0.07049107+0.j        ]]\n",
      "\n",
      " [[ 0.08936763+0.j         -0.00419129-0.02539242j]\n",
      "  [-0.00419129+0.02539243j  0.1019159 +0.j        ]]], shape=(2, 2, 2), dtype=complex64)\n",
      "(((h^H)h+i)^-1)h^H = tf.Tensor(\n",
      "[[[-0.02261004-0.03094581j -0.01871296+0.08829959j\n",
      "    0.07344877-0.08311186j  0.1191994 +0.16320157j]\n",
      "  [ 0.16523741-0.13618928j -0.06814785+0.05075144j\n",
      "    0.06236716-0.05515373j -0.00063102-0.07390185j]]\n",
      "\n",
      " [[-0.03628663+0.15267846j  0.17579031+0.12148435j\n",
      "    0.0079361 -0.08324968j -0.04709158-0.03492101j]\n",
      "  [-0.07331827-0.13905987j -0.03824792+0.10986055j\n",
      "   -0.11017823-0.117766j   -0.09201668+0.13470748j]]], shape=(2, 2, 4), dtype=complex64)\n",
      "x_hat_lmmse.shape = (2, 2)\n",
      "no_eff_lmmse shape = (2, 2)\n",
      "noise_var_eff_lmmse = 0.028204478\n",
      "noise_var_est_lmmse = 0.08991927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd8c6596c70>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# GPU Configuration and Imports\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "    \n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "# from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from sionna.utils import expand_to_rank, matrix_inv, matrix_pinv\n",
    "# from sionna.mimo.utils import whiten_channel\n",
    "from sionna.utils import matrix_sqrt_inv, expand_to_rank\n",
    "\n",
    "def whiten_channel(y, h, s, return_s=True):\n",
    "    # Compute whitening matrix\n",
    "    s_inv_1_2 = matrix_sqrt_inv(s)\n",
    "    s_inv_1_2 = expand_to_rank(s_inv_1_2, tf.rank(h), 0)\n",
    "\n",
    "    # Whiten obervation and channel matrix\n",
    "    yw = tf.expand_dims(y, -1)\n",
    "    yw = tf.matmul(s_inv_1_2, yw)\n",
    "    yw = tf.squeeze(yw, axis=-1)\n",
    "\n",
    "    hw = tf.matmul(s_inv_1_2, h)\n",
    "\n",
    "    if return_s:\n",
    "        # Ideal interference covariance matrix after whitening\n",
    "        sw = tf.eye(tf.shape(s)[-2], dtype=s.dtype)\n",
    "        sw = expand_to_rank(sw, tf.rank(s), 0)\n",
    "        return yw, hw, sw\n",
    "    else:\n",
    "        return yw, hw\n",
    "\n",
    "def lmmse_equalizer(y, h, s, whiten_interference=True):\n",
    "    if not whiten_interference:\n",
    "        # Compute G (G = H^H(HH^H + S}^-1).\n",
    "        print('H^H shape=',(np.linalg.pinv(h)).shape)\n",
    "        g = tf.matmul(h, h, adjoint_b=True) + s\n",
    "        print('H(H^H) shape=',(tf.matmul(h, h, adjoint_b=True)).shape)\n",
    "        print('H(H^H)+S shape=',g.shape)\n",
    "        print('(H(H^H)+S)^-1 shape',(matrix_inv(g)).shape)\n",
    "        g = tf.matmul(h, matrix_inv(g), adjoint_a=True)\n",
    "        print('H^H(H(H^H)+S)^-1 shape',g.shape)\n",
    "\n",
    "    else:\n",
    "        # Whiten channel\n",
    "        y, h  = whiten_channel(y, h, s, return_s=False) # type: ignore\n",
    "\n",
    "        # Compute G (G = ((H^H)H + i)^-1)H^H).\n",
    "        print('h =',h)\n",
    "        print('h^H =',np.linalg.pinv(h))\n",
    "        # print('h^H shape=',(np.linalg.pinv(h)).shape)\n",
    "        i = expand_to_rank(tf.eye(h.shape[-1], dtype=s.dtype), tf.rank(s), 0)\n",
    "        print('i =',i)\n",
    "        g = tf.matmul(h, h, adjoint_a=True) + i\n",
    "        print('(h^H)h =',tf.matmul(h, h, adjoint_a=True))\n",
    "        # print('(h^H)h shape=',(tf.matmul(h, h, adjoint_a=True)).shape)\n",
    "        print('(h^H)h+i =',g)\n",
    "        # print('(h^H)h+i shape=',g.shape)\n",
    "        print('((h^H)h+i)^-1 =',matrix_inv(g))\n",
    "        # print('((h^H)h+i)^-1 shape=',(matrix_inv(g)).shape)\n",
    "        g = tf.matmul(matrix_inv(g), h, adjoint_b=True)\n",
    "        print('(((h^H)h+i)^-1)h^H =',g)\n",
    "        # print('(((h^H)H+i)^-1)h^H shape=',g.shape)\n",
    "\n",
    "    # Compute Gy\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    gy = tf.squeeze(tf.matmul(g, y), axis=-1)\n",
    "\n",
    "    # Compute GH\n",
    "    gh = tf.matmul(g, h)\n",
    "\n",
    "    # Compute diag(GH)\n",
    "    d = tf.linalg.diag_part(gh)\n",
    "\n",
    "    # Compute x_hat (x_hat=(diag(GH)^-1)Gy)\n",
    "    x_hat = gy/d\n",
    "\n",
    "    # Compute residual error variance\n",
    "    one = tf.cast(1, dtype=d.dtype)\n",
    "    no_eff = tf.math.real(one/d - one)\n",
    "\n",
    "    return x_hat, no_eff\n",
    "\n",
    "def zf_equalizer(y, h, s):\n",
    "    # Compute G\n",
    "    g = matrix_pinv(h)\n",
    "\n",
    "    # Compute x_hat\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    x_hat = tf.squeeze(tf.matmul(g, y), axis=-1)\n",
    "\n",
    "    # Compute residual error variance\n",
    "    gsg = tf.matmul(tf.matmul(g, s), g, adjoint_b=True)\n",
    "    no_eff = tf.math.real(tf.linalg.diag_part(gsg))\n",
    "\n",
    "    return x_hat, no_eff\n",
    "\n",
    "def mf_equalizer(y, h, s):\n",
    "    # Compute G\n",
    "    hth = tf.matmul(h, h, adjoint_a=True)\n",
    "    d = tf.linalg.diag(tf.cast(1, h.dtype)/tf.linalg.diag_part(hth))\n",
    "    g = tf.matmul(d, h, adjoint_b=True)\n",
    "\n",
    "    # Compute x_hat\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    x_hat = tf.squeeze(tf.matmul(g, y), axis=-1)\n",
    "\n",
    "    # Compute residual error variance\n",
    "    gsg = tf.matmul(tf.matmul(g, s), g, adjoint_b=True)\n",
    "    gh = tf.matmul(g, h)\n",
    "    i = expand_to_rank(tf.eye(gsg.shape[-2], dtype=gsg.dtype), tf.rank(gsg), 0)\n",
    "\n",
    "    no_eff = tf.abs(tf.linalg.diag_part(tf.matmul(i-gh, i-gh, adjoint_b=True) + gsg))\n",
    "    return x_hat, no_eff\n",
    "\n",
    "# k = 512 # Block Length\n",
    "# no = 0.2 # Noise variance of the channel\n",
    "# NUM_TX_ANT = 4 # Transmit Antennas\n",
    "# NUM_RX_ANT = 16 # Receive Antennas\n",
    "# NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "# BATCH_SIZE = 8 # Parallelly Processed Batches\n",
    "# EBN0_DB_MIN = -30.0 # Minimum Eb/N0 [dB]\n",
    "# EBN0_DB_MAX = 10.0 # Maximum Eb/N0 [dB]\n",
    "# snrs = []\n",
    "# bers = []\n",
    "# sers_zf = []\n",
    "# sers_lmmse = []\n",
    "\n",
    "k = 8 # Block Length\n",
    "no = 0.2 # Noise variance of the channel\n",
    "NUM_TX_ANT = 2 # Transmit Antennas\n",
    "NUM_RX_ANT = 4 # Receive Antennas\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 1 # Parallelly Processed Batches\n",
    "EBN0_DB_MIN = -30.0 # Minimum Eb/N0 [dB]\n",
    "EBN0_DB_MAX = 10.0 # Maximum Eb/N0 [dB]\n",
    "snrs = []\n",
    "bers = []\n",
    "sers_zf = []\n",
    "sers_lmmse = []\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "\n",
    "# SymbolDemapper\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "\n",
    "y, h = flatfading_channel([x_reshape, no])\n",
    "print('y shape =',y.shape)\n",
    "# print('h =',h)\n",
    "print('h shape =',h.shape)\n",
    "\n",
    "s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "print('s =',s)\n",
    "print('tf.rank(s) =',tf.rank(s))\n",
    "\n",
    "x_hat_lmmse, no_eff_lmmse = lmmse_equalizer(y, h, s)\n",
    "print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "print('no_eff_lmmse shape =',no_eff_lmmse.shape)\n",
    "\n",
    "noise_var_eff_lmmse = np.var(x_reshape-x_hat_lmmse)\n",
    "noise_var_est_lmmse = np.mean(no_eff_lmmse)\n",
    "print('noise_var_eff_lmmse =',noise_var_eff_lmmse)\n",
    "print('noise_var_est_lmmse =',noise_var_est_lmmse)\n",
    "\n",
    "plt.axes().set_aspect(1.0)\n",
    "plt.scatter(np.real(x_hat_lmmse), np.imag(x_hat_lmmse))\n",
    "plt.scatter(np.real(x), np.imag(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SymbolDemapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 0\n",
      "x shape = (3, 2)\n",
      "y shape = (3, 4)\n",
      "h shape = (3, 4, 2)\n",
      "x_hat shape = (3, 2)\n",
      "no_eff shape = (3, 2)\n",
      "noise_var_eff = 0.098289706\n",
      "noise_var_est = 0.045822937\n",
      "exp = tf.Tensor(\n",
      "[[[-10.000001   -8.000001  -20.        -18.        -16.000002\n",
      "   -26.000002  -26.000002  -36.         -3.9999998  -2.\n",
      "    -2.         -0.        -10.000001  -20.         -8.000001\n",
      "   -18.       ]\n",
      "  [ -8.000001  -10.000001  -18.        -20.        -10.000001\n",
      "   -16.000002  -20.        -26.000002   -2.         -3.9999998\n",
      "    -0.         -2.         -4.0000005 -10.000001   -2.0000002\n",
      "    -8.000001 ]]\n",
      "\n",
      " [[ -2.         -3.9999998  -0.         -2.         -4.0000005\n",
      "   -10.000001   -2.0000002  -8.000001   -8.000001  -10.000001\n",
      "   -18.        -20.        -10.000001  -16.000002  -20.\n",
      "   -26.000002 ]\n",
      "  [ -3.9999998  -2.         -2.         -0.        -10.000001\n",
      "   -20.         -8.000001  -18.        -10.000001   -8.000001\n",
      "   -20.        -18.        -16.000002  -26.000002  -26.000002\n",
      "   -36.       ]]\n",
      "\n",
      " [[ -2.         -0.         -3.9999998  -2.         -8.000001\n",
      "   -18.        -10.000001  -20.         -4.0000005  -2.0000002\n",
      "   -10.000001   -8.000001  -10.000001  -20.        -16.000002\n",
      "   -26.000002 ]\n",
      "  [ -2.         -3.9999998  -0.         -2.         -4.0000005\n",
      "   -10.000001   -2.0000002  -8.000001   -8.000001  -10.000001\n",
      "   -18.        -20.        -10.000001  -16.000002  -20.\n",
      "   -26.000002 ]]], shape=(3, 2, 16), dtype=float32)\n",
      "tf.argmax(exp, axis=-1, output_type=tf.int32) = tf.Tensor(\n",
      "[[11 10]\n",
      " [ 2  3]\n",
      " [ 1  2]], shape=(3, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna\n",
    "\n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer\n",
    "# from sionna.mapping import SymbolDemapper\n",
    "from sionna.mapping import Constellation, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "\n",
    "class SymbolDemapper(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 constellation_type=None,\n",
    "                 num_bits_per_symbol=None,\n",
    "                 constellation=None,\n",
    "                 hard_out=False,\n",
    "                 with_prior=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self._hard_out = hard_out\n",
    "        self._with_prior = with_prior\n",
    " \n",
    "        # Create constellation object\n",
    "        self._constellation = Constellation.create_or_check_constellation(\n",
    "                                                        constellation_type,\n",
    "                                                        num_bits_per_symbol,\n",
    "                                                        constellation,\n",
    "                                                        dtype=dtype)\n",
    " \n",
    "    def call(self, inputs):\n",
    "        if self._with_prior:\n",
    "            y, prior, no = inputs\n",
    "        else:\n",
    "            y, no = inputs\n",
    "\n",
    "        # print('y =',y)\n",
    "        # print('y shape=',y.shape)\n",
    "        # print('tf.rank(y) =',tf.rank(y))\n",
    "        # print('tf.rank(y)+1 =',(tf.rank(y)+1))\n",
    "        # print('self._constellation.points =',self._constellation.points)\n",
    "        points = sn.utils.expand_to_rank(self._constellation.points,\n",
    "                                tf.rank(y)+1, axis=0)\n",
    "        # print('points =',points)\n",
    "        # print('points shape=',points.shape)\n",
    "\n",
    "        y = tf.expand_dims(y, axis=-1)\n",
    "        # print('y =',y)\n",
    "        # print('y shape=',y.shape)\n",
    "        d = tf.abs(y-points)\n",
    "        # print('d =',d)\n",
    "        # print('d shape=',d.shape)\n",
    " \n",
    "        no = sn.utils.expand_to_rank(no, tf.rank(d), axis=-1)\n",
    "        # print('no =',no)\n",
    "        # print('no shape=',no.shape)\n",
    "        exp = -d**2 / no\n",
    "        print('exp =',exp)\n",
    "        # print('exp shape=',exp.shape)\n",
    " \n",
    "        if self._with_prior:\n",
    "            prior = sn.utils.expand_to_rank(prior, tf.rank(exp), axis=0)\n",
    "            exp = exp + prior\n",
    " \n",
    "        if self._hard_out:\n",
    "            # tf.argmax: Get the Index of the maximum value in a tensor at the last dimension (axis=-1)\n",
    "            print('tf.argmax(exp, axis=-1, output_type=tf.int32) =',tf.argmax(exp, axis=-1, output_type=tf.int32))\n",
    "            # print('tf.argmax(exp, axis=-1, output_type=tf.int32) shape=',(tf.argmax(exp, axis=-1, output_type=tf.int32)).shape)\n",
    "            return tf.argmax(exp, axis=-1, output_type=tf.int32)\n",
    "        else:\n",
    "            # print('tf.nn.log_softmax(exp, axis=-1) =',tf.nn.log_softmax(exp, axis=-1))\n",
    "            print('tf.nn.log_softmax(exp, axis=-1) shape=',(tf.nn.log_softmax(exp, axis=-1)).shape)\n",
    "            return tf.nn.log_softmax(exp, axis=-1)\n",
    "        \n",
    "num_tx_ant = 2\n",
    "num_rx_ant = 4\n",
    "num_bits_per_symbol = 4\n",
    "batch_size = 3\n",
    "qam_source = QAMSource(num_bits_per_symbol)\n",
    "x = qam_source([batch_size, num_tx_ant])\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "channel = FlatFadingChannel(num_tx_ant, num_rx_ant, add_awgn=True, return_channel=True)\n",
    "no = 0.2 # Noise variance of the channel\n",
    "\n",
    "# y and h are the channel output and channel realizations, respectively.\n",
    "y, h = channel([x, no])\n",
    "print('y shape =',y.shape)\n",
    "print('h shape =',h.shape)\n",
    "\n",
    "s = tf.cast(no*tf.eye(num_rx_ant, num_rx_ant), y.dtype)\n",
    "x_hat, no_eff = lmmse_equalizer(y, h, s)\n",
    "print('x_hat shape =',x_hat.shape)\n",
    "\n",
    "plt.axes().set_aspect(1.0)\n",
    "plt.scatter(np.real(x_hat), np.imag(x_hat));\n",
    "plt.scatter(np.real(x), np.imag(x));\n",
    "\n",
    "print('no_eff shape =',no_eff.shape)\n",
    "\n",
    "noise_var_eff = np.var(x-x_hat)\n",
    "noise_var_est = np.mean(no_eff)\n",
    "print('noise_var_eff =',noise_var_eff)\n",
    "print('noise_var_est =',noise_var_est)\n",
    "\n",
    "symbol_demapper = SymbolDemapper(\"qam\", num_bits_per_symbol, hard_out=True)\n",
    "\n",
    "# Get symbol indices for the transmitted symbols\n",
    "x_ind = symbol_demapper([x, no])\n",
    "\n",
    "# # Get symbol indices for the received soft-symbols\n",
    "# x_ind_hat = symbol_demapper([x_hat, no])\n",
    "\n",
    "# compute_ser(x_ind, x_ind_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp_corr_mat & KroneckerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 0\n",
      "b shape = (1024, 4, 512)\n",
      "x shape = (1024, 4, 128)\n",
      "x_ind shape (1024, 4, 128)\n",
      "x reshape = (131072, 4)\n",
      "r_tx = tf.Tensor(\n",
      "[[1.        +0.j 0.4       -0.j 0.16000001-0.j 0.06400001-0.j]\n",
      " [0.4       +0.j 1.        +0.j 0.4       -0.j 0.16000001-0.j]\n",
      " [0.16000001+0.j 0.4       +0.j 1.        +0.j 0.4       -0.j]\n",
      " [0.06400001+0.j 0.16000001+0.j 0.4       +0.j 1.        +0.j]], shape=(4, 4), dtype=complex64)\n",
      "r_rx = tf.Tensor(\n",
      "[[1.        +0.j 0.9       -0.j 0.80999994-0.j 0.7289999 -0.j\n",
      "  0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j\n",
      "  0.4304671 -0.j 0.3874204 -0.j 0.34867835-0.j 0.3138105 -0.j\n",
      "  0.28242943-0.j 0.25418648-0.j 0.22876784-0.j 0.20589103-0.j]\n",
      " [0.9       +0.j 1.        +0.j 0.9       -0.j 0.80999994-0.j\n",
      "  0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j\n",
      "  0.47829682-0.j 0.4304671 -0.j 0.3874204 -0.j 0.34867835-0.j\n",
      "  0.3138105 -0.j 0.28242943-0.j 0.25418648-0.j 0.22876784-0.j]\n",
      " [0.80999994+0.j 0.9       +0.j 1.        +0.j 0.9       -0.j\n",
      "  0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j\n",
      "  0.5314409 -0.j 0.47829682-0.j 0.4304671 -0.j 0.3874204 -0.j\n",
      "  0.34867835-0.j 0.3138105 -0.j 0.28242943-0.j 0.25418648-0.j]\n",
      " [0.7289999 +0.j 0.80999994+0.j 0.9       +0.j 1.        +0.j\n",
      "  0.9       -0.j 0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j\n",
      "  0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j 0.4304671 -0.j\n",
      "  0.3874204 -0.j 0.34867835-0.j 0.3138105 -0.j 0.28242943-0.j]\n",
      " [0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j 0.9       +0.j\n",
      "  1.        +0.j 0.9       -0.j 0.80999994-0.j 0.7289999 -0.j\n",
      "  0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j\n",
      "  0.4304671 -0.j 0.3874204 -0.j 0.34867835-0.j 0.3138105 -0.j]\n",
      " [0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j\n",
      "  0.9       +0.j 1.        +0.j 0.9       -0.j 0.80999994-0.j\n",
      "  0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j\n",
      "  0.47829682-0.j 0.4304671 -0.j 0.3874204 -0.j 0.34867835-0.j]\n",
      " [0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j\n",
      "  0.80999994+0.j 0.9       +0.j 1.        +0.j 0.9       -0.j\n",
      "  0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j\n",
      "  0.5314409 -0.j 0.47829682-0.j 0.4304671 -0.j 0.3874204 -0.j]\n",
      " [0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j\n",
      "  0.7289999 +0.j 0.80999994+0.j 0.9       +0.j 1.        +0.j\n",
      "  0.9       -0.j 0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j\n",
      "  0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j 0.4304671 -0.j]\n",
      " [0.4304671 +0.j 0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j\n",
      "  0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j 0.9       +0.j\n",
      "  1.        +0.j 0.9       -0.j 0.80999994-0.j 0.7289999 -0.j\n",
      "  0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j 0.47829682-0.j]\n",
      " [0.3874204 +0.j 0.4304671 +0.j 0.47829682+0.j 0.5314409 +0.j\n",
      "  0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j\n",
      "  0.9       +0.j 1.        +0.j 0.9       -0.j 0.80999994-0.j\n",
      "  0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j 0.5314409 -0.j]\n",
      " [0.34867835+0.j 0.3874204 +0.j 0.4304671 +0.j 0.47829682+0.j\n",
      "  0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j\n",
      "  0.80999994+0.j 0.9       +0.j 1.        +0.j 0.9       -0.j\n",
      "  0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j 0.5904899 -0.j]\n",
      " [0.3138105 +0.j 0.34867835+0.j 0.3874204 +0.j 0.4304671 +0.j\n",
      "  0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j\n",
      "  0.7289999 +0.j 0.80999994+0.j 0.9       +0.j 1.        +0.j\n",
      "  0.9       -0.j 0.80999994-0.j 0.7289999 -0.j 0.6560999 -0.j]\n",
      " [0.28242943+0.j 0.3138105 +0.j 0.34867835+0.j 0.3874204 +0.j\n",
      "  0.4304671 +0.j 0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j\n",
      "  0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j 0.9       +0.j\n",
      "  1.        +0.j 0.9       -0.j 0.80999994-0.j 0.7289999 -0.j]\n",
      " [0.25418648+0.j 0.28242943+0.j 0.3138105 +0.j 0.34867835+0.j\n",
      "  0.3874204 +0.j 0.4304671 +0.j 0.47829682+0.j 0.5314409 +0.j\n",
      "  0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j 0.80999994+0.j\n",
      "  0.9       +0.j 1.        +0.j 0.9       -0.j 0.80999994-0.j]\n",
      " [0.22876784+0.j 0.25418648+0.j 0.28242943+0.j 0.3138105 +0.j\n",
      "  0.34867835+0.j 0.3874204 +0.j 0.4304671 +0.j 0.47829682+0.j\n",
      "  0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j 0.7289999 +0.j\n",
      "  0.80999994+0.j 0.9       +0.j 1.        +0.j 0.9       -0.j]\n",
      " [0.20589103+0.j 0.22876784+0.j 0.25418648+0.j 0.28242943+0.j\n",
      "  0.3138105 +0.j 0.34867835+0.j 0.3874204 +0.j 0.4304671 +0.j\n",
      "  0.47829682+0.j 0.5314409 +0.j 0.5904899 +0.j 0.6560999 +0.j\n",
      "  0.7289999 +0.j 0.80999994+0.j 0.9       +0.j 1.        +0.j]], shape=(16, 16), dtype=complex64)\n",
      "y shape = (131072, 16)\n",
      "h shape = (131072, 16, 4)\n",
      "x_hat_lmmse.shape = (131072, 4)\n",
      "no_eff_lmmse shape = (131072, 4)\n",
      "x_ind_hat_lmmse shape (1024, 4, 128)\n",
      "SER = tf.Tensor(0.0, shape=(), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc573be04f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras.layers import Layer\n",
    "# for performance measurements\n",
    "import time\n",
    "\n",
    "# GPU Configuration and Imports\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "    \n",
    "from sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\n",
    "# from sionna.channel import FlatFadingChannel, KroneckerModel\n",
    "from sionna.channel import FlatFadingChannel, SpatialCorrelation\n",
    "# from sionna.channel.utils import exp_corr_mat\n",
    "from sionna.mimo import lmmse_equalizer, zf_equalizer\n",
    "from sionna.mapping import SymbolDemapper, Mapper, Demapper\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.utils.misc import hard_decisions\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from sionna.utils import expand_to_rank, matrix_sqrt\n",
    "\n",
    "def exp_corr_mat(a, n, dtype=tf.complex64):\n",
    "\n",
    "    # Cast to desired output dtype and expand last dimension for broadcasting\n",
    "    a = tf.cast(a, dtype=dtype)\n",
    "    a = tf.expand_dims(a, -1)\n",
    " \n",
    "    # Check that a is valid\n",
    "    msg = \"The absolute value of the elements of `a` must be smaller than one\"\n",
    "    tf.debugging.assert_less(tf.abs(a), tf.cast(1, a.dtype.real_dtype), msg)\n",
    " \n",
    "    # Vector of exponents, adapt dtype and dimensions for broadcasting\n",
    "    exp = tf.range(0, n)\n",
    "    exp = tf.cast(exp, dtype=dtype)\n",
    "    exp = expand_to_rank(exp, tf.rank(a), 0)\n",
    " \n",
    "    # First column of R\n",
    "    col = tf.math.pow(a, exp)\n",
    " \n",
    "    # For a=0, one needs to remove the resulting nans due to 0**0=nan\n",
    "    cond = tf.math.is_nan(tf.math.real(col))\n",
    "    col = tf.where(cond, tf.ones_like(col), col)\n",
    " \n",
    "    # First row of R (equal to complex-conjugate of the first column)\n",
    "    row = tf.math.conj(col)\n",
    " \n",
    "    # Create Toeplitz operator\n",
    "    operator = tf.linalg.LinearOperatorToeplitz(col, row)\n",
    " \n",
    "    # Generate dense tensor from operator\n",
    "    r = operator.to_dense()\n",
    " \n",
    "    return r\n",
    "\n",
    "class KroneckerModel(SpatialCorrelation):\n",
    "    def __init__(self, r_tx=None, r_rx=None):\n",
    "        super().__init__()\n",
    "        self.r_tx = r_tx\n",
    "        self.r_rx = r_rx\n",
    " \n",
    "    @property\n",
    "    def r_tx(self):\n",
    "        return self._r_tx\n",
    " \n",
    "    @r_tx.setter\n",
    "    def r_tx(self, value):\n",
    "        self._r_tx = value\n",
    "        if self._r_tx is not None:\n",
    "            self._r_tx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_tx_sqrt = None\n",
    " \n",
    "    @property\n",
    "    def r_rx(self):\n",
    "        return self._r_rx\n",
    " \n",
    "    @r_rx.setter\n",
    "    def r_rx(self, value):\n",
    "        self._r_rx = value\n",
    "        if self._r_rx is not None:\n",
    "            self._r_rx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_rx_sqrt = None\n",
    " \n",
    "    def __call__(self, h):\n",
    "        if self._r_tx_sqrt is not None:\n",
    "            r_tx_sqrt = expand_to_rank(self._r_tx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(h, r_tx_sqrt, adjoint_b=True)\n",
    " \n",
    "        if self._r_rx_sqrt is not None:\n",
    "            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(r_rx_sqrt, h)\n",
    "        # print('h =',h)\n",
    "        return h\n",
    "\n",
    "k = 512 # Block Length\n",
    "no = 0.2 # Noise variance of the channel\n",
    "NUM_TX_ANT = 4 # Transmit Antennas\n",
    "NUM_RX_ANT = 16 # Receive Antennas\n",
    "NUM_BITS_PER_SYMBOL = 4 # 16 QAM\n",
    "BATCH_SIZE = 1024 # Parallelly Processed Batches\n",
    "EBN0_DB_MIN = -30.0 # Minimum Eb/N0 [dB]\n",
    "EBN0_DB_MAX = 10.0 # Maximum Eb/N0 [dB]\n",
    "snrs = []\n",
    "bers = []\n",
    "sers_zf = []\n",
    "sers_lmmse = []\n",
    "\n",
    "# Binary Source\n",
    "binary_source = sn.utils.BinarySource()\n",
    "\n",
    "# Constellation\n",
    "constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n",
    "#constellation.show(figsize=(7,7));\n",
    "\n",
    "# Mapper and Demapper\n",
    "mapper = sn.mapping.Mapper(constellation=constellation)\n",
    "# The demapper uses the same constellation object as the mapper\n",
    "demapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n",
    "\n",
    "# AWGN Channel\n",
    "awgn_channel = sn.channel.AWGN()\n",
    "\n",
    "# Flat Fading Channel\n",
    "# To simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`.\n",
    "flatfading_channel = FlatFadingChannel(NUM_TX_ANT, NUM_RX_ANT, add_awgn=True, return_channel=True)\n",
    "\n",
    "# SymbolDemapper\n",
    "symbol_demapper = SymbolDemapper(\"qam\", NUM_BITS_PER_SYMBOL, hard_out=True)\n",
    "\n",
    "b = binary_source([BATCH_SIZE,NUM_TX_ANT,k])\n",
    "print('b shape =',b.shape)\n",
    "\n",
    "x = mapper(b)\n",
    "print('x shape =',x.shape)\n",
    "\n",
    "x_ind = symbol_demapper([x, no])\n",
    "print('x_ind shape',x_ind.shape)\n",
    "\n",
    "shape = tf.shape(x)\n",
    "x_reshape = tf.reshape(x,[-1, NUM_TX_ANT])\n",
    "print('x reshape =',x_reshape.shape)\n",
    "\n",
    "# Adding Spatial Correlation\n",
    "# Create transmit and receive correlation matrices\n",
    "r_tx = exp_corr_mat(0.4, NUM_TX_ANT)\n",
    "r_rx = exp_corr_mat(0.9, NUM_RX_ANT)\n",
    "print('r_tx =',r_tx)\n",
    "print('r_rx =',r_rx)\n",
    "\n",
    "# Add the spatial correlation model to the channel\n",
    "flatfading_channel.spatial_corr = KroneckerModel(r_tx, r_rx)\n",
    "\n",
    "y, h = flatfading_channel([x_reshape, no])\n",
    "print('y shape =',y.shape)\n",
    "# print('h =',h)\n",
    "print('h shape =',h.shape)\n",
    "\n",
    "# Compute empirical covariance matrices\n",
    "r_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/NUM_RX_ANT\n",
    "r_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/NUM_TX_ANT\n",
    "\n",
    "# Test that the empirical results match the theory\n",
    "assert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\n",
    "assert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n",
    "\n",
    "s = tf.cast(no*tf.eye(NUM_RX_ANT, NUM_RX_ANT), y.dtype)\n",
    "\n",
    "x_hat_lmmse, no_eff_lmmse = lmmse_equalizer(y, h, s)\n",
    "print('x_hat_lmmse.shape =',x_hat_lmmse.shape)\n",
    "print('no_eff_lmmse shape =',no_eff_lmmse.shape)\n",
    "\n",
    "# Confirm the correctness of estimate x by comparing \n",
    "# the average estimated effective noise variance between \n",
    "# the transmitted and equalized symbols.\n",
    "noise_var_eff_lmmse = np.var(x_reshape-x_hat_lmmse)\n",
    "noise_var_est_lmmse = np.mean(no_eff_lmmse)\n",
    "# print('noise_var_eff_lmmse =',noise_var_eff_lmmse)\n",
    "# print('noise_var_est_lmmse =',noise_var_est_lmmse)\n",
    "\n",
    "x_hat_lmmse = tf.reshape(x_hat_lmmse, shape)\n",
    "\n",
    "x_ind_hat_lmmse = symbol_demapper([x_hat_lmmse, no])\n",
    "print('x_ind_hat_lmmse shape',x_ind_hat_lmmse.shape)\n",
    "\n",
    "print('SER =',compute_ser(x_ind, x_ind_hat_lmmse))\n",
    "\n",
    "plt.axes().set_aspect(1.0)\n",
    "plt.scatter(np.real(x_hat_lmmse), np.imag(x_hat_lmmse))\n",
    "plt.scatter(np.real(x), np.imag(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepImagePrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "class DeepImagePrior(object):\n",
    "    def __init__(self,user_num,M, iteration,LR,buffer_size,threshold,stop):\n",
    "        \n",
    "        self.user_num = user_num    ####number of transmitted symbol in real domain\n",
    "        self.M = M                  ####modulation order, 4 for 4qam, 16 for 16qam\n",
    "        self.iteration = iteration  ####number of max iterations used for DIP\n",
    "        self.LR = LR                ####Learning rate,  typically set to 0.01\n",
    "        self.buffer_size = buffer_size    ###iterations stored,  typically set to 30\n",
    "        self.threshold = threshold        ###Threshold of DIP stop,, typically set to 0.001\n",
    "        self.stop = stop                  ###True\n",
    "        constellation = np.linspace(int(-np.sqrt(M) + 1), int(np.sqrt(M) - 1), int(np.sqrt(M)))\n",
    "        alpha = np.sqrt((constellation ** 2).mean())\n",
    "        constellation /= (alpha * np.sqrt(2))\n",
    "        self.constellation = constellation\n",
    "        constellation_expanded = np.expand_dims(self.constellation, axis=1)\n",
    "        constellation_expanded= np.repeat(constellation_expanded[None,...],1,axis=0)\n",
    "        \n",
    "        constellation_expanded_transpose = np.repeat(constellation_expanded.transpose(0,2,1), self.user_num, axis=1)\n",
    "        \n",
    "        self.constellation_expanded =torch.from_numpy(constellation_expanded)\n",
    "        self.constellation_expanded_transpose = torch.from_numpy(constellation_expanded_transpose)\n",
    "\n",
    "    def QAM_const(self):\n",
    "        mod_n = self.M\n",
    "        sqrt_mod_n = np.int(np.sqrt(mod_n))\n",
    "        real_qam_consts = np.empty((mod_n), dtype=np.int64)\n",
    "        imag_qam_consts = np.empty((mod_n), dtype=np.int64)\n",
    "        for i in range(sqrt_mod_n):\n",
    "            for j in range(sqrt_mod_n):\n",
    "                    index = sqrt_mod_n*i + j\n",
    "                    real_qam_consts[index] = i\n",
    "                    imag_qam_consts[index] = j\n",
    "                    \n",
    "        return(self.constellation[real_qam_consts], self.constellation[imag_qam_consts])\n",
    "    \n",
    "    def ser(self,x_hat, x_true):\n",
    "        \n",
    "        real_QAM_const,imag_QAM_const = self.QAM_const()\n",
    "        x_real, x_imag = np.split(x_hat, 2, -1)\n",
    "        x_real = np.expand_dims(x_real,-1).repeat(real_QAM_const.size,-1)\n",
    "        x_imag = np.expand_dims(x_imag,-1).repeat(imag_QAM_const.size,-1)\n",
    "    \n",
    "        x_real = np.power(x_real - real_QAM_const, 2)\n",
    "        x_imag = np.power(x_imag - imag_QAM_const, 2)\n",
    "        x_dist = x_real + x_imag\n",
    "        estim_indices = np.argmin(x_dist, axis=-1)\n",
    "        \n",
    "        \n",
    "        x_real_true, x_imag_true = np.split(x_true, 2, -1)\n",
    "        x_real_true = np.expand_dims(x_real_true,-1).repeat(real_QAM_const.size,-1)\n",
    "        x_imag_true = np.expand_dims(x_imag_true,-1).repeat(imag_QAM_const.size,-1)\n",
    "    \n",
    "        x_real_true = np.power(x_real_true - real_QAM_const, 2)\n",
    "        x_imag_true = np.power(x_imag_true - imag_QAM_const, 2)\n",
    "        x_dist_true = x_real_true + x_imag_true\n",
    "        true_indices = np.argmin(x_dist_true, axis=-1)\n",
    "        \n",
    "         # estim_indices = joint_indices(x_hat_indices,constellation)\n",
    "        ser = np.sum(true_indices!=estim_indices)/true_indices.size\n",
    "        return ser\n",
    "\n",
    "\n",
    "    def DIP(self,Y,H):\n",
    "        \n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        dtype = torch.FloatTensor\n",
    "        batch_size = H.shape[0]\n",
    "        x_dip_ay = np.empty((batch_size,self.user_num))\n",
    "        num_stop_point = []\n",
    "        \n",
    "        for bs in range(batch_size):\n",
    "\n",
    "            i = 0            \n",
    "            flag = False\n",
    "            \n",
    "            net = Decoder(self.user_num).type(dtype)    ###Define the Neural network\n",
    "            mse = torch.nn.MSELoss().type(dtype)        ###Loss function\n",
    "            \n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr= self.LR)     ###Adam optimizer\n",
    "            net.apply(weight_reset)                     ###Reset the neural network parameters\n",
    "            net_input = torch.randn(1,4)                ###Random input for DIP\n",
    "            \n",
    "            y_torch = torch.from_numpy(Y[bs]).reshape(1,1,self.user_num,1).type(dtype)\n",
    "    \n",
    "            H_torch = torch.from_numpy(H[bs]).reshape(1, 1, self.user_num,self.user_num).type(dtype)\n",
    "            \n",
    "            variance_history = []\n",
    "            earlystop = EarlyStop(size= self.buffer_size)\n",
    "            \n",
    "            while i < self.iteration and flag==False :\n",
    "                \n",
    "                i+=1 \n",
    "                \n",
    "                # step 1, update network:\n",
    "                optimizer.zero_grad()\n",
    "                out = net(net_input).type(dtype)*np.max(self.constellation)\n",
    "                out1 = out.reshape(1,1,self.user_num,1).type(dtype)\n",
    "                Y_hat = torch.matmul(H_torch,out1).type(dtype)\n",
    "                total_loss = mse(Y_hat,y_torch)\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                x_dip = out.detach().cpu().numpy()\n",
    "               \n",
    "                if  self.stop is True:\n",
    "                    r_img_np = x_dip.reshape(-1)\n",
    "                    earlystop.update_img_collection(r_img_np)\n",
    "                    img_collection = earlystop.get_img_collection()\n",
    "                    if len(img_collection) ==  self.buffer_size:\n",
    "                        ave_img = np.mean(img_collection, axis=0)\n",
    "                        variance = []\n",
    "                        for tmp in img_collection:\n",
    "                            variance.append(earlystop.Var_cal(ave_img, tmp))\n",
    "                        cur_var = np.mean(variance)\n",
    "                        variance_history.append(cur_var)\n",
    "                    else:\n",
    "                        cur_var = 0\n",
    "                    \n",
    "                    if cur_var != 0 and cur_var <  self.threshold:\n",
    "                        num_stop_point.append(i)\n",
    "                        flag = True                \n",
    "                        \n",
    "            x_dip_ay[bs] = x_dip.reshape(-1)\n",
    "        \n",
    "        return x_dip_ay,num_stop_point\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,user_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nn1 = nn.Linear(4,8)\n",
    "        self.nn2 = nn.Linear(8,16)\n",
    "        self.nn3 = nn.Linear(16,32)\n",
    "        self.nn4 = nn.Linear(32,user_num)\n",
    "        self.act = nn.Tanh()\n",
    "         \n",
    "    def forward(self,x): \n",
    "        o1 = self.act(self.nn1(x)) \n",
    "        o2 = self.act(self.nn2(o1)) \n",
    "        o3 = self.act(self.nn3(o2)) \n",
    "        o4 = self.act(self.nn4(o3))  \n",
    "          \n",
    "        return o4    \n",
    "\n",
    "class EarlyStop():\n",
    "    def __init__(self, size):\n",
    "        self.img_collection = []\n",
    "        self.size = size\n",
    "\n",
    "    def update_img_collection(self, cur_img):\n",
    "        self.img_collection.append(cur_img)\n",
    "        if len(self.img_collection) > self.size:\n",
    "            self.img_collection.pop(0)\n",
    "    def get_img_collection(self):\n",
    "        return self.img_collection\n",
    "    def Var_cal(x1, x2):\n",
    "        return ((x1 - x2) ** 2).sum() / x1.size\n",
    "    \n",
    "    \n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters() \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
