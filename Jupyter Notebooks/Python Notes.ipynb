{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Jz6o4wZsGNKg","9Znw0gkAHE2h","BjO8c5_mf5eA","AOuFkkl-nDer","8_B310y21hYs"],"authorship_tag":"ABX9TyN1IojOiOHrvTxu+rE7TYTk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 16-Feb-2023"],"metadata":{"id":"oj67WU1rgCd6"}},{"cell_type":"markdown","source":["## 1. %matplotlib inline"],"metadata":{"id":"Jz6o4wZsGNKg"}},{"cell_type":"markdown","source":["\n","'**%matplotlib inline**' is a magic command in Python and Jupyter Notebook that enables the rendering of plots in the output cells of the notebook. When you use '**%matplotlib inline**', any plot that you create using Matplotlib will be displayed directly in the notebook, below the code cell that generated it.\n","\n","Without '**%matplotlib inline**', you would need to use the '**plt.show()**' method to display the plot in a separate window. However, when using Jupyter Notebook, this can disrupt the flow of the notebook and make it more difficult to read.\n","\n","The '**%matplotlib inline**' command sets the backend of Matplotlib to the inline backend, which allows plots to be displayed in the notebook output cells. It is important to note that this command needs to be executed before any Matplotlib plots are created in order to work properly."],"metadata":{"id":"1sEX_zDagcPc"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Create some data\n","x = [1, 2, 3, 4, 5]\n","y = [2, 4, 6, 8, 10]\n","\n","# Create a plot\n","plt.plot(x, y)\n","\n","# Display the plot inline in the notebook\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"qsplUWjxGPxI","executionInfo":{"status":"ok","timestamp":1676516459510,"user_tz":-660,"elapsed":321,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}},"outputId":"2999fcd3-a540-4cc8-fc7f-c46cca4ad388"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["In this example, we first import the Matplotlib library and then execute the %matplotlib inline command to enable inline plotting. We then create some data and use the plt.plot() method to create a plot. Finally, we use the plt.show() method to display the plot inline in the notebook."],"metadata":{"id":"iIvZ6IDDG13S"}},{"cell_type":"markdown","source":["## 2. %matplotlib widget"],"metadata":{"id":"9Znw0gkAHE2h"}},{"cell_type":"markdown","source":["The main difference between **%matplotlib widget** and **%matplotlib inline** is the way that the Matplotlib plots are displayed in the Jupyter Notebook.\n","\n","With **%matplotlib inline**, the plots are displayed as *static images* directly in the output cells of the notebook. This means that the plots cannot be interacted with, and the user cannot modify or explore the data in the plot.\n","\n","On the other hand, **%matplotlib widget** enables **interactive plots** within the Jupyter Notebook, allowing users to zoom, pan, and explore the data in the plot. When using %matplotlib widget, the plots are rendered using the ipympl library, which provides an interactive backend for Matplotlib."],"metadata":{"id":"bVjy2xxxgjFo"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import os\n","os.system(\"pip install ipympl\")\n","%matplotlib widget\n","\n","# Create some data\n","x = [1, 2, 3, 4, 5]\n","y = [2, 4, 6, 8, 10]\n","\n","# Create a plot\n","plt.plot(x, y)\n","\n","# Display the plot interactively in the notebook\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":482},"id":"iz4F00wRHGnY","executionInfo":{"status":"error","timestamp":1676517211022,"user_tz":-660,"elapsed":3888,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}},"outputId":"00d61f46-39b6-4974-e0f6-39b6d5cc9b37"},"execution_count":17,"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-da2b1f83e0d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create a plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Display the plot interactively in the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m     return gca().phase_spectrum(\n\u001b[1;32m   2760\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2761\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mgca\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mgcf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;31m# This figure will not be shown immediately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;31m# interactive mode will be on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[0;34m(cls, num, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m         \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_window_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Subplot configuration tool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3357\u001b[0m         \u001b[0mtool_fig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3358\u001b[0;31m         \u001b[0mtool_fig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3359\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot_tool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubplotTool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_fig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m         cid = self.canvas.mpl_connect(\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipympl/backend_nbagg.py\u001b[0m in \u001b[0;36mnew_figure_manager_given_figure\u001b[0;34m(num, figure)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'nbagg.transparent'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrcParams\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nbagg.transparent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFigureManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipympl/backend_nbagg.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, canvas, num)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mFigureManagerWebAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweb_sockets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoolbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToolbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipympl/backend_nbagg.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, canvas, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mDOMWidget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mNavigationToolbar2WebAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_webagg_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, canvas)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, canvas)\u001b[0m\n\u001b[1;32m   2706\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m     \u001b[0;31m# toggle scaling of x-axes between 'log and 'linear' (default key 'k')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoggle_xscale_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m         \u001b[0mscalex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_init_toolbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mKey\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmouse\u001b[0m \u001b[0mbutton\u001b[0m \u001b[0mpress\u001b[0m \u001b[0mhandling\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2771\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2772\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0msets\u001b[0m \u001b[0mup\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmouse\u001b[0m \u001b[0mbutton\u001b[0m \u001b[0mpress\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m     \u001b[0mhooking\u001b[0m \u001b[0mup\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_press_handler\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0mevent\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: "]}]},{"cell_type":"markdown","source":["In this example, we import the Matplotlib library and then execute the %matplotlib widget command to enable interactive plotting. We then create some data and use the plt.plot() method to create a plot. Finally, we use the plt.show() method to display the plot interactively in the notebook.\n","\n","It's important to note that %matplotlib widget requires a compatible backend, and may not work in all environments. Additionally, because interactive plots can be resource-intensive, they may be slower to render than static plots created using %matplotlib inline."],"metadata":{"id":"4mCGc7ZcHjf7"}},{"cell_type":"markdown","source":["## 3. run bash commands with !"],"metadata":{"id":"BjO8c5_mf5eA"}},{"cell_type":"code","source":["!pip install ipympl"],"metadata":{"id":"GTAEZ7vjWSoG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. sionna.mapping"],"metadata":{"id":"TjZlsFREg7Qv"}},{"cell_type":"markdown","source":["### 4.1 sn.mapping"],"metadata":{"id":"AOuFkkl-nDer"}},{"cell_type":"code","source":["#\n","# SPDX-FileCopyrightText: Copyright (c) 2021-2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n","# SPDX-License-Identifier: Apache-2.0\n","#\n","\"\"\"Layers for (de)mapping, constellation class, and utility functions\"\"\"\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Layer\n","import matplotlib.pyplot as plt\n","\n","import sionna as sn\n","\n","\n","\n","def pam_gray(b):\n","    # pylint: disable=line-too-long\n","    r\"\"\"Maps a vector of bits to a PAM constellation points with Gray labeling.\n","\n","    This recursive function maps a binary vector to Gray-labelled PAM\n","    constellation points. It can be used to generated QAM constellations.\n","    The constellation is not normalized.\n","\n","    Input\n","    -----\n","    b : [n], NumPy array\n","        Tensor with with binary entries.\n","\n","    Output\n","    ------\n","    : signed int\n","        The PAM constellation point taking values in\n","        :math:`\\{\\pm 1,\\pm 3,\\dots,\\pm (2^n-1)\\}`.\n","\n","    Note\n","    ----\n","    This algorithm is a recursive implementation of the expressions found in\n","    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n","    \"\"\" # pylint: disable=C0301\n","\n","    if len(b)>1:\n","        return (1-2*b[0])*(2**len(b[1:]) - pam_gray(b[1:]))\n","    return 1-2*b[0]\n","\n","\n","\n","\n","def qam(num_bits_per_symbol, normalize=True):\n","    r\"\"\"Generates a QAM constellation.\n","\n","    This function generates a complex-valued vector, where each element is\n","    a constellation point of an M-ary QAM constellation. The bit\n","    label of the ``n`` th point is given by the length-``num_bits_per_symbol``\n","    binary represenation of ``n``.\n","\n","    Input\n","    -----\n","    num_bits_per_symbol : int\n","        The number of bits per constellation point.\n","        Must be a multiple of two, e.g., 2, 4, 6, 8, etc.\n","\n","    normalize: bool\n","        If `True`, the constellation is normalized to have unit power.\n","        Defaults to `True`.\n","\n","    Output\n","    ------\n","    : :math:`[2^{\\text{num_bits_per_symbol}}]`, np.complex64\n","        The QAM constellation.\n","\n","    Note\n","    ----\n","    The bit label of the nth constellation point is given by the binary\n","    representation of its position within the array and can be obtained\n","    through ``np.binary_repr(n, num_bits_per_symbol)``.\n","\n","\n","    The normalization factor of a QAM constellation is given in\n","    closed-form as:\n","\n","    .. math::\n","        \\sqrt{\\frac{1}{2^{n-2}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n","\n","    where :math:`n= \\text{num_bits_per_symbol}/2` is the number of bits\n","    per dimension.\n","\n","    This algorithm is a recursive implementation of the expressions found in\n","    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n","    \"\"\" # pylint: disable=C0301\n","\n","    try:\n","        assert num_bits_per_symbol % 2 == 0 # is even\n","        assert num_bits_per_symbol >0 # is larger than zero\n","    except AssertionError as error:\n","        raise ValueError(\"num_bits_per_symbol must be a multiple of 2\") \\\n","        from error\n","    assert isinstance(normalize, bool), \"normalize must be boolean\"\n","\n","    # Build constellation by iterating through all points\n","    c = np.zeros([2**num_bits_per_symbol], dtype=np.complex64)\n","    for i in range(0, 2**num_bits_per_symbol):\n","        b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n","                     dtype=np.int16)\n","        c[i] = pam_gray(b[0::2]) + 1j*pam_gray(b[1::2]) # PAM in each dimension\n","\n","    if normalize: # Normalize to unit energy\n","        n = int(num_bits_per_symbol/2)\n","        qam_var = 1/(2**(n-2))*np.sum(np.linspace(1,2**n-1, 2**(n-1))**2)\n","        c /= np.sqrt(qam_var)\n","    return c\n","\n","\n","\n","\n","def pam(num_bits_per_symbol, normalize=True):\n","    r\"\"\"Generates a PAM constellation.\n","\n","    This function generates a real-valued vector, where each element is\n","    a constellation point of an M-ary PAM constellation. The bit\n","    label of the ``n`` th point is given by the length-``num_bits_per_symbol``\n","    binary represenation of ``n``.\n","\n","    Input\n","    -----\n","    num_bits_per_symbol : int\n","        The number of bits per constellation point.\n","        Must be positive.\n","\n","    normalize: bool\n","        If `True`, the constellation is normalized to have unit power.\n","        Defaults to `True`.\n","\n","    Output\n","    ------\n","    : :math:`[2^{\\text{num_bits_per_symbol}}]`, np.float32\n","        The PAM constellation.\n","\n","    Note\n","    ----\n","    The bit label of the nth constellation point is given by the binary\n","    representation of its position within the array and can be obtained\n","    through ``np.binary_repr(n, num_bits_per_symbol)``.\n","\n","\n","    The normalization factor of a PAM constellation is given in\n","    closed-form as:\n","\n","    .. math::\n","        \\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n","\n","    where :math:`n= \\text{num_bits_per_symbol}` is the number of bits\n","    per symbol.\n","\n","    This algorithm is a recursive implementation of the expressions found in\n","    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n","    \"\"\" # pylint: disable=C0301\n","\n","    try:\n","        assert num_bits_per_symbol >0 # is larger than zero\n","    except AssertionError as error:\n","        raise ValueError(\"num_bits_per_symbol must be positive\") \\\n","        from error\n","    assert isinstance(normalize, bool), \"normalize must be boolean\"\n","\n","    # Build constellation by iterating through all points\n","    c = np.zeros([2**num_bits_per_symbol], dtype=np.float32)\n","    for i in range(0, 2**num_bits_per_symbol):\n","        b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n","                     dtype=np.int16)\n","        c[i] = pam_gray(b)\n","\n","    if normalize: # Normalize to unit energy\n","        n = int(num_bits_per_symbol)\n","        pam_var = 1/(2**(n-1))*np.sum(np.linspace(1,2**n-1, 2**(n-1))**2)\n","        c /= np.sqrt(pam_var)\n","    return c\n","\n","\n","\n","\n","class Constellation(Layer):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    Constellation(constellation_type, num_bits_per_symbol, initial_value=None, normalize=True, center=False, trainable=False, dtype=tf.complex64, **kwargs)\n","\n","    Constellation that can be used by a (de)mapper.\n","\n","    This class defines a constellation, i.e., a complex-valued vector of\n","    constellation points. A constellation can be trainable. The binary\n","    representation of the index of an element of this vector corresponds\n","    to the bit label of the constellation point. This implicit bit\n","    labeling is used by the ``Mapper`` and ``Demapper`` classes.\n","\n","    Parameters\n","    ----------\n","    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","        For \"custom\", the constellation points are randomly initialized\n","        if no ``initial_value`` is provided.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","\n","    initial_value : :math:`[2^\\text{num_bits_per_symbol}]`, NumPy array or Tensor\n","        Initial values of the constellation points. If ``normalize`` or\n","        ``center`` are `True`, the initial constellation might be changed.\n","\n","    normalize : bool\n","        If `True`, the constellation is normalized to have unit power.\n","        Defaults to `True`.\n","\n","    center : bool\n","        If `True`, the constellation is ensured to have zero mean.\n","        Defaults to `False`.\n","\n","    trainable : bool\n","        If `True`, the constellation points are trainable variables.\n","        Defaults to `False`.\n","\n","    dtype : [tf.complex64, tf.complex128], tf.DType\n","        The dtype of the constellation.\n","\n","    Output\n","    ------\n","    : :math:`[2^\\text{num_bits_per_symbol}]`, ``dtype``\n","        The constellation.\n","\n","    Note\n","    ----\n","    One can create a trainable PAM/QAM constellation. This is\n","    equivalent to creating a custom trainable constellation which is\n","    initialized with PAM/QAM constellation points.\n","    \"\"\"\n","    # pylint: enable=C0301\n","\n","    def __init__(self,\n","                 constellation_type,\n","                 num_bits_per_symbol,\n","                 initial_value=None,\n","                 normalize=True,\n","                 center=False,\n","                 trainable=False,\n","                 dtype=tf.complex64,\n","                 **kwargs):\n","        super().__init__(**kwargs)\n","        assert dtype in [tf.complex64, tf.complex128],\\\n","            \"dtype must be tf.complex64 or tf.complex128\"\n","        self._dtype = dtype\n","\n","        assert constellation_type in (\"qam\", \"pam\", \"custom\"),\\\n","            \"Wrong constellation type\"\n","        self._constellation_type = constellation_type\n","\n","        assert isinstance(normalize, bool), \"normalize must be boolean\"\n","        self._normalize = normalize\n","\n","        assert isinstance(center, bool), \"center must be boolean\"\n","        self._center = center\n","\n","        assert isinstance(trainable, bool), \"trainable must be boolean\"\n","        self._trainable = trainable\n","\n","        # allow float inputs that represent int\n","        assert isinstance(num_bits_per_symbol, (float,int)),\\\n","            \"num_bits_per_symbol must be integer\"\n","        assert (num_bits_per_symbol%1==0),\\\n","            \"num_bits_per_symbol must be integer\"\n","        num_bits_per_symbol = int(num_bits_per_symbol)\n","\n","        if self._constellation_type==\"qam\":\n","            assert num_bits_per_symbol%2 == 0 and num_bits_per_symbol>0,\\\n","                \"num_bits_per_symbol must be a multiple of 2\"\n","            self._num_bits_per_symbol = int(num_bits_per_symbol)\n","\n","            assert initial_value is None, \"QAM must not have an initial value\"\n","            points = qam(self._num_bits_per_symbol, normalize=self.normalize)\n","            points = tf.cast(points, self._dtype)\n","\n","        if self._constellation_type==\"pam\":\n","            assert num_bits_per_symbol>0,\\\n","                \"num_bits_per_symbol must be integer\"\n","            self._num_bits_per_symbol = int(num_bits_per_symbol)\n","\n","            assert initial_value is None, \"PAM must not have an initial value\"\n","            points = pam(self._num_bits_per_symbol, normalize=self.normalize)\n","            points = tf.cast(points, self._dtype)\n","\n","        if self._constellation_type==\"custom\":\n","            assert num_bits_per_symbol>0,\\\n","                \"num_bits_per_symbol must be integer\"\n","            self._num_bits_per_symbol = int(num_bits_per_symbol)\n","\n","            # Randomly initialize points if no initial_value is provided\n","            if initial_value is None:\n","                points = tf.random.uniform(  # pylint: disable=E1123\n","                                        [2, 2**self._num_bits_per_symbol],\n","                                        minval=-0.05, maxval=0.05,\n","                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n","                points  = tf.complex(points[0], points[1])\n","            else:\n","                assert tf.rank(initial_value).numpy() == 1\n","                assert tf.shape(initial_value)[0] == 2**num_bits_per_symbol,\\\n","                    \"initial_value must have shape [2**num_bits_per_symbol]\"\n","                points = tf.cast(initial_value, self._dtype)\n","        self._points = points\n","\n","    def build(self, input_shape): #pylint: disable=unused-argument\n","        points = self._points\n","        points = tf.stack([tf.math.real(points),\n","                           tf.math.imag(points)], axis=0)\n","        if self._trainable:\n","            self._points = tf.Variable(points,\n","                                       trainable=self._trainable,\n","                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n","        else:\n","            self._points = tf.constant(points,\n","                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n","\n","    # pylint: disable=no-self-argument\n","\n","\n","    def create_or_check_constellation(  constellation_type=None,\n","                                        num_bits_per_symbol=None,\n","                                        constellation=None,\n","                                        dtype=tf.complex64):\n","        # pylint: disable=line-too-long\n","        r\"\"\"Static method for conviently creating a constellation object or checking that an existing one\n","        is consistent with requested settings.\n","\n","        If ``constellation`` is `None`, then this method creates a :class:`~sionna.mapping.Constellation`\n","        object of type ``constellation_type`` and with ``num_bits_per_symbol`` bits per symbol.\n","        Otherwise, this method checks that `constellation` is consistent with ``constellation_type`` and\n","        ``num_bits_per_symbol``. If it is, ``constellation`` is returned. Otherwise, an assertion is raised.\n","\n","        Input\n","        ------\n","        constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","            For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n","            must be provided.\n","\n","        num_bits_per_symbol : int\n","            The number of bits per constellation symbol, e.g., 4 for QAM16.\n","            Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n","\n","        constellation :  Constellation\n","            An instance of :class:`~sionna.mapping.Constellation` or\n","            `None`. In the latter case, ``constellation_type``\n","            and ``num_bits_per_symbol`` must be provided.\n","\n","        Output\n","        -------\n","        : :class:`~sionna.mapping.Constellation`\n","            A constellation object.\n","        \"\"\"\n","        constellation_object = None\n","        if constellation is not None:\n","            assert constellation_type in [None, \"custom\"], \\\n","                \"\"\"`constellation_type` must be \"custom\".\"\"\"\n","            assert num_bits_per_symbol in \\\n","                     [None, constellation.num_bits_per_symbol], \\\n","                \"\"\"`Wrong value of `num_bits_per_symbol.`\"\"\"\n","            assert constellation.dtype==dtype, \\\n","                \"Constellation has wrong dtype.\"\n","            constellation_object = constellation\n","        else:\n","            assert constellation_type in [\"qam\", \"pam\"], \\\n","                \"Wrong constellation type.\"\n","            assert num_bits_per_symbol is not None, \\\n","                \"`num_bits_per_symbol` must be provided.\"\n","            constellation_object = Constellation(   constellation_type,\n","                                                    num_bits_per_symbol,\n","                                                    dtype=dtype)\n","        return constellation_object\n","\n","\n","    def call(self, inputs): #pylint: disable=unused-argument\n","        x = self._points\n","        x = tf.complex(x[0], x[1])\n","        if self._center:\n","            x = x - tf.reduce_mean(x)\n","        if self._normalize:\n","            energy = tf.reduce_mean(tf.square(tf.abs(x)))\n","            energy_sqrt = tf.cast(tf.sqrt(energy), self._dtype)\n","            x = x / energy_sqrt\n","        return x\n","\n","    @property\n","    def normalize(self):\n","        \"\"\"Indicates if the constellation is normalized or not.\"\"\"\n","        return self._normalize\n","\n","    @normalize.setter\n","    def normalize(self, value):\n","        assert isinstance(value, bool), \"`normalize` must be boolean\"\n","        self._normalize = value\n","\n","    @property\n","    def center(self):\n","        \"\"\"Indicates if the constellation is centered.\"\"\"\n","        return self._center\n","\n","    @center.setter\n","    def center(self, value):\n","        assert isinstance(value, bool), \"`center` must be boolean\"\n","        self._center = value\n","\n","    @property\n","    def num_bits_per_symbol(self):\n","        \"\"\"The number of bits per constellation symbol.\"\"\"\n","        return self._num_bits_per_symbol\n","\n","    @property\n","    def points(self):\n","        \"\"\"The (possibly) centered and normalized constellation points.\"\"\"\n","        return self(None)\n","\n","\n","\n","    def show(self, labels=True, figsize=(7,7)):\n","        \"\"\"Generate a scatter-plot of the constellation.\n","\n","        Input\n","        -----\n","        labels : bool\n","            If `True`, the bit labels will be drawn next to each constellation\n","            point. Defaults to `True`.\n","\n","        figsize : Two-element Tuple, float\n","            Width and height in inches. Defaults to `(7,7)`.\n","\n","        Output\n","        ------\n","        : matplotlib.figure.Figure\n","            A handle to a matplot figure object.\n","        \"\"\"\n","        maxval = np.max(np.abs(self.points))*1.05\n","        fig = plt.figure(figsize=figsize)\n","        ax = fig.add_subplot(111)\n","        plt.xlim(-maxval, maxval)\n","        plt.ylim(-maxval, maxval)\n","        plt.scatter(np.real(self.points), np.imag(self.points))\n","        ax.set_aspect(\"equal\", adjustable=\"box\")\n","        plt.xlabel(\"Real Part\")\n","        plt.ylabel(\"Imaginary Part\")\n","        plt.grid(True, which=\"both\", axis=\"both\")\n","        plt.title(\"Constellation Plot\")\n","        if labels is True:\n","            for j, p in enumerate(self.points.numpy()):\n","                plt.annotate(\n","                    np.binary_repr(j, self.num_bits_per_symbol),\n","                    (np.real(p), np.imag(p))\n","                )\n","        return fig\n","\n","\n","\n","\n","class Mapper(Layer):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, return_indices=False, dtype=tf.complex64, **kwargs)\n","\n","    Maps binary tensors to points of a constellation.\n","\n","    This class defines a layer that maps a tensor of binary values\n","    to a tensor of points from a provided constellation.\n","\n","    Parameters\n","    ----------\n","    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n","        must be provided.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n","\n","    constellation :  Constellation\n","        An instance of :class:`~sionna.mapping.Constellation` or\n","        `None`. In the latter case, ``constellation_type``\n","        and ``num_bits_per_symbol`` must be provided.\n","\n","    return_indices : bool\n","        If enabled, symbol indices are additionally returned.\n","        Defaults to `False`.\n","\n","    dtype : One of [tf.complex64, tf.complex128], tf.DType\n","        The output dtype. Defaults to tf.complex64.\n","\n","    Input\n","    -----\n","    : [..., n], tf.float or tf.int\n","        Tensor with with binary entries.\n","\n","    Output\n","    ------\n","    : [...,n/Constellation.num_bits_per_symbol], tf.complex\n","        The mapped constellation symbols.\n","\n","    : [...,n/Constellation.num_bits_per_symbol], tf.int32\n","        The symbol indices corresponding to the constellation symbols.\n","        Only returned if ``return_indices`` is set to True.\n","\n","\n","    Note\n","    ----\n","    The last input dimension must be an integer multiple of the\n","    number of bits per constellation symbol.\n","    \"\"\"\n","    def __init__(self,\n","                 constellation_type=None,\n","                 num_bits_per_symbol=None,\n","                 constellation=None,\n","                 return_indices=False,\n","                 dtype=tf.complex64,\n","                 **kwargs\n","                ):\n","        super().__init__(dtype=dtype, **kwargs)\n","        assert dtype in [tf.complex64, tf.complex128],\\\n","            \"dtype must be tf.complex64 or tf.complex128\"\n","\n","        # Create constellation object\n","        self._constellation = Constellation.create_or_check_constellation(\n","                                                        constellation_type,\n","                                                        num_bits_per_symbol,\n","                                                        constellation,\n","                                                        dtype=dtype)\n","\n","        self._return_indices = return_indices\n","\n","        self._binary_base = 2**tf.constant(\n","                        range(self.constellation.num_bits_per_symbol-1,-1,-1))\n","\n","    @property\n","    def constellation(self):\n","        \"\"\"The Constellation used by the Mapper.\"\"\"\n","        return self._constellation\n","\n","    def call(self, inputs):\n","        tf.debugging.assert_greater_equal(tf.rank(inputs), 2,\n","            message=\"The input must have at least rank 2\")\n","\n","        # Reshape inputs to the desired format\n","        new_shape = [-1] + inputs.shape[1:-1].as_list() + \\\n","           [int(inputs.shape[-1] / self.constellation.num_bits_per_symbol),\n","            self.constellation.num_bits_per_symbol]\n","        inputs_reshaped = tf.cast(tf.reshape(inputs, new_shape), tf.int32)\n","\n","        # Convert the last dimension to an integer\n","        int_rep = tf.reduce_sum(inputs_reshaped * self._binary_base, axis=-1)\n","\n","        # Map integers to constellation symbols\n","        x = tf.gather(self.constellation.points, int_rep, axis=0)\n","\n","        if self._return_indices:\n","            return x, int_rep\n","        else:\n","            return x\n","\n","\n","\n","\n","class SymbolLogits2LLRs(Layer):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    SymbolLogits2LLRs(method, num_bits_per_symbol, hard_out=False, with_prior=False, dtype=tf.float32, **kwargs)\n","\n","    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n","    from a tensor of logits (i.e., unnormalized log-probabilities) on constellation points.\n","    If the flag ``with_prior`` is set, prior knowledge on the bits is assumed to be available.\n","\n","    Parameters\n","    ----------\n","    method : One of [\"app\", \"maxlog\"], str\n","        The method used for computing the LLRs.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","\n","    hard_out : bool\n","        If `True`, the layer provides hard-decided bits instead of soft-values.\n","        Defaults to `False`.\n","\n","    with_prior : bool\n","        If `True`, it is assumed that prior knowledge on the bits is available.\n","        This prior information is given as LLRs as an additional input to the layer.\n","        Defaults to `False`.\n","\n","    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n","        The dtype for the input and output.\n","        Defaults to `tf.float32`.\n","\n","    Input\n","    -----\n","    logits or (logits, prior):\n","        Tuple:\n","\n","    logits : [...,n, num_points], tf.float\n","        Logits on constellation points.\n","\n","    prior : [num_bits_per_symbol] or [...n, num_bits_per_symbol], tf.float\n","        Prior for every bit as LLRs.\n","        It can be provided either as a tensor of shape `[num_bits_per_symbol]`\n","        for the entire input batch, or as a tensor that is \"broadcastable\"\n","        to `[..., n, num_bits_per_symbol]`.\n","        Only required if the ``with_prior`` flag is set.\n","\n","    Output\n","    ------\n","    : [...,n, num_bits_per_symbol], tf.float\n","        LLRs or hard-decisions for every bit.\n","\n","    Note\n","    ----\n","    With the \"app\" method, the LLR for the :math:`i\\text{th}` bit\n","    is computed according to\n","\n","    .. math::\n","        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert \\mathbf{z},\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert \\mathbf{z},\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n","                \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                e^{z_c}\n","                }{\n","                \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                e^{z_c}\n","                }\\right)\n","\n","    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n","    sets of :math:`2^K` constellation points for which the :math:`i\\text{th}` bit is\n","    equal to 1 and 0, respectively. :math:`\\mathbf{z} = \\left[z_{c_0},\\dots,z_{c_{2^K-1}}\\right]` is the vector of logits on the constellation points, :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]`\n","    is the vector of LLRs that serves as prior knowledge on the :math:`K` bits that are mapped to\n","    a constellation point and is set to :math:`\\mathbf{0}` if no prior knowledge is assumed to be available,\n","    and :math:`\\Pr(c\\lvert\\mathbf{p})` is the prior probability on the constellation symbol :math:`c`:\n","\n","    .. math::\n","        \\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert\\mathbf{p} \\right)\n","        = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n","\n","    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where 0 is\n","    replaced by -1.\n","    The definition of the LLR has been\n","    chosen such that it is equivalent with that of logits. This is\n","    different from many textbooks in communications, where the LLR is\n","    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n","\n","    With the \"maxlog\" method, LLRs for the :math:`i\\text{th}` bit\n","    are approximated like\n","\n","    .. math::\n","        \\begin{align}\n","            LLR(i) &\\approx\\ln\\left(\\frac{\n","                \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                    e^{z_c}\n","                }{\n","                \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                    e^{z_c}\n","                }\\right)\n","                .\n","        \\end{align}\n","    \"\"\"\n","    def __init__(self,\n","                 method,\n","                 num_bits_per_symbol,\n","                 hard_out=False,\n","                 with_prior=False,\n","                 dtype=tf.float32,\n","                 **kwargs):\n","        super().__init__(dtype=dtype, **kwargs)\n","        assert method in (\"app\",\"maxlog\"), \"Unknown demapping method\"\n","        self._method = method\n","        self._hard_out = hard_out\n","        self._num_bits_per_symbol = num_bits_per_symbol\n","        self._with_prior = with_prior\n","        num_points = int(2**num_bits_per_symbol)\n","\n","        # Array composed of binary representations of all symbols indices\n","        a = np.zeros([num_points, num_bits_per_symbol])\n","        for i in range(0, num_points):\n","            a[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n","                              dtype=np.int16)\n","\n","        # Compute symbol indices for which the bits are 0 or 1\n","        c0 = np.zeros([int(num_points/2), num_bits_per_symbol])\n","        c1 = np.zeros([int(num_points/2), num_bits_per_symbol])\n","        for i in range(num_bits_per_symbol-1,-1,-1):\n","            c0[:,i] = np.where(a[:,i]==0)[0]\n","            c1[:,i] = np.where(a[:,i]==1)[0]\n","        self._c0 = tf.constant(c0, dtype=tf.int32) # Symbols with ith bit=0\n","        self._c1 = tf.constant(c1, dtype=tf.int32) # Symbols with ith bit=1\n","\n","        if with_prior:\n","            # Array of labels from {-1, 1} of all symbols\n","            # [num_points, num_bits_per_symbol]\n","            a = 2*a-1\n","            self._a = tf.constant(a, dtype=dtype)\n","\n","        # Determine the reduce function for LLR computation\n","        if self._method == \"app\":\n","            self._reduce = tf.reduce_logsumexp\n","        else:\n","            self._reduce = tf.reduce_max\n","\n","    @property\n","    def num_bits_per_symbol(self):\n","        return self._num_bits_per_symbol\n","\n","    def call(self, inputs):\n","        if self._with_prior:\n","            logits, prior = inputs\n","        else:\n","            logits = inputs\n","\n","        # Compute exponents\n","        exponents = logits\n","\n","        # Gather exponents for all bits\n","        # shape [...,n,num_points/2,num_bits_per_symbol]\n","        exp0 = tf.gather(exponents, self._c0, axis=-1, batch_dims=0)\n","        exp1 = tf.gather(exponents, self._c1, axis=-1, batch_dims=0)\n","\n","        # Process the prior information\n","        if self._with_prior:\n","            # Expanding `prior` such that it is broadcastable with\n","            # shape [..., n or 1, 1, num_bits_per_symbol]\n","            prior = sn.utils.expand_to_rank(prior, tf.rank(logits), axis=0)\n","            prior = tf.expand_dims(prior, axis=-2)\n","\n","            # Expand the symbol labeling to be broadcastable with prior\n","            # shape [..., 1, num_points, num_bits_per_symbol]\n","            a = sn.utils.expand_to_rank(self._a, tf.rank(prior), axis=0)\n","\n","            # Compute the prior probabilities on symbols exponents\n","            # shape [..., n or 1, num_points]\n","            exp_ps = tf.reduce_sum(tf.math.log_sigmoid(a*prior), axis=-1)\n","\n","            # Gather prior probability symbol for all bits\n","            # shape [..., n or 1, num_points/2, num_bits_per_symbol]\n","            exp_ps0 = tf.gather(exp_ps, self._c0, axis=-1)\n","            exp_ps1 = tf.gather(exp_ps, self._c1, axis=-1)\n","\n","        # Compute LLRs using the definition log( Pr(b=1)/Pr(b=0) )\n","        # shape [..., n, num_bits_per_symbol]\n","        if self._with_prior:\n","            llr = self._reduce(exp_ps1 + exp1, axis=-2)\\\n","                    - self._reduce(exp_ps0 + exp0, axis=-2)\n","        else:\n","            llr = self._reduce(exp1, axis=-2) - self._reduce(exp0, axis=-2)\n","\n","        if self._hard_out:\n","            return sn.utils.hard_decisions(llr)\n","        else:\n","            return llr\n","\n","\n","\n","\n","class SymbolLogits2LLRsWithPrior(SymbolLogits2LLRs):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    SymbolLogits2LLRsWithPrior(method, num_bits_per_symbol, hard_out=False, dtype=tf.float32, **kwargs)\n","\n","    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n","    from a tensor of logits (i.e., unnormalized log-probabilities) on constellation points,\n","    assuming that prior knowledge on the bits is available.\n","\n","    This class is deprecated as the functionality has been integrated\n","    into :class:`~sionna.mapping.SymbolLogits2LLRs`.\n","\n","    Parameters\n","    ----------\n","    method : One of [\"app\", \"maxlog\"], str\n","        The method used for computing the LLRs.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","\n","    hard_out : bool\n","        If `True`, the layer provides hard-decided bits instead of soft-values.\n","        Defaults to `False`.\n","\n","    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n","        The dtype for the input and output.\n","        Defaults to `tf.float32`.\n","\n","    Input\n","    -----\n","    (logits, prior):\n","        Tuple:\n","\n","    logits : [...,n, num_points], tf.float\n","        Logits on constellation points.\n","\n","    prior : [num_bits_per_symbol] or [...n, num_bits_per_symbol], tf.float\n","        Prior for every bit as LLRs.\n","        It can be provided either as a tensor of shape `[num_bits_per_symbol]` for the\n","        entire input batch, or as a tensor that is \"broadcastable\"\n","        to `[..., n, num_bits_per_symbol]`.\n","\n","    Output\n","    ------\n","    : [...,n, num_bits_per_symbol], tf.float\n","        LLRs or hard-decisions for every bit.\n","\n","    Note\n","    ----\n","    With the \"app\" method, the LLR for the :math:`i\\text{th}` bit\n","    is computed according to\n","\n","    .. math::\n","        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert \\mathbf{z},\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert \\mathbf{z},\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n","                \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                e^{z_c}\n","                }{\n","                \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                e^{z_c}\n","                }\\right)\n","\n","    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n","    sets of :math:`2^K` constellation points for which the :math:`i\\text{th}` bit is\n","    equal to 1 and 0, respectively. :math:`\\mathbf{z} = \\left[z_{c_0},\\dots,z_{c_{2^K-1}}\\right]` is the vector of logits on the constellation points, :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]`\n","    is the vector of LLRs that serves as prior knowledge on the :math:`K` bits that are mapped to\n","    a constellation point,\n","    and :math:`\\Pr(c\\lvert\\mathbf{p})` is the prior probability on the constellation symbol :math:`c`:\n","\n","    .. math::\n","        \\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert\\mathbf{p} \\right)\n","        = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n","\n","    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where 0 is\n","    replaced by -1.\n","    The definition of the LLR has been\n","    chosen such that it is equivalent with that of logits. This is\n","    different from many textbooks in communications, where the LLR is\n","    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n","\n","    With the \"maxlog\" method, LLRs for the :math:`i\\text{th}` bit\n","    are approximated like\n","\n","    .. math::\n","        \\begin{align}\n","            LLR(i) &\\approx\\ln\\left(\\frac{\n","                \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                    e^{z_c}\n","                }{\n","                \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                    e^{z_c}\n","                }\\right)\n","                .\n","        \\end{align}\n","    \"\"\"\n","    def __init__(self,\n","                 method,\n","                 num_bits_per_symbol,\n","                 hard_out=False,\n","                 dtype=tf.float32,\n","                 **kwargs):\n","        super().__init__(method=method,\n","                         num_bits_per_symbol=num_bits_per_symbol,\n","                         hard_out=False,\n","                         with_prior=True,\n","                         dtype=tf.float32,\n","                         **kwargs)\n","\n","\n","\n","\n","class Demapper(Layer):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    Demapper(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)\n","\n","    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n","    for a tensor of received symbols.\n","    If the flag ``with_prior`` is set, prior knowledge on the bits is assumed to be available.\n","\n","    This class defines a layer implementing different demapping\n","    functions. All demapping functions are fully differentiable when soft-decisions\n","    are computed.\n","\n","    Parameters\n","    ----------\n","    demapping_method : One of [\"app\", \"maxlog\"], str\n","        The demapping method used.\n","\n","    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n","        must be provided.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n","\n","    constellation : Constellation\n","        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n","        In the latter case, ``constellation_type``\n","        and ``num_bits_per_symbol`` must be provided.\n","\n","    hard_out : bool\n","        If `True`, the demapper provides hard-decided bits instead of soft-values.\n","        Defaults to `False`.\n","\n","    with_prior : bool\n","        If `True`, it is assumed that prior knowledge on the bits is available.\n","        This prior information is given as LLRs as an additional input to the layer.\n","        Defaults to `False`.\n","\n","    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n","        The dtype of `y`. Defaults to tf.complex64.\n","        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n","\n","    Input\n","    -----\n","    (y,no) or (y, prior, no) :\n","        Tuple:\n","\n","    y : [...,n], tf.complex\n","        The received symbols.\n","\n","    prior : [num_bits_per_symbol] or [...,num_bits_per_symbol], tf.float\n","        Prior for every bit as LLRs.\n","        It can be provided either as a tensor of shape `[num_bits_per_symbol]` for the\n","        entire input batch, or as a tensor that is \"broadcastable\"\n","        to `[..., n, num_bits_per_symbol]`.\n","        Only required if the ``with_prior`` flag is set.\n","\n","    no : Scalar or [...,n], tf.float\n","        The noise variance estimate. It can be provided either as scalar\n","        for the entire input batch or as a tensor that is \"broadcastable\" to\n","        ``y``.\n","\n","    Output\n","    ------\n","    : [...,n*num_bits_per_symbol], tf.float\n","        LLRs or hard-decisions for every bit.\n","\n","    Note\n","    ----\n","    With the \"app\" demapping method, the LLR for the :math:`i\\text{th}` bit\n","    is computed according to\n","\n","    .. math::\n","        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n","                \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n","                }{\n","                \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n","                }\\right)\n","\n","    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n","    sets of constellation points for which the :math:`i\\text{th}` bit is\n","    equal to 1 and 0, respectively. :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]`\n","    is the vector of LLRs that serves as prior knowledge on the :math:`K` bits that are mapped to\n","    a constellation point and is set to :math:`\\mathbf{0}` if no prior knowledge is assumed to be available,\n","    and :math:`\\Pr(c\\lvert\\mathbf{p})` is the prior probability on the constellation symbol :math:`c`:\n","\n","    .. math::\n","        \\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n","\n","    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where 0 is\n","    replaced by -1.\n","    The definition of the LLR has been\n","    chosen such that it is equivalent with that of logits. This is\n","    different from many textbooks in communications, where the LLR is\n","    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n","\n","    With the \"maxlog\" demapping method, LLRs for the :math:`i\\text{th}` bit\n","    are approximated like\n","\n","    .. math::\n","        \\begin{align}\n","            LLR(i) &\\approx\\ln\\left(\\frac{\n","                \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                    \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n","                }{\n","                \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                    \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n","                }\\right)\\\\\n","                &= \\max_{c\\in\\mathcal{C}_{i,0}}\n","                    \\left(\\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right)-\\frac{|y-c|^2}{N_o}\\right) -\n","                 \\max_{c\\in\\mathcal{C}_{i,1}}\\left( \\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right) - \\frac{|y-c|^2}{N_o}\\right)\n","                .\n","        \\end{align}\n","    \"\"\"\n","    def __init__(self,\n","                 demapping_method,\n","                 constellation_type=None,\n","                 num_bits_per_symbol=None,\n","                 constellation=None,\n","                 hard_out=False,\n","                 with_prior=False,\n","                 dtype=tf.complex64,\n","                 **kwargs):\n","        super().__init__(dtype=dtype, **kwargs)\n","        self._with_prior = with_prior\n","\n","\n","        # Create constellation object\n","        self._constellation = Constellation.create_or_check_constellation(\n","                                                        constellation_type,\n","                                                        num_bits_per_symbol,\n","                                                        constellation,\n","                                                        dtype=dtype)\n","        num_bits_per_symbol = self._constellation.num_bits_per_symbol\n","\n","        self._logits2llrs = SymbolLogits2LLRs(demapping_method,\n","                                              num_bits_per_symbol,\n","                                              hard_out,\n","                                              with_prior,\n","                                              dtype.real_dtype,\n","                                              **kwargs)\n","\n","    @property\n","    def constellation(self):\n","        return self._constellation\n","\n","    def call(self, inputs):\n","        if self._with_prior:\n","            y, prior, no = inputs\n","        else:\n","            y, no = inputs\n","\n","        # Reshape constellation points to [1,...1,num_points]\n","        points_shape = [1]*y.shape.rank + self.constellation.points.shape\n","        points = tf.reshape(self.constellation.points, points_shape)\n","\n","        # Compute squared distances from y to all points\n","        # shape [...,n,num_points]\n","        squared_dist = tf.pow(tf.abs(tf.expand_dims(y, axis=-1) - points), 2)\n","\n","        # Add a dummy dimension for broadcasting. This is not needed when no\n","        # is a scalar, but also does not do any harm.\n","        no = tf.expand_dims(no, axis=-1)\n","\n","        # Compute exponents\n","        exponents = -squared_dist/no\n","\n","        if self._with_prior:\n","            llr = self._logits2llrs([exponents, prior])\n","        else:\n","            llr = self._logits2llrs(exponents)\n","\n","        # Reshape LLRs to [...,n*num_bits_per_symbol]\n","        out_shape = tf.concat([tf.shape(y)[:-1],\n","                               [y.shape[-1] * \\\n","                                self.constellation.num_bits_per_symbol]], 0)\n","        llr_reshaped = tf.reshape(llr, out_shape)\n","\n","        return llr_reshaped\n","\n","\n","\n","\n","class DemapperWithPrior(Demapper):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n","\n","    Computes log-likelihood ratios (LLRs) or hard-decisions on bits\n","    for a tensor of received symbols, assuming that prior knowledge on the bits is available.\n","\n","    This class defines a layer implementing different demapping\n","    functions. All demapping functions are fully differentiable when soft-decisions\n","    are computed.\n","\n","    This class is deprecated as the functionality has been integrated\n","    into :class:`~sionna.mapping.Demapper`.\n","\n","    Parameters\n","    ----------\n","    demapping_method : One of [\"app\", \"maxlog\"], str\n","        The demapping method used.\n","\n","    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n","        must be provided.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n","\n","    constellation : Constellation\n","        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n","        In the latter case, ``constellation_type``\n","        and ``num_bits_per_symbol`` must be provided.\n","\n","    hard_out : bool\n","        If `True`, the demapper provides hard-decided bits instead of soft-values.\n","        Defaults to `False`.\n","\n","    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n","        The dtype of `y`. Defaults to tf.complex64.\n","        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n","\n","    Input\n","    -----\n","    (y, prior, no) :\n","        Tuple:\n","\n","    y : [...,n], tf.complex\n","        The received symbols.\n","\n","    prior : [num_bits_per_symbol] or [...,num_bits_per_symbol], tf.float\n","        Prior for every bit as LLRs.\n","        It can be provided either as a tensor of shape `[num_bits_per_symbol]` for the\n","        entire input batch, or as a tensor that is \"broadcastable\"\n","        to `[..., n, num_bits_per_symbol]`.\n","\n","    no : Scalar or [...,n], tf.float\n","        The noise variance estimate. It can be provided either as scalar\n","        for the entire input batch or as a tensor that is \"broadcastable\" to\n","        ``y``.\n","\n","    Output\n","    ------\n","    : [...,n*num_bits_per_symbol], tf.float\n","        LLRs or hard-decisions for every bit.\n","\n","    Note\n","    ----\n","    With the \"app\" demapping method, the LLR for the :math:`i\\text{th}` bit\n","    is computed according to\n","\n","    .. math::\n","        LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n","                \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n","                }{\n","                \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n","                }\\right)\n","\n","    where :math:`\\mathcal{C}_{i,1}` and :math:`\\mathcal{C}_{i,0}` are the\n","    sets of constellation points for which the :math:`i\\text{th}` bit is\n","    equal to 1 and 0, respectively. :math:`\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]`\n","    is the vector of LLRs that serves as prior knowledge on the :math:`K` bits that are mapped to\n","    a constellation point,\n","    and :math:`\\Pr(c\\lvert\\mathbf{p})` is the prior probability on the constellation symbol :math:`c`:\n","\n","    .. math::\n","        \\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n","\n","    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where 0 is\n","    replaced by -1.\n","    The definition of the LLR has been\n","    chosen such that it is equivalent with that of logits. This is\n","    different from many textbooks in communications, where the LLR is\n","    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n","\n","    With the \"maxlog\" demapping method, LLRs for the :math:`i\\text{th}` bit\n","    are approximated like\n","\n","    .. math::\n","        \\begin{align}\n","            LLR(i) &\\approx\\ln\\left(\\frac{\n","                \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                    \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n","                }{\n","                \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n","                    \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n","                }\\right)\\\\\n","                &= \\max_{c\\in\\mathcal{C}_{i,0}}\n","                    \\left(\\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right)-\\frac{|y-c|^2}{N_o}\\right) -\n","                 \\max_{c\\in\\mathcal{C}_{i,1}}\\left( \\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right) - \\frac{|y-c|^2}{N_o}\\right)\n","                .\n","        \\end{align}\n","    \"\"\"\n","    def __init__(self,\n","                 demapping_method,\n","                 constellation_type=None,\n","                 num_bits_per_symbol=None,\n","                 constellation=None,\n","                 hard_out=False,\n","                 dtype=tf.complex64,\n","                 **kwargs):\n","        super().__init__(demapping_method=demapping_method,\n","                         constellation_type=constellation_type,\n","                         num_bits_per_symbol=num_bits_per_symbol,\n","                         constellation=constellation,\n","                         hard_out=hard_out,\n","                         with_prior=True,\n","                         dtype=dtype,\n","                         **kwargs)\n","\n","\n","\n","\n","class SymbolDemapper(Layer):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    SymbolDemapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)\n","\n","    Computes normalized log-probabilities (logits) or hard-decisions on symbols\n","    for a tensor of received symbols.\n","    If the ``with_prior`` flag is set, prior knowldge on the transmitted constellation points is assumed to be available.\n","    The demapping function is fully differentiable when soft-values are\n","    computed.\n","\n","    Parameters\n","    ----------\n","    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n","        must be provided.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n","\n","    constellation : Constellation\n","        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n","        In the latter case, ``constellation_type``\n","        and ``num_bits_per_symbol`` must be provided.\n","\n","    hard_out : bool\n","        If `True`, the demapper provides hard-decided symbols instead of soft-values.\n","        Defaults to `False`.\n","\n","    with_prior : bool\n","        If `True`, it is assumed that prior knowledge on the constellation points is available.\n","        This prior information is given as log-probabilities (logits) as an additional input to the layer.\n","        Defaults to `False`.\n","\n","    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n","        The dtype of `y`. Defaults to tf.complex64.\n","        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n","\n","    Input\n","    -----\n","    (y, no) or (y, prior, no) :\n","        Tuple:\n","\n","    y : [...,n], tf.complex\n","        The received symbols.\n","\n","    prior : [num_points] or [...,num_points], tf.float\n","        Prior for every symbol as log-probabilities (logits).\n","        It can be provided either as a tensor of shape `[num_points]` for the\n","        entire input batch, or as a tensor that is \"broadcastable\"\n","        to `[..., n, num_points]`.\n","        Only required if the ``with_prior`` flag is set.\n","\n","    no : Scalar or [...,n], tf.float\n","        The noise variance estimate. It can be provided either as scalar\n","        for the entire input batch or as a tensor that is \"broadcastable\" to\n","        ``y``.\n","\n","    Output\n","    ------\n","    : [...,n, num_points] or [...,n], tf.float\n","        A tensor of shape `[...,n, num_points]` of logits for every constellation\n","        point if `hard_out` is set to `False`.\n","        Otherwise, a tensor of shape `[...,n]` of hard-decisions on the symbols.\n","\n","    Note\n","    ----\n","    The normalized log-probability for the constellation point :math:`c` is computed according to\n","\n","    .. math::\n","        \\ln\\left(\\Pr\\left(c \\lvert y,\\mathbf{p}\\right)\\right) = \\ln\\left( \\frac{\\exp\\left(-\\frac{|y-c|^2}{N_0} + p_c \\right)}{\\sum_{c'\\in\\mathcal{C}} \\exp\\left(-\\frac{|y-c'|^2}{N_0} + p_{c'} \\right)} \\right)\n","\n","    where :math:`\\mathcal{C}` is the set of constellation points used for modulation,\n","    and :math:`\\mathbf{p} = \\left\\{p_c \\lvert c \\in \\mathcal{C}\\right\\}` the prior information on constellation points given as log-probabilities\n","    and which is set to :math:`\\mathbf{0}` if no prior information on the constellation points is assumed to be available.\n","    \"\"\"\n","    def __init__(self,\n","                 constellation_type=None,\n","                 num_bits_per_symbol=None,\n","                 constellation=None,\n","                 hard_out=False,\n","                 with_prior=False,\n","                 dtype=tf.complex64,\n","                 **kwargs):\n","        super().__init__(dtype=dtype, **kwargs)\n","        self._hard_out = hard_out\n","        self._with_prior = with_prior\n","\n","        # Create constellation object\n","        self._constellation = Constellation.create_or_check_constellation(\n","                                                        constellation_type,\n","                                                        num_bits_per_symbol,\n","                                                        constellation,\n","                                                        dtype=dtype)\n","\n","    def call(self, inputs):\n","        if self._with_prior:\n","            y, prior, no = inputs\n","        else:\n","            y, no = inputs\n","\n","        points = sn.utils.expand_to_rank(self._constellation.points,\n","                                tf.rank(y)+1, axis=0)\n","        y = tf.expand_dims(y, axis=-1)\n","        d = tf.abs(y-points)\n","\n","        no = sn.utils.expand_to_rank(no, tf.rank(d), axis=-1)\n","        exp = -d**2 / no\n","\n","        if self._with_prior:\n","            prior = sn.utils.expand_to_rank(prior, tf.rank(exp), axis=0)\n","            exp = exp + prior\n","\n","        if self._hard_out:\n","            return tf.argmax(exp, axis=-1, output_type=tf.int32)\n","        else:\n","            return tf.nn.log_softmax(exp, axis=-1)\n","\n","\n","\n","\n","class SymbolDemapperWithPrior(SymbolDemapper):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    SymbolDemapperWithPrior(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n","\n","    Computes normalized log-probabilities (logits) or hard-decisions on symbols\n","    for a tensor of received symbols, assuming that prior knowledge on the constellation points is available.\n","    The demapping function is fully differentiable when soft-values are\n","    computed.\n","\n","    This class is deprecated as the functionality has been integrated\n","    into :class:`~sionna.mapping.SymbolDemapper`.\n","\n","    Parameters\n","    ----------\n","    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n","        must be provided.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n","\n","    constellation : Constellation\n","        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n","        In the latter case, ``constellation_type``\n","        and ``num_bits_per_symbol`` must be provided.\n","\n","    hard_out : bool\n","        If `True`, the demapper provides hard-decided symbols instead of soft-values.\n","        Defaults to `False`.\n","\n","    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n","        The dtype of `y`. Defaults to tf.complex64.\n","        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n","\n","    Input\n","    -----\n","    (y, prior, no) :\n","        Tuple:\n","\n","    y : [...,n], tf.complex\n","        The received symbols.\n","\n","    prior : [num_points] or [...,num_points], tf.float\n","        Prior for every symbol as log-probabilities (logits).\n","        It can be provided either as a tensor of shape `[num_points]` for the\n","        entire input batch, or as a tensor that is \"broadcastable\"\n","        to `[..., n, num_points]`.\n","\n","    no : Scalar or [...,n], tf.float\n","        The noise variance estimate. It can be provided either as scalar\n","        for the entire input batch or as a tensor that is \"broadcastable\" to\n","        ``y``.\n","\n","    Output\n","    ------\n","    : [...,n, num_points] or [...,n], tf.float\n","        A tensor of shape `[...,n, num_points]` of logits for every constellation\n","        point if `hard_out` is set to `False`.\n","        Otherwise, a tensor of shape `[...,n]` of hard-decisions on the symbols.\n","\n","    Note\n","    ----\n","    The normalized log-probability for the constellation point :math:`c` is computed according to\n","\n","    .. math::\n","        \\ln\\left(\\Pr\\left(c \\lvert y,\\mathbf{p}\\right)\\right) = \\ln\\left( \\frac{\\exp\\left(-\\frac{|y-c|^2}{N_0} + p_c \\right)}{\\sum_{c'\\in\\mathcal{C}} \\exp\\left(-\\frac{|y-c'|^2}{N_0} + p_{c'} \\right)} \\right)\n","\n","    where :math:`\\mathcal{C}` is the set of constellation points used for modulation,\n","    and :math:`\\mathbf{p} = \\left\\{p_c \\lvert c \\in \\mathcal{C}\\right\\}` the prior information on constellation points given as log-probabilities.\n","    \"\"\"\n","    def __init__(self,\n","                 constellation_type=None,\n","                 num_bits_per_symbol=None,\n","                 constellation=None,\n","                 hard_out=False,\n","                 dtype=tf.complex64,\n","                 **kwargs):\n","        super().__init__(constellation_type=constellation_type,\n","                         num_bits_per_symbol=num_bits_per_symbol,\n","                         constellation=constellation,\n","                         hard_out=hard_out,\n","                         with_prior=True,\n","                         dtype=dtype,\n","                         **kwargs)\n","\n","\n","\n","\n","class LLRs2SymbolLogits(Layer):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    LLRs2SymbolLogits(num_bits_per_symbol, hard_out=False, dtype=tf.float32, **kwargs)\n","\n","    Computes logits (i.e., unnormalized log-probabilities) or hard decisions\n","    on constellation points from a tensor of log-likelihood ratios (LLRs) on bits.\n","\n","    Parameters\n","    ----------\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","\n","    hard_out : bool\n","        If `True`, the layer provides hard-decided constellation points instead of soft-values.\n","        Defaults to `False`.\n","\n","    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n","        The dtype for the input and output.\n","        Defaults to `tf.float32`.\n","\n","    Input\n","    -----\n","    llrs : [..., n, num_bits_per_symbol], tf.float\n","        LLRs for every bit.\n","\n","    Output\n","    ------\n","    : [...,n, num_points], tf.float or [..., n], tf.int32\n","        Logits or hard-decisions on constellation points.\n","\n","    Note\n","    ----\n","    The logit for the constellation :math:`c` point\n","    is computed according to\n","\n","    .. math::\n","        \\begin{align}\n","            \\log{\\left(\\Pr\\left(c\\lvert LLRs \\right)\\right)}\n","                &= \\log{\\left(\\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert LLRs \\right)\\right)}\\\\\n","                &= \\log{\\left(\\prod_{k=0}^{K-1} \\text{sigmoid}\\left(LLR(k) \\ell(c)_k\\right)\\right)}\\\\\n","                &= \\sum_{k=0}^{K-1} \\log{\\left(\\text{sigmoid}\\left(LLR(k) \\ell(c)_k\\right)\\right)}\n","        \\end{align}\n","\n","    where :math:`\\ell(c)_k` is the :math:`k^{th}` bit label of :math:`c`, where 0 is\n","    replaced by -1.\n","    The definition of the LLR has been\n","    chosen such that it is equivalent with that of logits. This is\n","    different from many textbooks in communications, where the LLR is\n","    defined as :math:`LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)`.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 num_bits_per_symbol,\n","                 hard_out=False,\n","                 dtype=tf.float32,\n","                 **kwargs):\n","        super().__init__(dtype=dtype, **kwargs)\n","\n","        self._hard_out = hard_out\n","        self._num_bits_per_symbol = num_bits_per_symbol\n","        num_points = int(2**num_bits_per_symbol)\n","\n","        # Array composed of binary representations of all symbols indices\n","        a = np.zeros([num_points, num_bits_per_symbol])\n","        for i in range(0, num_points):\n","            a[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n","                              dtype=np.int16)\n","\n","        # Array of labels from {-1, 1} of all symbols\n","        # [num_points, num_bits_per_symbol]\n","        a = 2*a-1\n","        self._a = tf.constant(a, dtype=dtype)\n","\n","    @property\n","    def num_bits_per_symbol(self):\n","        return self._num_bits_per_symbol\n","\n","    def call(self, inputs):\n","        llrs = inputs\n","\n","        # Expand the symbol labeling to be broadcastable with prior\n","        # shape [1, ..., 1, num_points, num_bits_per_symbol]\n","        a = sn.utils.expand_to_rank(self._a, tf.rank(llrs), axis=0)\n","\n","        # Compute the prior probabilities on symbols exponents\n","        # shape [..., 1, num_points]\n","        llrs = tf.expand_dims(llrs, axis=-2)\n","        logits = tf.reduce_sum(tf.math.log_sigmoid(a*llrs), axis=-1)\n","\n","        if self._hard_out:\n","            return tf.argmax(logits, axis=-1, output_type=tf.int32)\n","        else:\n","            return logits\n","\n","\n","\n","\n","class SymbolLogits2Moments(Layer):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    SymbolLogits2Moments(constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.float32, **kwargs)\n","\n","    Computes the mean and variance of a constellation from logits (unnormalized log-probabilities) on the\n","    constellation points.\n","\n","    More precisely, given a constellation :math:`\\mathcal{C} = \\left[ c_0,\\dots,c_{N-1} \\right]` of size :math:`N`, this layer computes the mean and variance\n","    according to\n","\n","    .. math::\n","        \\begin{align}\n","            \\mu &= \\sum_{n = 0}^{N-1} c_n \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\\\\\n","            \\nu &= \\sum_{n = 0}^{N-1} \\left( c_n - \\mu \\right)^2 \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\n","        \\end{align}\n","\n","\n","    where :math:`\\mathbf{\\ell} = \\left[ \\ell_0, \\dots, \\ell_{N-1} \\right]` are the logits, and\n","\n","    .. math::\n","        \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right) = \\frac{\\exp \\left( \\ell_n \\right)}{\\sum_{i=0}^{N-1} \\exp \\left( \\ell_i \\right) }.\n","\n","    Parameters\n","    ----------\n","    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n","        must be provided.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n","\n","    constellation : Constellation\n","        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n","        In the latter case, ``constellation_type``\n","        and ``num_bits_per_symbol`` must be provided.\n","\n","    dtype : One of [tf.float32, tf.float64] tf.DType (dtype)\n","        The dtype for the input and output.\n","        Defaults to `tf.float32`.\n","\n","    Input\n","    -----\n","    logits : [...,n, num_points], tf.float\n","        Logits on constellation points.\n","\n","    Output\n","    ------\n","    mean : [...,n], tf.float\n","        Mean of the constellation.\n","\n","    var : [...,n], tf.float\n","        Variance of the constellation\n","    \"\"\"\n","    def __init__(self,\n","                 constellation_type=None,\n","                 num_bits_per_symbol=None,\n","                 constellation=None,\n","                 dtype=tf.float32,\n","                 **kwargs):\n","        super().__init__(dtype=dtype, **kwargs)\n","\n","        # Create constellation object\n","        const_dtype = tf.complex64 if dtype is tf.float32 else tf.complex128\n","        self._constellation = Constellation.create_or_check_constellation(\n","                                                        constellation_type,\n","                                                        num_bits_per_symbol,\n","                                                        constellation,\n","                                                        dtype=const_dtype)\n","\n","    def __call__(self, logits):\n","        p = tf.math.softmax(logits, axis=-1)\n","        p_c = tf.complex(p, tf.cast(0.0, self.dtype))\n","        points = self._constellation.points\n","        points = sn.utils.expand_to_rank(points, tf.rank(p), axis=0)\n","\n","        mean = tf.reduce_sum(p_c*points, axis=-1, keepdims=True)\n","        var = tf.reduce_sum(p*tf.square(tf.abs(points - mean)), axis=-1)\n","        mean = tf.squeeze(mean, axis=-1)\n","\n","        return mean, var\n","\n","\n","\n","\n","class QAM2PAM:\n","    r\"\"\"Transforms QAM symbol indices to PAM symbol indices.\n","\n","    For indices in a QAM constellation, computes the corresponding indices\n","    for the two PAM constellations corresponding the real and imaginary\n","    components of the QAM constellation.\n","\n","    Parameters\n","    ----------\n","    num_bits_per_symbol : int\n","        The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n","\n","    Input\n","    -----\n","    ind_qam : Tensor, tf.int\n","        Indices in the QAM constellation\n","\n","    Output\n","    -------\n","    ind_pam1 : Tensor, tf.int\n","        Indices for the first component of the corresponding PAM modulation\n","\n","    ind_pam2 : Tensor, tf.int\n","        Indices for the first component of the corresponding PAM modulation\n","    \"\"\"\n","    def __init__(self, num_bits_per_symbol):\n","        base = [2**i for i in range(num_bits_per_symbol//2-1, -1, -1)]\n","        base = np.array(base)\n","        pam1_ind = np.zeros([2**num_bits_per_symbol], dtype=np.int32)\n","        pam2_ind = np.zeros([2**num_bits_per_symbol], dtype=np.int32)\n","        for i in range(0, 2**num_bits_per_symbol):\n","            b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n","                         dtype=np.int32)\n","            pam1_ind[i] = np.sum(b[0::2]*base)\n","            pam2_ind[i] = np.sum(b[1::2]*base)\n","        self._pam1_ind = tf.constant(pam1_ind, dtype=tf.int32)\n","        self._pam2_ind = tf.constant(pam2_ind, dtype=tf.int32)\n","\n","    def __call__(self, ind_qam):\n","\n","        ind_pam1 = tf.gather(self._pam1_ind, ind_qam, axis=0)\n","        ind_pam2 = tf.gather(self._pam2_ind, ind_qam, axis=0)\n","\n","        return ind_pam1, ind_pam2\n","\n","\n","\n","\n","class PAM2QAM:\n","    r\"\"\"Transforms PAM symbol indices/logits to QAM symbol indices/logits.\n","\n","    For two PAM constellation symbol indices or logits, corresponding to\n","    the real and imaginary components of a QAM constellation,\n","    compute the QAM symbol index or logits.\n","\n","    Parameters\n","    ----------\n","    num_bits_per_symbol : int\n","        Number of bits per QAM constellation symbol, e.g., 4 for QAM16\n","\n","    hard_in_out : bool\n","        Determines if inputs and outputs are indices or logits over\n","        constellation symbols.\n","        Defaults to `True`.\n","\n","    Input\n","    -----\n","    pam1 : Tensor, tf.int, or [...,2**(num_bits_per_symbol/2)], tf.float\n","        Indices or logits for the first PAM constellation\n","\n","    pam2 : Tensor, tf.int, or [...,2**(num_bits_per_symbol/2)], tf.float\n","        Indices or logits for the second PAM constellation\n","\n","    Output\n","    -------\n","    qam : Tensor, tf.int, or [...,2**num_bits_per_symbol], tf.float\n","        Indices or logits for the corresponding QAM constellation\n","    \"\"\"\n","    def __init__(self, num_bits_per_symbol, hard_in_out=True):\n","        num_pam_symbols = 2**(num_bits_per_symbol//2)\n","        base = np.array([2**i for i in range(num_bits_per_symbol-1, -1, -1)])\n","\n","        # Create an array of QAM symbol indices, index by two PAM indices\n","        ind = np.zeros([num_pam_symbols, num_pam_symbols], np.int32)\n","        for i in range(0, num_pam_symbols):\n","            for j in range(0, num_pam_symbols):\n","                b1 = np.array(list(np.binary_repr(i,num_bits_per_symbol//2)),\n","                              dtype=np.int16)\n","                b2 = np.array(list(np.binary_repr(j,num_bits_per_symbol//2)),\n","                              dtype=np.int16)\n","                b = np.zeros([num_bits_per_symbol], np.int32)\n","                b[0::2] = b1\n","                b[1::2] = b2\n","                ind[i, j] = np.sum(b*base)\n","        self._qam_ind = tf.constant(ind, dtype=tf.int32)\n","        self._hard_in_out = hard_in_out\n","\n","    def __call__(self, pam1, pam2):\n","\n","        # PAM indices to QAM indices\n","        if self._hard_in_out:\n","            shape = tf.shape(pam1)\n","            ind_pam1 = tf.reshape(pam1, [-1, 1])\n","            ind_pam2 = tf.reshape(pam2, [-1, 1])\n","            ind_pam = tf.concat([ind_pam1, ind_pam2], axis=-1)\n","            ind_qam = tf.gather_nd(self._qam_ind, ind_pam)\n","            ind_qam = tf.reshape(ind_qam, shape)\n","            return ind_qam\n","\n","        # PAM logits to QAM logits\n","        else:\n","            # Compute all combination of sums of logits\n","            logits_mat = tf.expand_dims(pam1, -1) + tf.expand_dims(pam2, -2)\n","\n","            # Flatten to a vector\n","            logits = sn.utils.flatten_last_dims(logits_mat)\n","\n","            # Gather symbols in the correct order\n","            gather_ind = tf.reshape(self._qam_ind, [-1])\n","            logits = tf.gather(logits, gather_ind, axis=-1)\n","            return logits\n","\n","\n","\n","\n","class SymbolInds2Bits(Layer):\n","    # pylint: disable=line-too-long\n","    r\"\"\"SymbolInds2Bits(num_bits_per_symbol, dtype=tf.float32, **kwargs)\n","\n","    Transforms symbol indices to their binary representations.\n","\n","    Parameters\n","    ----------\n","    num_bits_per_symbol : int\n","        Number of bits per constellation symbol\n","\n","    dtype: tf.DType\n","        Output dtype. Defaults to `tf.float32`.\n","\n","    Input\n","    -----\n","    : Tensor, tf.int\n","        Symbol indices\n","\n","    Output\n","    -----\n","    : input.shape + [num_bits_per_symbol], dtype\n","        Binary representation of symbol indices\n","    \"\"\"\n","    def __init__(self,\n","               num_bits_per_symbol,\n","               dtype=tf.float32,\n","               **kwargs):\n","        super().__init__(dtype=dtype, **kwargs)\n","        num_symbols = 2**num_bits_per_symbol\n","        b = np.zeros([num_symbols, num_bits_per_symbol])\n","        for i in range(0, num_symbols):\n","            b[i,:] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n","                              dtype=np.int16)\n","        self._bit_labels = tf.constant(b, self.dtype)\n","\n","    def call(self, inputs):\n","        symbol_ind = inputs\n","        return tf.gather(self._bit_labels, symbol_ind)\n"],"metadata":{"id":"gZtDki86m_SR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.2 sn.mapping.Constellation"],"metadata":{"id":"Mf59lmonhMTG"}},{"cell_type":"code","source":["class Constellation(Layer):\n","    # pylint: disable=line-too-long\n","    r\"\"\"\n","    Constellation(constellation_type, num_bits_per_symbol, initial_value=None, normalize=True, center=False, trainable=False, dtype=tf.complex64, **kwargs)\n","\n","    Constellation that can be used by a (de)mapper.\n","\n","    This class defines a constellation, i.e., a complex-valued vector of\n","    constellation points. A constellation can be trainable. The binary\n","    representation of the index of an element of this vector corresponds\n","    to the bit label of the constellation point. This implicit bit\n","    labeling is used by the ``Mapper`` and ``Demapper`` classes.\n","\n","    Parameters\n","    ----------\n","    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","        For \"custom\", the constellation points are randomly initialized\n","        if no ``initial_value`` is provided.\n","\n","    num_bits_per_symbol : int\n","        The number of bits per constellation symbol, e.g., 4 for QAM16.\n","\n","    initial_value : :math:`[2^\\text{num_bits_per_symbol}]`, NumPy array or Tensor\n","        Initial values of the constellation points. If ``normalize`` or\n","        ``center`` are `True`, the initial constellation might be changed.\n","\n","    normalize : bool\n","        If `True`, the constellation is normalized to have unit power.\n","        Defaults to `True`.\n","\n","    center : bool\n","        If `True`, the constellation is ensured to have zero mean.\n","        Defaults to `False`.\n","\n","    trainable : bool\n","        If `True`, the constellation points are trainable variables.\n","        Defaults to `False`.\n","\n","    dtype : [tf.complex64, tf.complex128], tf.DType\n","        The dtype of the constellation.\n","\n","    Output\n","    ------\n","    : :math:`[2^\\text{num_bits_per_symbol}]`, ``dtype``\n","        The constellation.\n","\n","    Note\n","    ----\n","    One can create a trainable PAM/QAM constellation. This is\n","    equivalent to creating a custom trainable constellation which is\n","    initialized with PAM/QAM constellation points.\n","    \"\"\"\n","    # pylint: enable=C0301\n","\n","    def __init__(self,\n","                 constellation_type,\n","                 num_bits_per_symbol,\n","                 initial_value=None,\n","                 normalize=True,\n","                 center=False,\n","                 trainable=False,\n","                 dtype=tf.complex64,\n","                 **kwargs):\n","### super().__init__(**kwargs): calls the constructor of the base class with the\n","### keyword arguments 'kwargs' to initialize the base class from the derived class.\n","### By using **kwargs, the keyword arguments passed to the derived class \n","### constructor can be passed to the base class constructor as well, without \n","### having to explicitly list them.\n","        super().__init__(**kwargs)\n","\n","### <Keyword 'assert'>\n","### Syntax: assert condition, message\n","### Checks a condition true or false and raises an 'AssertionError' when false.\n","### e.g: assert b != 0, \"Cannot divide by zero\"\n","\n","### <Keyword 'in'>\n","### Syntax: value in sequence\n","### If the value is found in the sequence, in returns True. Otherwise, False.\n","        assert dtype in [tf.complex64, tf.complex128],\\\n","            \"dtype must be tf.complex64 or tf.complex128\"\n","        self._dtype = dtype\n","\n","        assert constellation_type in (\"qam\", \"pam\", \"custom\"),\\\n","            \"Wrong constellation type\"\n","        self._constellation_type = constellation_type\n","\n","### <Function 'isinstance()'>\n","### Syntax: isinstance(object, classinfo)\n","### Checks if an object is an instance of a specific class. Returns True if \n","### the object is an instance of the specified class or a subclass of \n","### the specified class. Otherwise, False.\n","        assert isinstance(normalize, bool), \"normalize must be boolean\"\n","        self._normalize = normalize\n","\n","        assert isinstance(center, bool), \"center must be boolean\"\n","        self._center = center\n","\n","        assert isinstance(trainable, bool), \"trainable must be boolean\"\n","        self._trainable = trainable\n","\n","        # allow float inputs that represent int\n","        assert isinstance(num_bits_per_symbol, (float,int)),\\\n","            \"num_bits_per_symbol must be integer\"\n","        assert (num_bits_per_symbol%1==0),\\\n","            \"num_bits_per_symbol must be integer\"\n","        num_bits_per_symbol = int(num_bits_per_symbol)\n","\n","        if self._constellation_type==\"qam\":\n","            assert num_bits_per_symbol%2 == 0 and num_bits_per_symbol>0,\\\n","                \"num_bits_per_symbol must be a multiple of 2\"\n","            self._num_bits_per_symbol = int(num_bits_per_symbol)\n","\n","            assert initial_value is None, \"QAM must not have an initial value\"\n","            points = qam(self._num_bits_per_symbol, normalize=self.normalize)\n","            points = tf.cast(points, self._dtype)\n","\n","        if self._constellation_type==\"pam\":\n","            assert num_bits_per_symbol>0,\\\n","                \"num_bits_per_symbol must be integer\"\n","            self._num_bits_per_symbol = int(num_bits_per_symbol)\n","\n","            assert initial_value is None, \"PAM must not have an initial value\"\n","            points = pam(self._num_bits_per_symbol, normalize=self.normalize)\n","            points = tf.cast(points, self._dtype)\n","\n","        if self._constellation_type==\"custom\":\n","            assert num_bits_per_symbol>0,\\\n","                \"num_bits_per_symbol must be integer\"\n","            self._num_bits_per_symbol = int(num_bits_per_symbol)\n","\n","            # Randomly initialize points if no initial_value is provided\n","            if initial_value is None:\n","                points = tf.random.uniform(  # pylint: disable=E1123\n","                                        [2, 2**self._num_bits_per_symbol],\n","                                        minval=-0.05, maxval=0.05,\n","                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n","                points  = tf.complex(points[0], points[1])\n","            else:\n","                assert tf.rank(initial_value).numpy() == 1\n","                assert tf.shape(initial_value)[0] == 2**num_bits_per_symbol,\\\n","                    \"initial_value must have shape [2**num_bits_per_symbol]\"\n","                points = tf.cast(initial_value, self._dtype)\n","        self._points = points\n","\n","    def build(self, input_shape): #pylint: disable=unused-argument\n","        points = self._points\n","        points = tf.stack([tf.math.real(points),\n","                           tf.math.imag(points)], axis=0)\n","        if self._trainable:\n","            self._points = tf.Variable(points,\n","                                       trainable=self._trainable,\n","                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n","        else:\n","            self._points = tf.constant(points,\n","                                    dtype=tf.as_dtype(self._dtype).real_dtype)\n","\n","    # pylint: disable=no-self-argument\n","\n","    def create_or_check_constellation(  constellation_type=None,\n","                                        num_bits_per_symbol=None,\n","                                        constellation=None,\n","                                        dtype=tf.complex64):\n","        # pylint: disable=line-too-long\n","        r\"\"\"Static method for conviently creating a constellation object or checking that an existing one\n","        is consistent with requested settings.\n","\n","        If ``constellation`` is `None`, then this method creates a :class:`~sionna.mapping.Constellation`\n","        object of type ``constellation_type`` and with ``num_bits_per_symbol`` bits per symbol.\n","        Otherwise, this method checks that `constellation` is consistent with ``constellation_type`` and\n","        ``num_bits_per_symbol``. If it is, ``constellation`` is returned. Otherwise, an assertion is raised.\n","\n","        Input\n","        ------\n","        constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n","            For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n","            must be provided.\n","\n","        num_bits_per_symbol : int\n","            The number of bits per constellation symbol, e.g., 4 for QAM16.\n","            Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n","\n","        constellation :  Constellation\n","            An instance of :class:`~sionna.mapping.Constellation` or\n","            `None`. In the latter case, ``constellation_type``\n","            and ``num_bits_per_symbol`` must be provided.\n","\n","        Output\n","        -------\n","        : :class:`~sionna.mapping.Constellation`\n","            A constellation object.\n","        \"\"\"\n","        constellation_object = None\n","        if constellation is not None:\n","            assert constellation_type in [None, \"custom\"], \\\n","                \"\"\"`constellation_type` must be \"custom\".\"\"\"\n","            assert num_bits_per_symbol in \\\n","                     [None, constellation.num_bits_per_symbol], \\\n","                \"\"\"`Wrong value of `num_bits_per_symbol.`\"\"\"\n","            assert constellation.dtype==dtype, \\\n","                \"Constellation has wrong dtype.\"\n","            constellation_object = constellation\n","        else:\n","            assert constellation_type in [\"qam\", \"pam\"], \\\n","                \"Wrong constellation type.\"\n","            assert num_bits_per_symbol is not None, \\\n","                \"`num_bits_per_symbol` must be provided.\"\n","            constellation_object = Constellation(   constellation_type,\n","                                                    num_bits_per_symbol,\n","                                                    dtype=dtype)\n","        return constellation_object\n","\n","\n","    def call(self, inputs): #pylint: disable=unused-argument\n","        x = self._points\n","        x = tf.complex(x[0], x[1])\n","        if self._center:\n","            x = x - tf.reduce_mean(x)\n","        if self._normalize:\n","            energy = tf.reduce_mean(tf.square(tf.abs(x)))\n","            energy_sqrt = tf.cast(tf.sqrt(energy), self._dtype)\n","            x = x / energy_sqrt\n","        return x\n","\n","    @property\n","    def normalize(self):\n","        \"\"\"Indicates if the constellation is normalized or not.\"\"\"\n","        return self._normalize\n","\n","    @normalize.setter\n","    def normalize(self, value):\n","        assert isinstance(value, bool), \"`normalize` must be boolean\"\n","        self._normalize = value\n","\n","    @property\n","    def center(self):\n","        \"\"\"Indicates if the constellation is centered.\"\"\"\n","        return self._center\n","\n","    @center.setter\n","    def center(self, value):\n","        assert isinstance(value, bool), \"`center` must be boolean\"\n","        self._center = value\n","\n","    @property\n","    def num_bits_per_symbol(self):\n","        \"\"\"The number of bits per constellation symbol.\"\"\"\n","        return self._num_bits_per_symbol\n","\n","    @property\n","    def points(self):\n","        \"\"\"The (possibly) centered and normalized constellation points.\"\"\"\n","        return self(None)\n","\n","\n","    def show(self, labels=True, figsize=(7,7)):\n","        \"\"\"Generate a scatter-plot of the constellation.\n","\n","        Input\n","        -----\n","        labels : bool\n","            If `True`, the bit labels will be drawn next to each constellation\n","            point. Defaults to `True`.\n","\n","        figsize : Two-element Tuple, float\n","            Width and height in inches. Defaults to `(7,7)`.\n","\n","        Output\n","        ------\n","        : matplotlib.figure.Figure\n","            A handle to a matplot figure object.\n","        \"\"\"\n","        maxval = np.max(np.abs(self.points))*1.05\n","        fig = plt.figure(figsize=figsize)\n","        ax = fig.add_subplot(111)\n","        plt.xlim(-maxval, maxval)\n","        plt.ylim(-maxval, maxval)\n","        plt.scatter(np.real(self.points), np.imag(self.points))\n","        ax.set_aspect(\"equal\", adjustable=\"box\")\n","        plt.xlabel(\"Real Part\")\n","        plt.ylabel(\"Imaginary Part\")\n","        plt.grid(True, which=\"both\", axis=\"both\")\n","        plt.title(\"Constellation Plot\")\n","        if labels is True:\n","            for j, p in enumerate(self.points.numpy()):\n","                plt.annotate(\n","                    np.binary_repr(j, self.num_bits_per_symbol),\n","                    (np.real(p), np.imag(p))\n","                )\n","        return fig"],"metadata":{"id":"sq31CZTwrzug"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.3 sionna.mapping.pam_gray(b)/qam(num_bits_per_symbol, normalize=True)/pam(num_bits_per_symbol, normalize=True)"],"metadata":{"id":"8_B310y21hYs"}},{"cell_type":"markdown","source":["[Source Code]"],"metadata":{"id":"9JCmoCIJbN4y"}},{"cell_type":"code","source":["def pam_gray(b):\n","    # pylint: disable=line-too-long\n","    r\"\"\"Maps a vector of bits to a PAM constellation points with Gray labeling.\n","\n","    This recursive function maps a binary vector to Gray-labelled PAM\n","    constellation points. It can be used to generated QAM constellations.\n","    The constellation is not normalized.\n","\n","    Input\n","    -----\n","    b : [n], NumPy array\n","        Tensor with with binary entries.\n","\n","    Output\n","    ------\n","    : signed int\n","        The PAM constellation point taking values in\n","        :math:`\\{\\pm 1,\\pm 3,\\dots,\\pm (2^n-1)\\}`. ### Latex: a \\pm b  a  b\n","\n","    Note\n","    ----\n","    This algorithm is a recursive implementation of the expressions found in\n","    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n","    \"\"\" # pylint: disable=C0301\n","\n","    if len(b)>1:\n","        return (1-2*b[0])*(2**len(b[1:]) - pam_gray(b[1:]))\n","    return 1-2*b[0]\n","\n","\n","\n","\n","def qam(num_bits_per_symbol, normalize=True):\n","    r\"\"\"Generates a QAM constellation.\n","\n","    This function generates a complex-valued vector, where each element is\n","    a constellation point of an M-ary QAM constellation. The bit\n","    label of the ``n`` th point is given by the length-``num_bits_per_symbol``\n","    binary represenation of ``n``.\n","\n","    Input\n","    -----\n","    num_bits_per_symbol : int\n","        The number of bits per constellation point.\n","        Must be a multiple of two, e.g., 2, 4, 6, 8, etc.\n","\n","    normalize: bool\n","        If `True`, the constellation is normalized to have unit power.\n","        Defaults to `True`.\n","\n","    Output\n","    ------\n","    : :math:`[2^{\\text{num_bits_per_symbol}}]`, np.complex64\n","        The QAM constellation.\n","\n","    Note\n","    ----\n","    The bit label of the nth constellation point is given by the binary\n","    representation of its position within the array and can be obtained\n","    through ``np.binary_repr(n, num_bits_per_symbol)``.\n","\n","\n","    The normalization factor of a QAM constellation is given in\n","    closed-form as:\n","\n","    .. math::\n","        \\sqrt{\\frac{1}{2^{n-2}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n","\n","    where :math:`n= \\text{num_bits_per_symbol}/2` is the number of bits\n","    per dimension.\n","\n","    This algorithm is a recursive implementation of the expressions found in\n","    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n","    \"\"\" # pylint: disable=C0301\n","\n","    try:\n","        assert num_bits_per_symbol % 2 == 0 # is even\n","        assert num_bits_per_symbol >0 # is larger than zero\n","    except AssertionError as error:\n","        raise ValueError(\"num_bits_per_symbol must be a multiple of 2\") \\\n","        from error\n","    assert isinstance(normalize, bool), \"normalize must be boolean\"\n","\n","    # Build constellation by iterating through all points\n","    c = np.zeros([2**num_bits_per_symbol], dtype=np.complex64)\n","    for i in range(0, 2**num_bits_per_symbol):\n","        b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n","                     dtype=np.int16)\n","        c[i] = pam_gray(b[0::2]) + 1j*pam_gray(b[1::2]) # PAM in each dimension\n","\n","    if normalize: # Normalize to unit energy\n","        n = int(num_bits_per_symbol/2)\n","        qam_var = 1/(2**(n-2))*np.sum(np.linspace(1,2**n-1, 2**(n-1))**2)\n","        c /= np.sqrt(qam_var)\n","    return c\n","\n","\n","\n","\n","def pam(num_bits_per_symbol, normalize=True):\n","    r\"\"\"Generates a PAM constellation.\n","\n","    This function generates a real-valued vector, where each element is\n","    a constellation point of an M-ary PAM constellation. The bit\n","    label of the ``n`` th point is given by the length-``num_bits_per_symbol``\n","    binary represenation of ``n``.\n","\n","    Input\n","    -----\n","    num_bits_per_symbol : int\n","        The number of bits per constellation point.\n","        Must be positive.\n","\n","    normalize: bool\n","        If `True`, the constellation is normalized to have unit power.\n","        Defaults to `True`.\n","\n","    Output\n","    ------\n","    : :math:`[2^{\\text{num_bits_per_symbol}}]`, np.float32\n","        The PAM constellation.\n","\n","    Note\n","    ----\n","    The bit label of the nth constellation point is given by the binary\n","    representation of its position within the array and can be obtained\n","    through ``np.binary_repr(n, num_bits_per_symbol)``.\n","\n","\n","    The normalization factor of a PAM constellation is given in\n","    closed-form as:\n","\n","    .. math::\n","        \\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n","\n","    where :math:`n= \\text{num_bits_per_symbol}` is the number of bits\n","    per symbol.\n","\n","    This algorithm is a recursive implementation of the expressions found in\n","    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n","    \"\"\" # pylint: disable=C0301\n","\n","    try:\n","        assert num_bits_per_symbol >0 # is larger than zero\n","    except AssertionError as error:\n","        raise ValueError(\"num_bits_per_symbol must be positive\") \\\n","        from error\n","    assert isinstance(normalize, bool), \"normalize must be boolean\"\n","\n","    # Build constellation by iterating through all points\n","    c = np.zeros([2**num_bits_per_symbol], dtype=np.float32)\n","    for i in range(0, 2**num_bits_per_symbol):\n","        b = np.array(list(np.binary_repr(i,num_bits_per_symbol)),\n","                     dtype=np.int16)\n","        c[i] = pam_gray(b)\n","\n","    if normalize: # Normalize to unit energy\n","        n = int(num_bits_per_symbol)\n","        pam_var = 1/(2**(n-1))*np.sum(np.linspace(1,2**n-1, 2**(n-1))**2)\n","        c /= np.sqrt(pam_var)\n","    return c\n"],"metadata":{"id":"1mc8l6W51ja4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[Learning Notes]"],"metadata":{"id":"b3JWaGS4bWJa"}},{"cell_type":"markdown","source":["How to transfer to Gray code?"],"metadata":{"id":"9hxBEUJsb_53"}},{"cell_type":"code","source":["import numpy as np\n","\n","def pam_gray(data, levels):\n","    # Convert input data to Gray code\n","    gray_data = np.bitwise_xor(data, np.right_shift(data, 1))\n","    print(gray_data)\n","    # Map Gray code to PAM constellation\n","    pam_levels = np.linspace(-1, 1, levels)\n","    print(pam_levels)\n","    pam_symbols = pam_levels[gray_data]\n","    print(pam_symbols)\n","\n","    return pam_symbols\n","\n","data1 = [0, 1, 0, 0, 1]\n","level1 = 4\n","pam_symbols1 = pam_gray(data1,level1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7N3uULZoDr-1","executionInfo":{"status":"ok","timestamp":1676548295123,"user_tz":-660,"elapsed":449,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}},"outputId":"33fd918b-4718-4039-bd3f-65f5c4174e22"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1]\n","[-1.         -0.33333333  0.33333333  1.        ]\n","[-1.         -0.33333333 -1.         -1.         -0.33333333]\n"]}]},{"cell_type":"code","source":["def pam_gray(b):\n","    # pylint: disable=line-too-long\n","    r\"\"\"Maps a vector of bits to a PAM constellation points with Gray labeling.\n","\n","    This recursive function maps a binary vector to Gray-labelled PAM\n","    constellation points. It can be used to generated QAM constellations.\n","    The constellation is not normalized.\n","\n","    Input\n","    -----\n","    b : [n], NumPy array\n","        Tensor with with binary entries.\n","\n","    Output\n","    ------\n","    : signed int\n","        The PAM constellation point taking values in\n","        :math:`\\{\\pm 1,\\pm 3,\\dots,\\pm (2^n-1)\\}`. ### Latex: a \\pm b  a  b\n","\n","    Note\n","    ----\n","    This algorithm is a recursive implementation of the expressions found in\n","    Section 5.1 of [3GPPTS38211]_. It is used in the 5G standard.\n","    \"\"\" # pylint: disable=C0301\n","\n","    if len(b)>1:\n","        return (1-2*b[0])*(2**len(b[1:]) - pam_gray(b[1:]))\n","    return 1-2*b[0]\n","\n","b1 = [1,0,1]\n","pam_gray(b1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKd7E6S7MsVf","executionInfo":{"status":"ok","timestamp":1676550996827,"user_tz":-660,"elapsed":323,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}},"outputId":"2c05f7a6-9f5c-4e16-c294-758d56bd9b6d"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-1"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["[numpy.binary_repr(num, width=None)]"],"metadata":{"id":"b-4RbQhyam01"}},{"cell_type":"markdown","source":["Return the binary representation of the input number as a string.\n","\n","For negative numbers, if width is not given, a minus sign is added to the front. If width is given, the twos complement of the number is returned, with respect to that width."],"metadata":{"id":"nTwDonFXfOEV"}}]}