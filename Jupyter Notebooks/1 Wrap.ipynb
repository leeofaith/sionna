{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyODisOg0FpCJt18UbKX3/3v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Imports & Basics\n","\n","# Import TensorFlow and NumPy\n","import tensorflow as tf\n","import numpy as np\n","\n","# Import Sionna\n","try:\n","    import sionna as sn\n","except ImportError as e:\n","    # Install Sionna if package is not already installed\n","    import os\n","    os.system(\"pip install sionna\")\n","    import sionna as sn\n","\n","# For plotting\n","%matplotlib inline\n","# also try %matplotlib widget\n","\n","import matplotlib.pyplot as plt\n","\n","# for performance measurements\n","import time\n","\n","# For the implementation of the Keras models\n","from tensorflow.keras import Model\n","\n","from sionna.mapping import Mapper, Constellation"],"metadata":{"id":"iN-QIZ32Hs4Z","executionInfo":{"status":"ok","timestamp":1678330299203,"user_tz":-660,"elapsed":307,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def plot_ser(snr_db,\n","             ser,\n","             legend=\"\",\n","             ylabel=\"SER\",\n","             title=\"Symbol Error Rate\",\n","             ebno=True,\n","             #is_bler=None,\n","             xlim=None,\n","             ylim=None,\n","             save_fig=False,\n","             path=\"\"):\n","    \"\"\"Plot error-rates.\n","\n","    Input\n","    -----\n","    snr_db: ndarray\n","        Array of floats defining the simulated SNR points.\n","        Can be also a list of multiple arrays.\n","\n","    ser: ndarray\n","        Array of floats defining the SER per SNR point.\n","        Can be also a list of multiple arrays.\n","\n","    legend: str\n","        Defaults to \"\". Defining the legend entries. Can be\n","        either a string or a list of strings.\n","\n","    ylabel: str\n","        Defaults to \"SER\". Defining the y-label.\n","\n","    title: str\n","        Defaults to \"Symbol Error Rate\". Defining the title of the figure.\n","\n","    ebno: bool\n","        Defaults to True. If True, the x-label is set to\n","        \"EbNo [dB]\" instead of \"EsNo [dB]\".\n","\n","    #is_bler: bool\n","        #Defaults to False. If True, the corresponding curve is dashed.\n","\n","    xlim: tuple of floats\n","        Defaults to None. A tuple of two floats defining x-axis limits.\n","\n","    ylim: tuple of floats\n","        Defaults to None. A tuple of two floats defining y-axis limits.\n","\n","    save_fig: bool\n","        Defaults to False. If True, the figure is saved as `.png`.\n","\n","    path: str\n","        Defaults to \"\". Defining the path to save the figure\n","        (iff ``save_fig`` is True).\n","\n","    Output\n","    ------\n","        (fig, ax) :\n","            Tuple:\n","\n","        fig : matplotlib.figure.Figure\n","            A matplotlib figure handle.\n","\n","        ax : matplotlib.axes.Axes\n","            A matplotlib axes object.\n","    \"\"\"\n","\n","    # legend must be a list or string\n","    if not isinstance(legend, list):\n","        assert isinstance(legend, str)\n","        legend = [legend]\n","\n","    assert isinstance(title, str), \"title must be str.\"\n","\n","    # broadcast snr if ber is list\n","    if isinstance(ser, list):\n","        if not isinstance(snr_db, list):\n","            snr_db = [snr_db]*len(ser)\n","\n","#    # check that is_bler is list of same size and contains only bools\n","#    if is_bler is None:\n","#        if isinstance(ber, list):\n","#            is_bler = [False] * len(ber) # init is_bler as list with False\n","#        else:\n","#            is_bler = False\n","#    else:\n","#        if isinstance(is_bler, list):\n","#            assert (len(is_bler) == len(ber)), \"is_bler has invalid size.\"\n","#        else:\n","#            assert isinstance(is_bler, bool), \\\n","#                \"is_bler must be bool or list of bool.\"\n","#            is_bler = [is_bler] # change to list\n","\n","    # tile snr_db if not list, but ser is list\n","\n","    fig, ax = plt.subplots(figsize=(16,10))\n","\n","    plt.xticks(fontsize=18)\n","    plt.yticks(fontsize=18)\n","\n","    if xlim is not None:\n","        plt.xlim(xlim)\n","    if ylim is not None:\n","        plt.ylim(ylim)\n","\n","    plt.title(title, fontsize=25)\n","    # return figure handle\n","    if isinstance(ser, list):\n","        for idx, b in enumerate(ser):\n","#            if is_bler[idx]:\n","#                line_style = \"--\"\n","#            else:\n","            line_style = \"\"\n","            plt.semilogy(snr_db[idx], b, line_style, linewidth=2)\n","    else:\n","#        if is_bler:\n","#            line_style = \"--\"\n","#        else:\n","        line_style = \"\"\n","        plt.semilogy(snr_db, ber, line_style, linewidth=2)\n","\n","    plt.grid(which=\"both\")\n","    if ebno:\n","        plt.xlabel(r\"$E_b/N_0$ (dB)\", fontsize=25)\n","    else:\n","        plt.xlabel(r\"$E_s/N_0$ (dB)\", fontsize=25)\n","    plt.ylabel(ylabel, fontsize=25)\n","    plt.legend(legend, fontsize=20)\n","    if save_fig:\n","        plt.savefig(path)\n","        plt.close(fig)\n","    else:\n","        #plt.close(fig)\n","        pass\n","    return fig, ax"],"metadata":{"id":"XdBGGVe7RIV7","executionInfo":{"status":"ok","timestamp":1678330356555,"user_tz":-660,"elapsed":4,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def simulate_ser(self,\n","                 mc_fun,\n","                 ebno_dbs,\n","                 batch_size,\n","                 max_mc_iter,\n","                 legend=\"\",\n","                 add_ser=True,\n","#                 add_bler=False,\n","                 soft_estimates=False,\n","                 num_target_symbol_errors=None,\n","#                 num_target_block_errors=None,\n","                 early_stop=True,\n","                 graph_mode=None,\n","                 add_results=True,\n","                 forward_keyboard_interrupt=True,\n","                 show_fig=True,\n","                 verbose=True):\n","        \"\"\"Simulate SER curves for given Keras model and saves the results.\n","\n","        Internally calls :class:`sionna.utils.sim_ser`.\n","\n","        Input\n","        -----\n","        mc_fun:\n","            Callable that yields the transmitted bits `b` and the\n","            receiver's estimate `b_hat` for a given ``batch_size`` and\n","            ``ebno_db``. If ``soft_estimates`` is True, b_hat interpreted as\n","            logit.\n","\n","        ebno_dbs: ndarray of floats\n","            SNR points to be evaluated.\n","\n","        batch_size: tf.int32\n","            Batch-size for evaluation.\n","\n","        max_mc_iter: int\n","            Max. number of Monte-Carlo iterations per SNR point.\n","\n","        legend: str\n","            Name to appear in legend.\n","\n","        add_ser: bool\n","            Defaults to True. Indicate if SER should be added to plot.\n","\n","#        add_bler: bool\n","#            Defaults to False. Indicate if BLER should be added\n","#            to plot.\n","\n","        soft_estimates: bool\n","            A boolean, defaults to False. If True, ``s_hat``\n","            is interpreted as logit and additional hard-decision is applied\n","            internally.\n","\n","        num_target_symbol_errors: int\n","            Target number of symbol errors per SNR point until the simulation\n","            stops.\n","\n","#        num_target_block_errors: int\n","#            Target number of block errors per SNR point until the simulation\n","#            stops.\n","\n","        early_stop: bool\n","            A boolean defaults to True. If True, the simulation stops after the\n","            first error-free SNR point (i.e., no error occurred after\n","            ``max_mc_iter`` Monte-Carlo iterations).\n","\n","        graph_mode: One of [\"graph\", \"xla\"], str\n","            A string describing the execution mode of ``mc_fun``.\n","            Defaults to `None`. In this case, ``mc_fun`` is executed as is.\n","\n","        add_results: bool\n","            Defaults to True. If True, the simulation results will be appended\n","            to the internal list of results.\n","\n","        show_fig: bool\n","            Defaults to True. If True, a BER figure will be plotted.\n","\n","        verbose: bool\n","            A boolean defaults to True. If True, the current progress will be\n","            printed.\n","\n","        forward_keyboard_interrupt: bool\n","            A boolean defaults to True. If False, `KeyboardInterrupts` will be\n","            catched internally and not forwarded (e.g., will not stop outer\n","            loops). If False, the simulation ends and returns the intermediate\n","            simulation results.\n","\n","        Output\n","        ------\n","        (ser):\n","            Tuple:\n","\n","        ser: float\n","            The simulated bit-error rate.\n","\n","#        bler: float\n","#            The simulated block-error rate.\n","        \"\"\"\n","\n","        ser = sim_ser(mc_fun,\n","                    ebno_dbs,\n","                    batch_size,\n","                    soft_estimates=soft_estimates,\n","                    max_mc_iter=max_mc_iter,\n","                    num_target_symbol_errors=num_target_symbol_errors,\n","#                    num_target_block_errors=num_target_block_errors,\n","                    early_stop=early_stop,\n","                    graph_mode=graph_mode,\n","                    verbose=verbose,\n","                forward_keyboard_interrupt=forward_keyboard_interrupt)\n","\n","        if add_ser:\n","            self._sers += [ser]\n","            self._snrs +=  [ebno_dbs]\n","            self._legends += [legend]\n","#            self._is_bler += [False]\n","\n","#        if add_bler:\n","#            self._bers += [bler]\n","#            self._snrs +=  [ebno_dbs]\n","#            self._legends += [legend + \" (BLER)\"]\n","#            self._is_bler += [True]\n","\n","        if show_fig:\n","            self()\n","\n","        # remove current curve if add_results=False\n","        if add_results is False:\n","#            if add_bler:\n","#                self.remove(-1)\n","            if add_ser:\n","                self.remove(-1)\n","\n","        return ser"],"metadata":{"id":"unaZW-AmRdlm","executionInfo":{"status":"ok","timestamp":1678330364031,"user_tz":-660,"elapsed":311,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def sim_ser(mc_fun,\n","            ebno_dbs,\n","            batch_size,\n","            max_mc_iter,\n","            soft_estimates=False,\n","            num_target_symbol_errors=None,\n","#            num_target_block_errors=None,\n","            early_stop=True,\n","            graph_mode=None,\n","            verbose=True,\n","            forward_keyboard_interrupt=True,\n","            dtype=tf.complex64):\n","    \"\"\"Simulates until target number of errors is reached and returns SER.\n","\n","    The simulation continues with the next SNR point if\n","    ``num_target_symbol_errors`` symbol errors\n","    is achieved. Further, it continues with the next SNR point after\n","    ``max_mc_iter`` batches of size ``batch_size`` have been simulated.\n","\n","    Input\n","    -----\n","    mc_fun:\n","        Callable that yields the transmitted bits `b` and the\n","        receiver's estimate `b_hat` for a given ``batch_size`` and\n","        ``ebno_db``. If ``soft_estimates`` is True, b_hat is interpreted as\n","        logit.\n","\n","    ebno_dbs: tf.float32\n","        A tensor containing SNR points to be evaluated.\n","\n","    batch_size: tf.int32\n","        Batch-size for evaluation.\n","\n","    max_mc_iter: tf.int32\n","        Max. number of Monte-Carlo iterations per SNR point.\n","\n","    soft_estimates: bool\n","        A boolean, defaults to False. If True, `s_hat``\n","        is interpreted as logit and an additional hard-decision is applied\n","        internally.\n","\n","    num_target_symbol_errors: tf.int32\n","        Defaults to None. Target number of symbol errors per SNR point until\n","        the simulation continues to next SNR point.\n","\n","#    num_target_block_errors: tf.int32\n","#        Defaults to None. Target number of block errors per SNR point\n","#        until the simulation continues\n","\n","    early_stop: bool\n","        A boolean defaults to True. If True, the simulation stops after the\n","        first error-free SNR point (i.e., no error occurred after\n","        ``max_mc_iter`` Monte-Carlo iterations).\n","\n","    graph_mode: One of [\"graph\", \"xla\"], str\n","        A string describing the execution mode of ``mc_fun``.\n","        Defaults to `None`. In this case, ``mc_fun`` is executed as is.\n","\n","    verbose: bool\n","        A boolean defaults to True. If True, the current progress will be\n","        printed.\n","\n","    forward_keyboard_interrupt: bool\n","        A boolean defaults to True. If False, KeyboardInterrupts will be\n","        catched internally and not forwarded (e.g., will not stop outer loops).\n","        If False, the simulation ends and returns the intermediate simulation\n","        results.\n","\n","    dtype: tf.complex64\n","        Datatype of the model / function to be used (``mc_fun``).\n","\n","    Output\n","    ------\n","    (ser) :\n","        Tuple:\n","\n","    ser: tf.float32\n","        The symbol-error rate.\n","\n","#    bler: tf.float32\n","#        The block-error rate.\n","\n","    Raises\n","    ------\n","    AssertionError\n","        If ``soft_estimates`` is not bool.\n","\n","    AssertionError\n","        If ``dtype`` is not `tf.complex`.\n","\n","    Note\n","    ----\n","    This function is implemented based on tensors to allow\n","    full compatibility with tf.function(). However, to run simulations\n","    in graph mode, the provided ``mc_fun`` must use the `@tf.function()`\n","    decorator.\n","\n","    \"\"\"\n","\n","    # utility function to print progress\n","    def _print_progress(is_final, rt, idx_snr, idx_it, header_text=None):\n","        \"\"\"Print summary of current simulation progress.\n","\n","        Input\n","        -----\n","        is_final: bool\n","            A boolean. If True, the progress is printed into a new line.\n","        rt: float\n","            The runtime of the current SNR point in seconds.\n","        idx_snr: int\n","            Index of current SNR point.\n","        idx_it: int\n","            Current iteration index.\n","        header_text: list of str\n","            Elements will be printed instead of current progress, iff not None.\n","            Can be used to generate table header.\n","        \"\"\"\n","        # set carriage return if not final step\n","        if is_final:\n","            end_str = \"\\n\"\n","        else:\n","            end_str = \"\\r\"\n","\n","        # prepare to print table header\n","        if header_text is not None:\n","            row_text = header_text\n","            end_str = \"\\n\"\n","        else:\n","            # calculate intermediate ber / bler\n","            ser_np = (tf.cast(symbol_errors[idx_snr], tf.float64)\n","                        / tf.cast(nb_symbols[idx_snr], tf.float64)).numpy()\n","            ser_np = np.nan_to_num(ser_np) # avoid nan for first point\n","#            bler_np = (tf.cast(block_errors[idx_snr], tf.float64)\n","#                        / tf.cast(nb_blocks[idx_snr], tf.float64)).numpy()\n","#            bler_np = np.nan_to_num(bler_np) # avoid nan for first point\n","\n","            # load statuslevel\n","            # print current iter if simulation is still running\n","            if status[idx_snr]==0:\n","                status_txt = f\"iter: {idx_it:.0f}/{max_mc_iter:.0f}\"\n","            else:\n","                status_txt = status_levels[int(status[idx_snr])]\n","\n","            # generate list with all elements to be printed\n","            row_text = [str(np.round(ebno_dbs[idx_snr].numpy(), 3)),\n","                        f\"{ser_np:.4e}\",\n","#                        f\"{bler_np:.4e}\",\n","                        np.round(symbol_errors[idx_snr].numpy(), 0),\n","                        np.round(nb_symbols[idx_snr].numpy(), 0),\n","#                        np.round(block_errors[idx_snr].numpy(), 0),\n","#                        np.round(nb_blocks[idx_snr].numpy(), 0),\n","                        np.round(rt, 1),\n","                        status_txt]\n","\n","        # pylint: disable=line-too-long, consider-using-f-string\n","        print(\"{: >9} |{: >11} |{: >12} |{: >12} |{: >12} |{: >10}\".format(*row_text), end=end_str)\n","\n","\n","     # init table headers\n","    header_text = [\"EbNo [dB]\", \"SER\", \"symbol errors\",\n","                   \"num bits\",\n","                   \"runtime [s]\", \"status\"]\n","\n","    # replace status by text\n","    status_levels = [\"not simulated\", # status=0\n","            \"reached max iter       \", # status=1; spacing for impr. layout\n","            \"no errors - early stop\", # status=2\n","            \"reached target symbol errors\"] # status=3\n","#            \"reached target block errors\"] # status=4\n","\n","    # check inputs for consistency\n","    assert isinstance(early_stop, bool), \"early_stop must be bool.\"\n","    assert isinstance(soft_estimates, bool), \"soft_estimates must be bool.\"\n","    assert dtype.is_complex, \"dtype must be a complex type.\"\n","    assert isinstance(verbose, bool), \"verbose must be bool.\"\n","\n","    if graph_mode is None:\n","        graph_mode=\"default\" # applies default graph mode\n","    assert isinstance(graph_mode, str), \"graph_mode must be str.\"\n","\n","    if graph_mode==\"default\":\n","        pass # nothing to do\n","    elif graph_mode==\"graph\":\n","        # avoid retracing -> check if mc_fun is already a function\n","        if not isinstance(mc_fun, tf.types.experimental.GenericFunction):\n","            mc_fun = tf.function(mc_fun,\n","                                 jit_compile=False,\n","                                 experimental_follow_type_hints=True)\n","    elif graph_mode==\"xla\":\n","        # avoid retracing -> check if mc_fun is already a function\n","        if not isinstance(mc_fun, tf.types.experimental.GenericFunction) or \\\n","           not mc_fun.function_spec.jit_compile:\n","            mc_fun = tf.function(mc_fun,\n","                                 jit_compile=True,\n","                                 experimental_follow_type_hints=True)\n","    else:\n","        raise TypeError(\"Unknown graph_mode selected.\")\n","\n","    ebno_dbs = tf.cast(ebno_dbs, dtype.real_dtype)\n","    batch_size = tf.cast(batch_size, tf.int32)\n","    num_points = tf.shape(ebno_dbs)[0]\n","    symbol_errors = tf.Variable(   tf.zeros([num_points], dtype=tf.int64),\n","                            dtype=tf.int64)\n","#    block_errors = tf.Variable(  tf.zeros([num_points], dtype=tf.int64),\n","#                            dtype=tf.int64)\n","    nb_symbols = tf.Variable(  tf.zeros([num_points], dtype=tf.int64),\n","                            dtype=tf.int64)\n","#    nb_blocks = tf.Variable(  tf.zeros([num_points], dtype=tf.int64),\n","#                            dtype=tf.int64)\n","\n","    # track status of simulation (early termination etc.)\n","    status = np.zeros(num_points)\n","\n","    # measure runtime per SNR point\n","    runtime = np.zeros(num_points)\n","\n","    # ensure num_target_errors is a tensor\n","    if num_target_symbol_errors is not None:\n","        num_target_symbol_errors = tf.cast(num_target_symbol_errors, tf.int64)\n","#    if num_target_block_errors is not None:\n","#        num_target_block_errors = tf.cast(num_target_block_errors, tf.int64)\n","\n","    try:\n","        # simulate until a target number of errors is reached\n","        for i in tf.range(num_points):\n","            runtime[i] = time.perf_counter() # save start time\n","            iter_count = -1 # for print in verbose mode\n","            for ii in tf.range(max_mc_iter):\n","\n","                iter_count += 1\n","\n","                outputs = mc_fun(batch_size=batch_size, ebno_db=ebno_dbs[i])\n","\n","                # assume first and second return value is b and b_hat\n","                # other returns are ignored\n","                b = outputs[0]\n","                b_hat = outputs[1]\n","\n","                if soft_estimates:\n","                    b_hat = hard_decisions(b_hat)\n","\n","                # count symbol errors\n","\t\t            s = Mapper(b)\n","\t\t            s_hat = Mapper(b_hat)\n","                symbol_e = count_errors(s, s_hat)\n","#                block_e = count_block_errors(b, b_hat)\n","\n","                # count total number of bits\n","                symbol_n = tf.size(s)\n","#                block_n = tf.size(b[...,-1])\n","\n","                # update variables\n","                symbol_errors = tf.tensor_scatter_nd_add(  symbol_errors, [[i]],\n","                                                    tf.cast([symbol_e], tf.int64))\n","#                block_errors = tf.tensor_scatter_nd_add(  block_errors, [[i]],\n","#                                                tf.cast([block_e], tf.int64))\n","                nb_symbols = tf.tensor_scatter_nd_add( nb_symbols, [[i]],\n","                                                    tf.cast([symbol_n], tf.int64))\n","#                nb_blocks = tf.tensor_scatter_nd_add( nb_blocks, [[i]],\n","#                                                tf.cast([block_n], tf.int64))\n","\n","                # print progress summary\n","                if verbose:\n","                    # print summary header during first iteration\n","                    if i==0 and iter_count==0:\n","                        _print_progress(is_final=True,\n","                                        rt=0,\n","                                        idx_snr=0,\n","                                        idx_it=0,\n","                                        header_text=header_text)\n","                        # print seperator after headline\n","                        print('-' * 135)\n","\n","                    # evaluate current runtime\n","                    rt = time.perf_counter() - runtime[i]\n","                    # print current progress\n","                    _print_progress(is_final=False, idx_snr=i, idx_it=ii, rt=rt)\n","\n","\n","                # symbol-error based stopping cond.\n","                if num_target_symbol_errors is not None:\n","                    if tf.greater_equal(symbol_errors[i], num_target_symbol_errors):\n","                        status[i] = 3 # change internal status for summary\n","                        # stop runtime timer\n","                        runtime[i] = time.perf_counter() - runtime[i]\n","                        break # enough errors for SNR point have been simulated\n","\n","#                # block-error based stopping cond.\n","#                if num_target_block_errors is not None:\n","#                    if tf.greater_equal(block_errors[i],\n","#                                        num_target_block_errors):\n","#                        # stop runtime timer\n","#                        runtime[i] = time.perf_counter() - runtime[i]\n","#                        status[i] = 4 # change internal status for summary\n","#                        break # enough errors for SNR point have been simulated\n","\n","                # max iter have been reached -> continue with next SNR point\n","                if iter_count==max_mc_iter-1: # all iterations are done\n","                    # stop runtime timer\n","                    runtime[i] = time.perf_counter() - runtime[i]\n","                    status[i] = 1 # change internal status for summary\n","\n","            # print results again AFTER last iteration / early stop (new status)\n","            if verbose:\n","                _print_progress(is_final=True,\n","                                idx_snr=i,\n","                                idx_it=iter_count,\n","                                rt=runtime[i])\n","\n","            # early stop if no error occurred\n","            if early_stop: # only if early stop is active\n","                if block_errors[i]==0:\n","                    status[i] = 2 # change internal status for summary\n","                    if verbose:\n","                        print(\"\\nSimulation stopped as no error occurred \" \\\n","                              f\"@ EbNo = {ebno_dbs[i].numpy():.1f} dB.\\n\")\n","                    break\n","\n","    # Stop if KeyboardInterrupt is detected and set remaining SNR points to -1\n","    except KeyboardInterrupt as e:\n","\n","        # Raise Interrupt again to stop outer loops\n","        if forward_keyboard_interrupt:\n","            raise e\n","\n","        print(\"\\nSimulation stopped by the user \" \\\n","              f\"@ EbNo = {ebno_dbs[i].numpy()} dB\")\n","        # overwrite remaining SER positions with -1\n","        for idx in range(i+1, num_points):\n","            symbol_errors = tf.tensor_scatter_nd_update( symbol_errors, [[idx]],\n","                                                    tf.cast([-1], tf.int64))\n","#            block_errors = tf.tensor_scatter_nd_update( block_errors, [[idx]],\n","#                                                    tf.cast([-1], tf.int64))\n","            nb_symbols = tf.tensor_scatter_nd_update( nb_symbols, [[idx]],\n","                                                    tf.cast([1], tf.int64))\n","#            nb_blocks = tf.tensor_scatter_nd_update( nb_blocks, [[idx]],\n","#                                                    tf.cast([1], tf.int64))\n","\n","    # calculate SER\n","    ser = tf.cast(symbol_errors, tf.float64) / tf.cast(nb_symbols, tf.float64)\n","#    bler = tf.cast(block_errors, tf.float64) / tf.cast(nb_blocks, tf.float64)\n","\n","    # replace nans (from early stop)\n","    ser = tf.where(tf.math.is_nan(ser), tf.zeros_like(ser), ser)\n","#    bler = tf.where(tf.math.is_nan(bler), tf.zeros_like(bler), bler)\n","\n","    return ser"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":134},"id":"hBmy26CjRnCQ","executionInfo":{"status":"error","timestamp":1678330508213,"user_tz":-660,"elapsed":300,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}},"outputId":"c1d914e7-0f14-4e0a-c7ae-2ccb50293774"},"execution_count":12,"outputs":[{"output_type":"error","ename":"TabError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-12ba93dffc46>\"\u001b[0;36m, line \u001b[0;32m243\u001b[0m\n\u001b[0;31m    s = Mapper(b)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6ysPZH5aHWLn","executionInfo":{"status":"ok","timestamp":1678088296121,"user_tz":-660,"elapsed":5,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}}},"outputs":[],"source":["class UncodedSystemAWGN(Model): # Inherits from Keras Model\n","    def __init__(self, num_bits_per_symbol, block_length):\n","        \"\"\"\n","        A keras model of an uncoded transmission over the AWGN channel.\n","\n","        Parameters\n","        ----------\n","        num_bits_per_symbol: int\n","            The number of bits per constellation symbol, e.g., 4 for QAM16.\n","\n","        block_length: int\n","            The number of bits per transmitted message block (will be the codeword length later).\n","\n","        Input\n","        -----\n","        batch_size: int\n","            The batch_size of the Monte-Carlo simulation.\n","\n","        ebno_db: float\n","            The `Eb/No` value (=rate-adjusted SNR) in dB.\n","\n","        Output\n","        ------\n","        (bits, llr):\n","            Tuple:\n","\n","        bits: tf.float32\n","            A tensor of shape `[batch_size, block_length] of 0s and 1s\n","            containing the transmitted information bits.\n","\n","        llr: tf.float32\n","            A tensor of shape `[batch_size, block_length] containing the\n","            received log-likelihood-ratio (LLR) values.\n","        \"\"\"\n","\n","        super().__init__() # Must call the Keras model initializer\n","\n","        self.num_bits_per_symbol = num_bits_per_symbol\n","        self.block_length = block_length\n","        self.constellation = sn.mapping.Constellation(\"qam\", self.num_bits_per_symbol)\n","        self.mapper = sn.mapping.Mapper(constellation=self.constellation)\n","        self.demapper = sn.mapping.Demapper(\"app\", constellation=self.constellation)\n","        self.binary_source = sn.utils.BinarySource()\n","        self.awgn_channel = sn.channel.AWGN()\n","\n","    # @tf.function # Enable graph execution to speed things up\n","    def __call__(self, batch_size, ebno_db):\n","\n","        # no channel coding used; we set coderate=1.0\n","        no = sn.utils.ebnodb2no(ebno_db,\n","                                num_bits_per_symbol=self.num_bits_per_symbol,\n","                                coderate=1.0)\n","\n","        bits = self.binary_source([batch_size, self.block_length]) # Blocklength set to 1024 bits\n","        #print(\"bits=\",bits)\n","        x = self.mapper(bits)\n","        #print(\"x=\",x)\n","        y = self.awgn_channel([x, no])\n","        #print(\"y=\",y)\n","        llr = self.demapper([y,no])\n","        #print(\"llr=\",llr)\n","        return bits, llr"]},{"cell_type":"code","source":["# Constellation\n","\n","NUM_BITS_PER_SYMBOL = 4 # QPSK\n","#constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n","\n","#constellation.show(figsize=(7,7));\n","model_uncoded_awgn = UncodedSystemAWGN(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, block_length=1024)\n","EBN0_DB_MIN = -3.0 # Minimum value of Eb/N0 [dB] for simulations\n","EBN0_DB_MAX = 5.0 # Maximum value of Eb/N0 [dB] for simulations\n","BATCH_SIZE = 2000 # How many examples are processed by Sionna in parallel\n","\n","#model_uncoded_awgn(batch_size=BATCH_SIZE, ebno_db=-3)\n","\n","ber_plots = sn.utils.PlotBER(\"AWGN\")\n","# ber_plots.simulate(model_uncoded_awgn,\n","#                   ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n","#                   batch_size=BATCH_SIZE,\n","#                   num_target_block_errors=100, # simulate until 100 block errors occured\n","#                   legend=\"Uncoded\",\n","#                   soft_estimates=True,\n","#                   max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n","#                   show_fig=True);"],"metadata":{"id":"4nhq-heIH416","executionInfo":{"status":"ok","timestamp":1678088332182,"user_tz":-660,"elapsed":392,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b083374-b8f5-4d23-ece2-9c50c415ca55"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["<sionna.utils.plotting.PlotBER object at 0x7f1322134e80>\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# define two arrays with the same shape\n","arr1 = np.array([[1, 2], [3, 4]])\n","arr2 = np.array([[1, 2], [2, 4]])\n","\n","# compare the two arrays\n","comparison = arr1 == arr2\n","\n","# count the number of different elements\n","different_elements = np.count_nonzero(comparison == False)\n","\n","# print the result\n","print(\"The number of different elements is:\", different_elements)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ve5wR7FRt7iw","executionInfo":{"status":"ok","timestamp":1678006674337,"user_tz":-660,"elapsed":281,"user":{"displayName":"Xinyang Li","userId":"17514655502118138922"}},"outputId":"91fdafd0-853e-4b7b-8f42-bc126a9ec201"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["The number of different elements is: 1\n"]}]}]}