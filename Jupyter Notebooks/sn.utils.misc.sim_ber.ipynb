{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_ber(mc_fun,\n",
    "            ebno_dbs,\n",
    "            batch_size,\n",
    "            max_mc_iter,\n",
    "            soft_estimates=False,\n",
    "            num_target_bit_errors=None,\n",
    "            num_target_block_errors=None,\n",
    "            early_stop=True,\n",
    "            graph_mode=None,\n",
    "            verbose=True,\n",
    "            forward_keyboard_interrupt=True,\n",
    "            dtype=tf.complex64):\n",
    "    \"\"\"Simulates until target number of errors is reached and returns BER/BLER.\n",
    "\n",
    "    The simulation continues with the next SNR point if either\n",
    "    ``num_target_bit_errors`` bit errors or ``num_target_block_errors`` block\n",
    "    errors is achieved. Further, it continues with the next SNR point after\n",
    "    ``max_mc_iter`` batches of size ``batch_size`` have been simulated.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    mc_fun:\n",
    "        Callable that yields the transmitted bits `b` and the\n",
    "        receiver's estimate `b_hat` for a given ``batch_size`` and\n",
    "        ``ebno_db``. If ``soft_estimates`` is True, b_hat is interpreted as\n",
    "        logit.\n",
    "\n",
    "    ebno_dbs: tf.float32\n",
    "        A tensor containing SNR points to be evaluated.\n",
    "\n",
    "    batch_size: tf.int32\n",
    "        Batch-size for evaluation.\n",
    "\n",
    "    max_mc_iter: tf.int32\n",
    "        Max. number of Monte-Carlo iterations per SNR point.\n",
    "\n",
    "    soft_estimates: bool\n",
    "        A boolean, defaults to False. If True, `b_hat``\n",
    "        is interpreted as logit and an additional hard-decision is applied\n",
    "        internally.\n",
    "\n",
    "    num_target_bit_errors: tf.int32\n",
    "        Defaults to None. Target number of bit errors per SNR point until\n",
    "        the simulation continues to next SNR point.\n",
    "\n",
    "    num_target_block_errors: tf.int32\n",
    "        Defaults to None. Target number of block errors per SNR point\n",
    "        until the simulation continues\n",
    "\n",
    "    early_stop: bool\n",
    "        A boolean defaults to True. If True, the simulation stops after the\n",
    "        first error-free SNR point (i.e., no error occurred after\n",
    "        ``max_mc_iter`` Monte-Carlo iterations).\n",
    "\n",
    "    graph_mode: One of [\"graph\", \"xla\"], str\n",
    "        A string describing the execution mode of ``mc_fun``.\n",
    "        Defaults to `None`. In this case, ``mc_fun`` is executed as is.\n",
    "\n",
    "    verbose: bool\n",
    "        A boolean defaults to True. If True, the current progress will be\n",
    "        printed.\n",
    "\n",
    "    forward_keyboard_interrupt: bool\n",
    "        A boolean defaults to True. If False, KeyboardInterrupts will be\n",
    "        catched internally and not forwarded (e.g., will not stop outer loops).\n",
    "        If False, the simulation ends and returns the intermediate simulation\n",
    "        results.\n",
    "\n",
    "    dtype: tf.complex64\n",
    "        Datatype of the model / function to be used (``mc_fun``).\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    (ber, bler) :\n",
    "        Tuple:\n",
    "\n",
    "    ber: tf.float32\n",
    "        The bit-error rate.\n",
    "\n",
    "    bler: tf.float32\n",
    "        The block-error rate.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    AssertionError\n",
    "        If ``soft_estimates`` is not bool.\n",
    "\n",
    "    AssertionError\n",
    "        If ``dtype`` is not `tf.complex`.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    This function is implemented based on tensors to allow\n",
    "    full compatibility with tf.function(). However, to run simulations\n",
    "    in graph mode, the provided ``mc_fun`` must use the `@tf.function()`\n",
    "    decorator.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # utility function to print progress\n",
    "    def _print_progress(is_final, rt, idx_snr, idx_it, header_text=None):\n",
    "        \"\"\"Print summary of current simulation progress.\n",
    "\n",
    "        Input\n",
    "        -----\n",
    "        is_final: bool\n",
    "            A boolean. If True, the progress is printed into a new line.\n",
    "        rt: float\n",
    "            The runtime of the current SNR point in seconds.\n",
    "        idx_snr: int\n",
    "            Index of current SNR point.\n",
    "        idx_it: int\n",
    "            Current iteration index.\n",
    "        header_text: list of str\n",
    "            Elements will be printed instead of current progress, iff not None.\n",
    "            Can be used to generate table header.\n",
    "        \"\"\"\n",
    "        # set carriage return if not final step\n",
    "        if is_final:\n",
    "            end_str = \"\\n\"\n",
    "        else:\n",
    "            end_str = \"\\r\"\n",
    "\n",
    "        # prepare to print table header\n",
    "        if header_text is not None:\n",
    "            row_text = header_text\n",
    "            end_str = \"\\n\"\n",
    "        else:\n",
    "            # calculate intermediate ber / bler\n",
    "            ber_np = (tf.cast(bit_errors[idx_snr], tf.float64)\n",
    "                        / tf.cast(nb_bits[idx_snr], tf.float64)).numpy()\n",
    "            ber_np = np.nan_to_num(ber_np) # avoid nan for first point\n",
    "            bler_np = (tf.cast(block_errors[idx_snr], tf.float64)\n",
    "                        / tf.cast(nb_blocks[idx_snr], tf.float64)).numpy()\n",
    "            bler_np = np.nan_to_num(bler_np) # avoid nan for first point\n",
    "\n",
    "            # load statuslevel\n",
    "            # print current iter if simulation is still running\n",
    "            if status[idx_snr]==0:\n",
    "                status_txt = f\"iter: {idx_it:.0f}/{max_mc_iter:.0f}\"\n",
    "            else:\n",
    "                status_txt = status_levels[int(status[idx_snr])]\n",
    "\n",
    "            # generate list with all elements to be printed\n",
    "            row_text = [str(np.round(ebno_dbs[idx_snr].numpy(), 3)),\n",
    "                        f\"{ber_np:.4e}\",\n",
    "                        f\"{bler_np:.4e}\",\n",
    "                        np.round(bit_errors[idx_snr].numpy(), 0),\n",
    "                        np.round(nb_bits[idx_snr].numpy(), 0),\n",
    "                        np.round(block_errors[idx_snr].numpy(), 0),\n",
    "                        np.round(nb_blocks[idx_snr].numpy(), 0),\n",
    "                        np.round(rt, 1),\n",
    "                        status_txt]\n",
    "\n",
    "        # pylint: disable=line-too-long, consider-using-f-string\n",
    "        print(\"{: >9} |{: >11} |{: >11} |{: >12} |{: >12} |{: >13} |{: >12} |{: >12} |{: >10}\".format(*row_text), end=end_str)\n",
    "\n",
    "\n",
    "     # init table headers\n",
    "    header_text = [\"EbNo [dB]\", \"BER\", \"BLER\", \"bit errors\",\n",
    "                   \"num bits\", \"block errors\", \"num blocks\",\n",
    "                   \"runtime [s]\", \"status\"]\n",
    "\n",
    "    # replace status by text\n",
    "    status_levels = [\"not simulated\", # status=0\n",
    "            \"reached max iter       \", # status=1; spacing for impr. layout\n",
    "            \"no errors - early stop\", # status=2\n",
    "            \"reached target bit errors\", # status=3\n",
    "            \"reached target block errors\"] # status=4\n",
    "\n",
    "    # check inputs for consistency\n",
    "    assert isinstance(early_stop, bool), \"early_stop must be bool.\"\n",
    "    assert isinstance(soft_estimates, bool), \"soft_estimates must be bool.\"\n",
    "    assert dtype.is_complex, \"dtype must be a complex type.\"\n",
    "    assert isinstance(verbose, bool), \"verbose must be bool.\"\n",
    "\n",
    "    if graph_mode is None:\n",
    "        graph_mode=\"default\" # applies default graph mode\n",
    "    assert isinstance(graph_mode, str), \"graph_mode must be str.\"\n",
    "\n",
    "    if graph_mode==\"default\":\n",
    "        pass # nothing to do\n",
    "    elif graph_mode==\"graph\":\n",
    "        # avoid retracing -> check if mc_fun is already a function\n",
    "        if not isinstance(mc_fun, tf.types.experimental.GenericFunction):\n",
    "            mc_fun = tf.function(mc_fun,\n",
    "                                 jit_compile=False,\n",
    "                                 experimental_follow_type_hints=True)\n",
    "    elif graph_mode==\"xla\":\n",
    "        # avoid retracing -> check if mc_fun is already a function\n",
    "        if not isinstance(mc_fun, tf.types.experimental.GenericFunction) or \\\n",
    "           not mc_fun.function_spec.jit_compile:\n",
    "            mc_fun = tf.function(mc_fun,\n",
    "                                 jit_compile=True,\n",
    "                                 experimental_follow_type_hints=True)\n",
    "    else:\n",
    "        raise TypeError(\"Unknown graph_mode selected.\")\n",
    "\n",
    "    ebno_dbs = tf.cast(ebno_dbs, dtype.real_dtype)\n",
    "    batch_size = tf.cast(batch_size, tf.int32)\n",
    "    num_points = tf.shape(ebno_dbs)[0]\n",
    "    bit_errors = tf.Variable(   tf.zeros([num_points], dtype=tf.int64),\n",
    "                            dtype=tf.int64)\n",
    "    block_errors = tf.Variable(  tf.zeros([num_points], dtype=tf.int64),\n",
    "                            dtype=tf.int64)\n",
    "    nb_bits = tf.Variable(  tf.zeros([num_points], dtype=tf.int64),\n",
    "                            dtype=tf.int64)\n",
    "    nb_blocks = tf.Variable(  tf.zeros([num_points], dtype=tf.int64),\n",
    "                            dtype=tf.int64)\n",
    "\n",
    "    # track status of simulation (early termination etc.)\n",
    "    status = np.zeros(num_points)\n",
    "\n",
    "    # measure runtime per SNR point\n",
    "    runtime = np.zeros(num_points)\n",
    "\n",
    "    # ensure num_target_errors is a tensor\n",
    "    if num_target_bit_errors is not None:\n",
    "        num_target_bit_errors = tf.cast(num_target_bit_errors, tf.int64)\n",
    "    if num_target_block_errors is not None:\n",
    "        num_target_block_errors = tf.cast(num_target_block_errors, tf.int64)\n",
    "\n",
    "    try:\n",
    "        # simulate until a target number of errors is reached\n",
    "        for i in tf.range(num_points):\n",
    "            runtime[i] = time.perf_counter() # save start time\n",
    "            iter_count = -1 # for print in verbose mode\n",
    "            for ii in tf.range(max_mc_iter):\n",
    "\n",
    "                iter_count += 1\n",
    "\n",
    "                outputs = mc_fun(batch_size=batch_size, ebno_db=ebno_dbs[i])\n",
    "\n",
    "                # assume first and second return value is b and b_hat\n",
    "                # other returns are ignored\n",
    "                b = outputs[0]\n",
    "                b_hat = outputs[1]\n",
    "\n",
    "                if soft_estimates:\n",
    "                    b_hat = hard_decisions(b_hat)\n",
    "\n",
    "                # count errors\n",
    "                bit_e = count_errors(b, b_hat)\n",
    "                block_e = count_block_errors(b, b_hat)\n",
    "\n",
    "                # count total number of bits\n",
    "                bit_n = tf.size(b)\n",
    "                block_n = tf.size(b[...,-1])\n",
    "\n",
    "                # update variables\n",
    "                bit_errors = tf.tensor_scatter_nd_add(  bit_errors, [[i]],\n",
    "                                                    tf.cast([bit_e], tf.int64))\n",
    "                block_errors = tf.tensor_scatter_nd_add(  block_errors, [[i]],\n",
    "                                                tf.cast([block_e], tf.int64))\n",
    "                nb_bits = tf.tensor_scatter_nd_add( nb_bits, [[i]],\n",
    "                                                    tf.cast([bit_n], tf.int64))\n",
    "                nb_blocks = tf.tensor_scatter_nd_add( nb_blocks, [[i]],\n",
    "                                                tf.cast([block_n], tf.int64))\n",
    "\n",
    "                # print progress summary\n",
    "                if verbose:\n",
    "                    # print summary header during first iteration\n",
    "                    if i==0 and iter_count==0:\n",
    "                        _print_progress(is_final=True,\n",
    "                                        rt=0,\n",
    "                                        idx_snr=0,\n",
    "                                        idx_it=0,\n",
    "                                        header_text=header_text)\n",
    "                        # print seperator after headline\n",
    "                        print('-' * 135)\n",
    "\n",
    "                    # evaluate current runtime\n",
    "                    rt = time.perf_counter() - runtime[i]\n",
    "                    # print current progress\n",
    "                    _print_progress(is_final=False, idx_snr=i, idx_it=ii, rt=rt)\n",
    "\n",
    "\n",
    "                # bit-error based stopping cond.\n",
    "                if num_target_bit_errors is not None:\n",
    "                    if tf.greater_equal(bit_errors[i], num_target_bit_errors):\n",
    "                        status[i] = 3 # change internal status for summary\n",
    "                        # stop runtime timer\n",
    "                        runtime[i] = time.perf_counter() - runtime[i]\n",
    "                        break # enough errors for SNR point have been simulated\n",
    "\n",
    "                # block-error based stopping cond.\n",
    "                if num_target_block_errors is not None:\n",
    "                    if tf.greater_equal(block_errors[i],\n",
    "                                        num_target_block_errors):\n",
    "                        # stop runtime timer\n",
    "                        runtime[i] = time.perf_counter() - runtime[i]\n",
    "                        status[i] = 4 # change internal status for summary\n",
    "                        break # enough errors for SNR point have been simulated\n",
    "\n",
    "                # max iter have been reached -> continue with next SNR point\n",
    "                if iter_count==max_mc_iter-1: # all iterations are done\n",
    "                    # stop runtime timer\n",
    "                    runtime[i] = time.perf_counter() - runtime[i]\n",
    "                    status[i] = 1 # change internal status for summary\n",
    "\n",
    "            # print results again AFTER last iteration / early stop (new status)\n",
    "            if verbose:\n",
    "                _print_progress(is_final=True,\n",
    "                                idx_snr=i,\n",
    "                                idx_it=iter_count,\n",
    "                                rt=runtime[i])\n",
    "\n",
    "            # early stop if no error occurred\n",
    "            if early_stop: # only if early stop is active\n",
    "                if block_errors[i]==0:\n",
    "                    status[i] = 2 # change internal status for summary\n",
    "                    if verbose:\n",
    "                        print(\"\\nSimulation stopped as no error occurred \" \\\n",
    "                              f\"@ EbNo = {ebno_dbs[i].numpy():.1f} dB.\\n\")\n",
    "                    break\n",
    "\n",
    "    # Stop if KeyboardInterrupt is detected and set remaining SNR points to -1\n",
    "    except KeyboardInterrupt as e:\n",
    "\n",
    "        # Raise Interrupt again to stop outer loops\n",
    "        if forward_keyboard_interrupt:\n",
    "            raise e\n",
    "\n",
    "        print(\"\\nSimulation stopped by the user \" \\\n",
    "              f\"@ EbNo = {ebno_dbs[i].numpy()} dB\")\n",
    "        # overwrite remaining BER / BLER positions with -1\n",
    "        for idx in range(i+1, num_points):\n",
    "            bit_errors = tf.tensor_scatter_nd_update( bit_errors, [[idx]],\n",
    "                                                    tf.cast([-1], tf.int64))\n",
    "            block_errors = tf.tensor_scatter_nd_update( block_errors, [[idx]],\n",
    "                                                    tf.cast([-1], tf.int64))\n",
    "            nb_bits = tf.tensor_scatter_nd_update( nb_bits, [[idx]],\n",
    "                                                    tf.cast([1], tf.int64))\n",
    "            nb_blocks = tf.tensor_scatter_nd_update( nb_blocks, [[idx]],\n",
    "                                                    tf.cast([1], tf.int64))\n",
    "\n",
    "    # calculate BER / BLER\n",
    "    ber = tf.cast(bit_errors, tf.float64) / tf.cast(nb_bits, tf.float64)\n",
    "    bler = tf.cast(block_errors, tf.float64) / tf.cast(nb_blocks, tf.float64)\n",
    "\n",
    "    # replace nans (from early stop)\n",
    "    ber = tf.where(tf.math.is_nan(ber), tf.zeros_like(ber), ber)\n",
    "    bler = tf.where(tf.math.is_nan(bler), tf.zeros_like(bler), bler)\n",
    "\n",
    "    return ber, bler"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
